{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T08:13:49.394311Z",
     "start_time": "2024-05-13T08:13:48.587839Z"
    }
   },
   "id": "180c947e7839a277"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T08:13:54.726671Z",
     "start_time": "2024-05-13T08:13:51.440059Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.scripts.utils import preprocess\n",
    "\n",
    "file_paths = ['../data/hourly/ada_lunarcrush_timeseries_hourly.csv', '../data/hourly/btc_lunarcrush_timeseries_hourly.csv', '../data/hourly/doge_lunarcrush_timeseries_hourly.csv', '../data/hourly/eth_lunarcrush_timeseries_hourly.csv', '../data/hourly/xmr_lunarcrush_timeseries_hourly.csv', '../data/hourly/xrp_lunarcrush_timeseries_hourly.csv', '../data/hourly/aave_lunarcrash_timeseries_hourly.csv']\n",
    "\n",
    "crypto_dfs = {}\n",
    "for path in file_paths:\n",
    "    crypto = os.path.basename(path).split('_')[0]\n",
    "    if os.path.exists(path):  # Check if the file exists\n",
    "        crypto_dfs[crypto] = preprocess(path)\n",
    "    else:\n",
    "        print(f\"File does not exist: {path}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training on Financial-only data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11179a2896eceb81"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from models.scripts.utils import simplify_df\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    crypto_dfs[crypto] = simplify_df(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T08:13:55.480555Z",
     "start_time": "2024-05-13T08:13:55.460519Z"
    }
   },
   "id": "69bc7905d190b44e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3927bf944a6e119a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def baseline_model(df):\n",
    "    df['predicted_close'] = df['close'].shift(1)\n",
    "    df = df.dropna(subset=['predicted_close'])\n",
    "    mae = mean_absolute_error(df['close'], df['predicted_close'])\n",
    "    return mae"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T08:13:57.311750Z",
     "start_time": "2024-05-13T08:13:57.305463Z"
    }
   },
   "id": "25c3eec94c289b0e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE results for each cryptocurrency:\n",
      "ada: 0.0047\n",
      "btc: 121.2149\n",
      "doge: 0.0008\n",
      "eth: 8.7742\n",
      "xmr: 1.0392\n",
      "xrp: 0.0036\n",
      "aave: 17.2299\n"
     ]
    }
   ],
   "source": [
    "baseline_results = {}\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    mae = baseline_model(df)\n",
    "    baseline_results[crypto] = mae\n",
    "\n",
    "# Output the baseline MAE results\n",
    "print(\"Baseline MAE results for each cryptocurrency:\")\n",
    "for crypto, mae in baseline_results.items():\n",
    "    print(f\"{crypto}: {mae:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T08:13:58.405133Z",
     "start_time": "2024-05-13T08:13:58.392352Z"
    }
   },
   "id": "9df6fba09ac1cb35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "597f8917256c21be"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras.models import Model as tfkModel\n",
    "\n",
    "def build_simple_LSTM_regressor(input_shape, output_units=1):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm = tfkl.LSTM(16, activation='leaky_relu', return_sequences=True)(input_layer)\n",
    "    lstm = tfkl.LSTM(16, activation='leaky_relu')(lstm)\n",
    "\n",
    "    # Output layer for regression\n",
    "    output_layer = tfkl.Dense(output_units)(lstm)  # Single unit for regression output\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfkModel(inputs=input_layer, outputs=output_layer, name='Simple_LSTM_regressor')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T12:53:11.922135Z",
     "start_time": "2024-05-02T12:53:09.524357Z"
    }
   },
   "id": "d6fecc91004f7446"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def fit(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    # Assuming input_shape is (5, n_features)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_units = 1\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_simple_LSTM_regressor(input_shape, output_units)\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    ).history\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T12:53:11.926903Z",
     "start_time": "2024-05-02T12:53:11.924720Z"
    }
   },
   "id": "e5333f00c89b193"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T12:53:12.162558Z",
     "start_time": "2024-05-02T12:53:11.927520Z"
    }
   },
   "id": "4695c6a453c2d6de"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.0670 - mae: 0.1183 - val_loss: 0.0172 - val_mae: 0.1146 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 0.0060 - val_mae: 0.0689 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.6164e-04 - mae: 0.0171 - val_loss: 0.0017 - val_mae: 0.0354 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.8209e-04 - mae: 0.0157 - val_loss: 8.2147e-04 - val_mae: 0.0238 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.0653e-04 - mae: 0.0146 - val_loss: 5.3331e-04 - val_mae: 0.0188 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.4817e-04 - mae: 0.0139 - val_loss: 5.8363e-04 - val_mae: 0.0198 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.7273e-04 - mae: 0.0130 - val_loss: 4.1103e-04 - val_mae: 0.0163 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.3989e-04 - mae: 0.0129 - val_loss: 6.5098e-04 - val_mae: 0.0211 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.0821e-04 - mae: 0.0126 - val_loss: 2.2216e-04 - val_mae: 0.0116 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.3114e-04 - mae: 0.0116 - val_loss: 3.3335e-04 - val_mae: 0.0147 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.6694e-04 - mae: 0.0108 - val_loss: 2.0975e-04 - val_mae: 0.0115 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.8385e-04 - mae: 0.0110 - val_loss: 2.5664e-04 - val_mae: 0.0129 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7246e-04 - mae: 0.0109 - val_loss: 2.0078e-04 - val_mae: 0.0113 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.1701e-04 - mae: 0.0102 - val_loss: 1.6549e-04 - val_mae: 0.0105 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.7564e-04 - mae: 0.0092 - val_loss: 1.9473e-04 - val_mae: 0.0113 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6574e-04 - mae: 0.0090 - val_loss: 3.2422e-04 - val_mae: 0.0150 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.5490e-04 - mae: 0.0090 - val_loss: 2.2004e-04 - val_mae: 0.0121 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.4432e-04 - mae: 0.0088 - val_loss: 1.8449e-04 - val_mae: 0.0111 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.3792e-04 - mae: 0.0088 - val_loss: 1.9803e-04 - val_mae: 0.0116 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.0588e-04 - mae: 0.0079 - val_loss: 2.0660e-04 - val_mae: 0.0118 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.0015e-04 - mae: 0.0078 - val_loss: 2.3276e-04 - val_mae: 0.0126 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.9657e-04 - mae: 0.0078 - val_loss: 2.1420e-04 - val_mae: 0.0120 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.9323e-04 - mae: 0.0078 - val_loss: 1.5997e-04 - val_mae: 0.0103 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.9006e-04 - mae: 0.0077 - val_loss: 1.7497e-04 - val_mae: 0.0107 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.7075e-04 - mae: 0.0072 - val_loss: 2.2371e-04 - val_mae: 0.0123 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6748e-04 - mae: 0.0071 - val_loss: 1.9060e-04 - val_mae: 0.0112 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6540e-04 - mae: 0.0071 - val_loss: 1.6447e-04 - val_mae: 0.0103 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6280e-04 - mae: 0.0071 - val_loss: 2.5204e-04 - val_mae: 0.0132 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6103e-04 - mae: 0.0071 - val_loss: 1.6670e-04 - val_mae: 0.0104 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.5229e-04 - mae: 0.0068 - val_loss: 2.0773e-04 - val_mae: 0.0118 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.5119e-04 - mae: 0.0068 - val_loss: 1.6921e-04 - val_mae: 0.0104 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.4806e-04 - mae: 0.0067 - val_loss: 1.8869e-04 - val_mae: 0.0111 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.4889e-04 - mae: 0.0067 - val_loss: 1.6978e-04 - val_mae: 0.0105 - lr: 6.2500e-05\n",
      "121/121 [==============================] - 0s 430us/step - loss: 0.0021 - mae: 0.0392\n",
      "121/121 [==============================] - 0s 513us/step\n",
      "Running model for btc...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0706 - mae: 0.1165 - val_loss: 0.0065 - val_mae: 0.0646 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.0903e-04 - mae: 0.0211 - val_loss: 0.0038 - val_mae: 0.0472 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.8716e-04 - mae: 0.0175 - val_loss: 0.0023 - val_mae: 0.0368 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.2188e-04 - mae: 0.0162 - val_loss: 0.0019 - val_mae: 0.0342 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.8460e-04 - mae: 0.0155 - val_loss: 0.0018 - val_mae: 0.0327 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.5209e-04 - mae: 0.0148 - val_loss: 0.0014 - val_mae: 0.0287 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.1099e-04 - mae: 0.0142 - val_loss: 0.0018 - val_mae: 0.0326 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.6748e-04 - mae: 0.0136 - val_loss: 0.0012 - val_mae: 0.0262 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.3188e-04 - mae: 0.0132 - val_loss: 9.3463e-04 - val_mae: 0.0231 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7698e-04 - mae: 0.0124 - val_loss: 7.3990e-04 - val_mae: 0.0199 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.5318e-04 - mae: 0.0121 - val_loss: 7.4763e-04 - val_mae: 0.0207 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.0632e-04 - mae: 0.0113 - val_loss: 5.2906e-04 - val_mae: 0.0168 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.5942e-04 - mae: 0.0104 - val_loss: 4.2763e-04 - val_mae: 0.0157 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.4759e-04 - mae: 0.0105 - val_loss: 5.3411e-04 - val_mae: 0.0183 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.2828e-04 - mae: 0.0099 - val_loss: 4.5780e-04 - val_mae: 0.0168 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.9895e-04 - mae: 0.0092 - val_loss: 2.2165e-04 - val_mae: 0.0112 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.9015e-04 - mae: 0.0091 - val_loss: 2.1861e-04 - val_mae: 0.0114 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.7834e-04 - mae: 0.0089 - val_loss: 1.9272e-04 - val_mae: 0.0107 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.7456e-04 - mae: 0.0088 - val_loss: 2.0381e-04 - val_mae: 0.0109 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.7032e-04 - mae: 0.0087 - val_loss: 5.5879e-04 - val_mae: 0.0194 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6408e-04 - mae: 0.0086 - val_loss: 5.0619e-04 - val_mae: 0.0184 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.3631e-04 - mae: 0.0076 - val_loss: 4.3010e-04 - val_mae: 0.0166 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.3559e-04 - mae: 0.0075 - val_loss: 4.3473e-04 - val_mae: 0.0166 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.3432e-04 - mae: 0.0075 - val_loss: 8.5298e-04 - val_mae: 0.0241 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.2990e-04 - mae: 0.0073 - val_loss: 0.0011 - val_mae: 0.0284 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.3537e-04 - mae: 0.0077 - val_loss: 7.4344e-04 - val_mae: 0.0228 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.1884e-04 - mae: 0.0069 - val_loss: 0.0012 - val_mae: 0.0293 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.1726e-04 - mae: 0.0068 - val_loss: 8.2663e-04 - val_mae: 0.0238 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 477us/step - loss: 0.0025 - mae: 0.0365\n",
      "121/121 [==============================] - 0s 530us/step\n",
      "Running model for doge...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0694 - mae: 0.1068 - val_loss: 0.0107 - val_mae: 0.0861 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0238 - val_loss: 0.0076 - val_mae: 0.0754 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0204 - val_loss: 0.0052 - val_mae: 0.0614 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0181 - val_loss: 0.0058 - val_mae: 0.0667 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0177 - val_loss: 0.0047 - val_mae: 0.0589 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0163 - val_loss: 0.0049 - val_mae: 0.0608 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0162 - val_loss: 0.0043 - val_mae: 0.0563 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0147 - val_loss: 0.0018 - val_mae: 0.0330 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.5268e-04 - mae: 0.0136 - val_loss: 0.0043 - val_mae: 0.0584 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.3981e-04 - mae: 0.0126 - val_loss: 0.0028 - val_mae: 0.0444 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.7183e-04 - mae: 0.0130 - val_loss: 0.0022 - val_mae: 0.0393 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.5113e-04 - mae: 0.0116 - val_loss: 0.0027 - val_mae: 0.0452 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.4634e-04 - mae: 0.0121 - val_loss: 0.0022 - val_mae: 0.0400 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.6946e-04 - mae: 0.0106 - val_loss: 0.0020 - val_mae: 0.0378 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.6183e-04 - mae: 0.0105 - val_loss: 0.0021 - val_mae: 0.0394 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.5415e-04 - mae: 0.0107 - val_loss: 0.0018 - val_mae: 0.0369 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.3216e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0287 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9986e-04 - mae: 0.0100 - val_loss: 0.0015 - val_mae: 0.0337 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.1384e-04 - mae: 0.0103 - val_loss: 0.0017 - val_mae: 0.0365 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.8426e-04 - mae: 0.0102 - val_loss: 0.0020 - val_mae: 0.0399 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.7973e-04 - mae: 0.0102 - val_loss: 0.0012 - val_mae: 0.0289 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.6172e-04 - mae: 0.0098 - val_loss: 0.0022 - val_mae: 0.0407 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0281e-04 - mae: 0.0089 - val_loss: 0.0017 - val_mae: 0.0367 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.9299e-04 - mae: 0.0087 - val_loss: 0.0015 - val_mae: 0.0328 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7899e-04 - mae: 0.0085 - val_loss: 0.0013 - val_mae: 0.0309 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.5945e-04 - mae: 0.0084 - val_loss: 0.0015 - val_mae: 0.0331 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.6863e-04 - mae: 0.0086 - val_loss: 0.0014 - val_mae: 0.0311 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.3873e-04 - mae: 0.0080 - val_loss: 0.0015 - val_mae: 0.0331 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.3021e-04 - mae: 0.0079 - val_loss: 0.0013 - val_mae: 0.0303 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.3023e-04 - mae: 0.0079 - val_loss: 0.0017 - val_mae: 0.0358 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.1973e-04 - mae: 0.0078 - val_loss: 0.0016 - val_mae: 0.0343 - lr: 1.2500e-04\n",
      "121/121 [==============================] - 0s 476us/step - loss: 0.0029 - mae: 0.0452\n",
      "121/121 [==============================] - 0s 567us/step\n",
      "Running model for eth...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.1090 - mae: 0.1429 - val_loss: 0.0042 - val_mae: 0.0492 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0240 - val_loss: 0.0020 - val_mae: 0.0351 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 0.0026 - val_mae: 0.0375 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0170 - val_loss: 0.0016 - val_mae: 0.0304 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.2958e-04 - mae: 0.0158 - val_loss: 0.0015 - val_mae: 0.0291 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.7702e-04 - mae: 0.0148 - val_loss: 0.0017 - val_mae: 0.0319 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.8459e-04 - mae: 0.0142 - val_loss: 0.0025 - val_mae: 0.0410 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.4186e-04 - mae: 0.0139 - val_loss: 0.0018 - val_mae: 0.0344 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.0258e-04 - mae: 0.0134 - val_loss: 0.0029 - val_mae: 0.0452 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.5085e-04 - mae: 0.0125 - val_loss: 0.0031 - val_mae: 0.0473 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.3726e-04 - mae: 0.0124 - val_loss: 0.0041 - val_mae: 0.0543 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.1865e-04 - mae: 0.0121 - val_loss: 0.0056 - val_mae: 0.0643 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.1642e-04 - mae: 0.0121 - val_loss: 0.0060 - val_mae: 0.0663 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.3653e-04 - mae: 0.0121 - val_loss: 0.0059 - val_mae: 0.0668 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.3163e-04 - mae: 0.0113 - val_loss: 0.0057 - val_mae: 0.0652 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 482us/step - loss: 0.0061 - mae: 0.0586\n",
      "121/121 [==============================] - 0s 538us/step\n",
      "Running model for xmr...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0960 - mae: 0.1345 - val_loss: 0.0020 - val_mae: 0.0347 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0044 - val_mae: 0.0606 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0013 - val_mae: 0.0305 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0206 - val_loss: 3.4039e-04 - val_mae: 0.0144 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.1119e-04 - mae: 0.0193 - val_loss: 2.5515e-04 - val_mae: 0.0125 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.8233e-04 - mae: 0.0180 - val_loss: 3.9016e-04 - val_mae: 0.0160 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.8729e-04 - mae: 0.0171 - val_loss: 2.8667e-04 - val_mae: 0.0132 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.2181e-04 - mae: 0.0163 - val_loss: 2.4446e-04 - val_mae: 0.0122 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.6709e-04 - mae: 0.0156 - val_loss: 4.9302e-04 - val_mae: 0.0174 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.0340e-04 - mae: 0.0146 - val_loss: 0.0022 - val_mae: 0.0405 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.8317e-04 - mae: 0.0143 - val_loss: 0.0024 - val_mae: 0.0427 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.7137e-04 - mae: 0.0142 - val_loss: 0.0011 - val_mae: 0.0254 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.4608e-04 - mae: 0.0139 - val_loss: 0.0022 - val_mae: 0.0382 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.2030e-04 - mae: 0.0134 - val_loss: 0.0032 - val_mae: 0.0453 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.8439e-04 - mae: 0.0128 - val_loss: 0.0050 - val_mae: 0.0588 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7396e-04 - mae: 0.0127 - val_loss: 0.0033 - val_mae: 0.0469 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.6383e-04 - mae: 0.0126 - val_loss: 0.0052 - val_mae: 0.0598 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.5474e-04 - mae: 0.0124 - val_loss: 0.0045 - val_mae: 0.0548 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 470us/step - loss: 0.0023 - mae: 0.0349\n",
      "121/121 [==============================] - 0s 532us/step\n",
      "Running model for xrp...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0985 - mae: 0.1359 - val_loss: 0.0067 - val_mae: 0.0660 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0284 - val_loss: 0.0037 - val_mae: 0.0491 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0229 - val_loss: 0.0024 - val_mae: 0.0378 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0203 - val_loss: 0.0018 - val_mae: 0.0320 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0264 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 9.2799e-04 - val_mae: 0.0225 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.2953e-04 - mae: 0.0175 - val_loss: 5.8359e-04 - val_mae: 0.0167 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.7127e-04 - mae: 0.0170 - val_loss: 4.4201e-04 - val_mae: 0.0134 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.6273e-04 - mae: 0.0168 - val_loss: 4.6943e-04 - val_mae: 0.0139 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.5050e-04 - mae: 0.0158 - val_loss: 6.6125e-04 - val_mae: 0.0194 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.7326e-04 - mae: 0.0150 - val_loss: 5.1544e-04 - val_mae: 0.0163 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.1598e-04 - mae: 0.0144 - val_loss: 5.5801e-04 - val_mae: 0.0178 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.9531e-04 - mae: 0.0143 - val_loss: 3.2311e-04 - val_mae: 0.0113 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.6308e-04 - mae: 0.0140 - val_loss: 3.7907e-04 - val_mae: 0.0126 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9989e-04 - mae: 0.0129 - val_loss: 3.5578e-04 - val_mae: 0.0134 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9889e-04 - mae: 0.0130 - val_loss: 5.0724e-04 - val_mae: 0.0130 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.7781e-04 - mae: 0.0126 - val_loss: 2.7252e-04 - val_mae: 0.0115 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9137e-04 - mae: 0.0126 - val_loss: 3.7633e-04 - val_mae: 0.0124 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.8979e-04 - mae: 0.0109 - val_loss: 2.0587e-04 - val_mae: 0.0094 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7774e-04 - mae: 0.0106 - val_loss: 1.7996e-04 - val_mae: 0.0088 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.6369e-04 - mae: 0.0106 - val_loss: 2.1164e-04 - val_mae: 0.0101 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.5874e-04 - mae: 0.0105 - val_loss: 1.6696e-04 - val_mae: 0.0083 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.4249e-04 - mae: 0.0102 - val_loss: 1.9604e-04 - val_mae: 0.0100 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.5807e-04 - mae: 0.0107 - val_loss: 1.6627e-04 - val_mae: 0.0085 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.1516e-04 - mae: 0.0096 - val_loss: 1.5008e-04 - val_mae: 0.0083 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.1540e-04 - mae: 0.0096 - val_loss: 1.7665e-04 - val_mae: 0.0090 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.0644e-04 - mae: 0.0094 - val_loss: 1.9331e-04 - val_mae: 0.0099 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.0982e-04 - mae: 0.0095 - val_loss: 1.8189e-04 - val_mae: 0.0097 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.0295e-04 - mae: 0.0093 - val_loss: 1.3897e-04 - val_mae: 0.0081 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.8817e-04 - mae: 0.0090 - val_loss: 2.0781e-04 - val_mae: 0.0107 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.8874e-04 - mae: 0.0090 - val_loss: 2.0898e-04 - val_mae: 0.0109 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.8353e-04 - mae: 0.0088 - val_loss: 2.4281e-04 - val_mae: 0.0120 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.8776e-04 - mae: 0.0089 - val_loss: 1.3780e-04 - val_mae: 0.0080 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.8152e-04 - mae: 0.0088 - val_loss: 2.0897e-04 - val_mae: 0.0110 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.7804e-04 - mae: 0.0087 - val_loss: 1.4373e-04 - val_mae: 0.0083 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.7379e-04 - mae: 0.0086 - val_loss: 1.5390e-04 - val_mae: 0.0087 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.7352e-04 - mae: 0.0087 - val_loss: 1.3464e-04 - val_mae: 0.0079 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.7396e-04 - mae: 0.0086 - val_loss: 1.5886e-04 - val_mae: 0.0090 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.7279e-04 - mae: 0.0086 - val_loss: 1.5545e-04 - val_mae: 0.0089 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6772e-04 - mae: 0.0085 - val_loss: 1.7415e-04 - val_mae: 0.0096 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6695e-04 - mae: 0.0084 - val_loss: 1.6244e-04 - val_mae: 0.0091 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6653e-04 - mae: 0.0084 - val_loss: 1.6469e-04 - val_mae: 0.0093 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6679e-04 - mae: 0.0085 - val_loss: 1.4514e-04 - val_mae: 0.0085 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6648e-04 - mae: 0.0084 - val_loss: 1.6420e-04 - val_mae: 0.0093 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6347e-04 - mae: 0.0084 - val_loss: 1.5215e-04 - val_mae: 0.0088 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6330e-04 - mae: 0.0084 - val_loss: 1.6223e-04 - val_mae: 0.0092 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.6353e-04 - mae: 0.0084 - val_loss: 1.6174e-04 - val_mae: 0.0091 - lr: 1.5625e-05\n",
      "121/121 [==============================] - 0s 494us/step - loss: 3.5729e-04 - mae: 0.0142\n",
      "121/121 [==============================] - 0s 549us/step\n",
      "Running model for aave...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 41ms/step - loss: 0.7862 - mae: 0.8093 - val_loss: 0.0543 - val_mae: 0.1903 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6799 - mae: 0.7520 - val_loss: 0.0521 - val_mae: 0.1852 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5697 - mae: 0.6870 - val_loss: 0.0499 - val_mae: 0.1800 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4499 - mae: 0.6063 - val_loss: 0.0481 - val_mae: 0.1738 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3308 - mae: 0.5071 - val_loss: 0.0473 - val_mae: 0.1669 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2323 - mae: 0.3914 - val_loss: 0.0485 - val_mae: 0.1645 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1807 - mae: 0.3369 - val_loss: 0.0538 - val_mae: 0.1745 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1541 - mae: 0.3122 - val_loss: 0.0650 - val_mae: 0.2001 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1242 - mae: 0.2618 - val_loss: 0.0813 - val_mae: 0.2357 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1140 - mae: 0.2413 - val_loss: 0.0948 - val_mae: 0.2593 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1197 - mae: 0.2452 - val_loss: 0.0968 - val_mae: 0.2627 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1168 - mae: 0.2432 - val_loss: 0.0953 - val_mae: 0.2602 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1111 - mae: 0.2368 - val_loss: 0.0921 - val_mae: 0.2550 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1045 - mae: 0.2284 - val_loss: 0.0886 - val_mae: 0.2491 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0998 - mae: 0.2242 - val_loss: 0.0862 - val_mae: 0.2450 - lr: 5.0000e-04\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1749 - mae: 0.4025\n",
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Data Model       MSE       MAE      MAPE\n0   ada  LSTM  0.002148  0.039191  0.172768\n1   btc  LSTM  0.002524  0.036518  0.445379\n2  doge  LSTM  0.002929  0.045230  4.522522\n3   eth  LSTM  0.006070  0.058626  1.239930\n4   xmr  LSTM  0.002264  0.034918  1.462316\n5   xrp  LSTM  0.000357  0.014200  0.600601\n6  aave  LSTM  0.174922  0.402494  0.577823",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Model</th>\n      <th>MSE</th>\n      <th>MAE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ada</td>\n      <td>LSTM</td>\n      <td>0.002148</td>\n      <td>0.039191</td>\n      <td>0.172768</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>btc</td>\n      <td>LSTM</td>\n      <td>0.002524</td>\n      <td>0.036518</td>\n      <td>0.445379</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>doge</td>\n      <td>LSTM</td>\n      <td>0.002929</td>\n      <td>0.045230</td>\n      <td>4.522522</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eth</td>\n      <td>LSTM</td>\n      <td>0.006070</td>\n      <td>0.058626</td>\n      <td>1.239930</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xmr</td>\n      <td>LSTM</td>\n      <td>0.002264</td>\n      <td>0.034918</td>\n      <td>1.462316</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xrp</td>\n      <td>LSTM</td>\n      <td>0.000357</td>\n      <td>0.014200</td>\n      <td>0.600601</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aave</td>\n      <td>LSTM</td>\n      <td>0.174922</td>\n      <td>0.402494</td>\n      <td>0.577823</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.scripts.utils import split_data_frame, apply_functions\n",
    "\n",
    "def run_model_for_dataframe(df):\n",
    "    # Split the DataFrame into train, validation, and test sets\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "\n",
    "    # Apply any additional functions to preprocess the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    # Fit the model\n",
    "    model, history = fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Get the evaluation metrics for each set\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the evaluation metrics along with the model and history\n",
    "    return model, history, (mse, mae, mape)\n",
    "\n",
    "# Assuming crypto_dfs is your dictionary of DataFrames for each crypto\n",
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_model_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    lstm = 'LSTM'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': lstm,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "lstm_df = pd.DataFrame(summary_table)\n",
    "lstm_df.to_csv('../results/lstm.csv')\n",
    "lstm_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T12:55:43.384987Z",
     "start_time": "2024-05-02T12:53:12.162669Z"
    }
   },
   "id": "6e2bfcb35ca11c0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM-CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff103f172728cb9f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras.models import Model as tfkModel\n",
    "\n",
    "def build_improved_LSTM_CNN(input_shape, output_units):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # CNN Layer 1\n",
    "    cnn = tfkl.Conv1D(256, 3, padding='same')(input_layer)  # Increased number of filters and adjusted kernel size\n",
    "    cnn = tfkl.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tfkl.MaxPooling1D(pool_size=2)(cnn)  # Added pool_size\n",
    "\n",
    "    # CNN Layer 2\n",
    "    cnn = tfkl.Conv1D(128, 3, padding='same')(cnn)  # Adjusted number of filters and kernel size\n",
    "    cnn = tfkl.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tfkl.MaxPooling1D(pool_size=2)(cnn)  # Added pool_size\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    lstm = tfkl.LSTM(128, return_sequences=True)(cnn)  # Increased the number of units\n",
    "    lstm = tfkl.Dropout(0.2)(lstm)  # Added dropout for regularization\n",
    "\n",
    "    # LSTM Layer 2\n",
    "    lstm = tfkl.LSTM(128)(lstm)  # Adjusted the number of units\n",
    "    lstm = tfkl.Dropout(0.2)(lstm)  # Added dropout for regularization\n",
    "\n",
    "    # Feature Extractor Layer\n",
    "    dense = tfkl.Dense(64)(lstm)  # Adjusted the number of units\n",
    "    dense = tfkl.LeakyReLU(alpha=0.2)(dense)\n",
    "    dense = tfkl.Dropout(0.2)(dense)  # Added dropout for regularization\n",
    "\n",
    "    # Output layer for regression\n",
    "    output_layer = tfkl.Dense(output_units)(dense)  # No activation for regression output\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfkModel(inputs=input_layer, outputs=output_layer, name='Improved_LSTM_CNN')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T12:55:43.387467Z",
     "start_time": "2024-05-02T12:55:43.387053Z"
    }
   },
   "id": "5b23a37520f60656"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def fit(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_units = 1  # Assuming we want to predict one feature, e.g., close price for one day ahead\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_improved_LSTM_CNN(input_shape, output_units)\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    ).history\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T12:56:35.922410Z",
     "start_time": "2024-05-02T12:56:35.913793Z"
    }
   },
   "id": "5e195f9f3ecc94ee"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T12:56:36.267028Z",
     "start_time": "2024-05-02T12:56:36.254114Z"
    }
   },
   "id": "c5e9f29ef73d30fc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0301 - mae: 0.1050 - val_loss: 0.0047 - val_mae: 0.0604 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0141 - mae: 0.0814 - val_loss: 0.0109 - val_mae: 0.0972 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0124 - mae: 0.0771 - val_loss: 0.0043 - val_mae: 0.0571 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0112 - mae: 0.0743 - val_loss: 0.0054 - val_mae: 0.0654 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0110 - mae: 0.0738 - val_loss: 0.0149 - val_mae: 0.1159 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0108 - mae: 0.0726 - val_loss: 0.0042 - val_mae: 0.0562 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0098 - mae: 0.0688 - val_loss: 0.0058 - val_mae: 0.0682 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0673 - val_loss: 0.0141 - val_mae: 0.1125 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0097 - mae: 0.0686 - val_loss: 0.0117 - val_mae: 0.1003 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0085 - mae: 0.0651 - val_loss: 0.0117 - val_mae: 0.1006 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0655 - val_loss: 0.0094 - val_mae: 0.0874 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0071 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.1220 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0592 - val_loss: 0.0091 - val_mae: 0.0850 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0596 - val_loss: 0.0218 - val_mae: 0.1414 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0587 - val_loss: 0.0114 - val_mae: 0.0987 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0591 - val_loss: 0.0120 - val_mae: 0.1009 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 944us/step - loss: 0.0083 - mae: 0.0819\n",
      "121/121 [==============================] - 0s 958us/step\n",
      "Running model for btc...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0254 - mae: 0.1050 - val_loss: 0.0026 - val_mae: 0.0459 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0129 - mae: 0.0836 - val_loss: 0.0018 - val_mae: 0.0334 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0113 - mae: 0.0789 - val_loss: 6.6270e-04 - val_mae: 0.0208 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0101 - mae: 0.0742 - val_loss: 0.0012 - val_mae: 0.0289 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0096 - mae: 0.0725 - val_loss: 0.0028 - val_mae: 0.0469 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0097 - mae: 0.0724 - val_loss: 0.0029 - val_mae: 0.0371 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0090 - mae: 0.0707 - val_loss: 0.0182 - val_mae: 0.1238 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0086 - mae: 0.0686 - val_loss: 0.0094 - val_mae: 0.0792 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0074 - mae: 0.0640 - val_loss: 0.0060 - val_mae: 0.0656 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0071 - mae: 0.0630 - val_loss: 0.0090 - val_mae: 0.0848 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0633 - val_loss: 0.0104 - val_mae: 0.0786 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0634 - val_loss: 0.0129 - val_mae: 0.0939 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0071 - mae: 0.0628 - val_loss: 0.0108 - val_mae: 0.0734 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 896us/step - loss: 0.0025 - mae: 0.0429\n",
      "121/121 [==============================] - 0s 860us/step\n",
      "Running model for doge...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0326 - mae: 0.1006 - val_loss: 0.0108 - val_mae: 0.0956 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0171 - mae: 0.0827 - val_loss: 0.0019 - val_mae: 0.0345 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0144 - mae: 0.0770 - val_loss: 0.0134 - val_mae: 0.1077 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0136 - mae: 0.0749 - val_loss: 0.0062 - val_mae: 0.0676 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0130 - mae: 0.0746 - val_loss: 0.0031 - val_mae: 0.0446 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0123 - mae: 0.0725 - val_loss: 0.0060 - val_mae: 0.0696 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0118 - mae: 0.0713 - val_loss: 0.0020 - val_mae: 0.0352 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0098 - mae: 0.0641 - val_loss: 0.0015 - val_mae: 0.0317 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0090 - mae: 0.0625 - val_loss: 0.0013 - val_mae: 0.0293 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0619 - val_loss: 0.0047 - val_mae: 0.0584 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0095 - mae: 0.0619 - val_loss: 0.0060 - val_mae: 0.0663 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0621 - val_loss: 0.0048 - val_mae: 0.0593 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0086 - mae: 0.0606 - val_loss: 0.0067 - val_mae: 0.0701 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0084 - mae: 0.0606 - val_loss: 0.0063 - val_mae: 0.0666 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0564 - val_loss: 0.0059 - val_mae: 0.0641 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0074 - mae: 0.0565 - val_loss: 0.0062 - val_mae: 0.0671 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0566 - val_loss: 0.0065 - val_mae: 0.0684 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0075 - mae: 0.0570 - val_loss: 0.0052 - val_mae: 0.0594 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0075 - mae: 0.0563 - val_loss: 0.0051 - val_mae: 0.0592 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 902us/step - loss: 0.0033 - mae: 0.0503\n",
      "121/121 [==============================] - 0s 935us/step\n",
      "Running model for eth...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 6s 5ms/step - loss: 0.0265 - mae: 0.1011 - val_loss: 0.0038 - val_mae: 0.0527 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0122 - mae: 0.0796 - val_loss: 0.0046 - val_mae: 0.0609 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0113 - mae: 0.0760 - val_loss: 0.0012 - val_mae: 0.0277 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0102 - mae: 0.0735 - val_loss: 0.0012 - val_mae: 0.0297 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0100 - mae: 0.0728 - val_loss: 0.0015 - val_mae: 0.0322 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0095 - mae: 0.0712 - val_loss: 0.0028 - val_mae: 0.0448 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0094 - mae: 0.0705 - val_loss: 0.0014 - val_mae: 0.0313 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0090 - mae: 0.0690 - val_loss: 9.2143e-04 - val_mae: 0.0229 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0090 - mae: 0.0692 - val_loss: 8.3224e-04 - val_mae: 0.0235 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0086 - mae: 0.0680 - val_loss: 0.0015 - val_mae: 0.0318 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0084 - mae: 0.0673 - val_loss: 9.2348e-04 - val_mae: 0.0243 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0082 - mae: 0.0660 - val_loss: 0.0024 - val_mae: 0.0452 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0078 - mae: 0.0649 - val_loss: 6.6167e-04 - val_mae: 0.0202 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0078 - mae: 0.0649 - val_loss: 5.9635e-04 - val_mae: 0.0212 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0076 - mae: 0.0636 - val_loss: 0.0024 - val_mae: 0.0455 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0073 - mae: 0.0633 - val_loss: 0.0086 - val_mae: 0.0819 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0073 - mae: 0.0626 - val_loss: 0.0053 - val_mae: 0.0626 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0074 - mae: 0.0629 - val_loss: 0.0036 - val_mae: 0.0518 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0064 - mae: 0.0593 - val_loss: 0.0027 - val_mae: 0.0427 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0064 - mae: 0.0586 - val_loss: 0.0029 - val_mae: 0.0461 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0590 - val_loss: 0.0028 - val_mae: 0.0474 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0063 - mae: 0.0589 - val_loss: 0.0040 - val_mae: 0.0541 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0584 - val_loss: 0.0028 - val_mae: 0.0488 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0568 - val_loss: 0.0035 - val_mae: 0.0523 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 947us/step - loss: 0.0028 - mae: 0.0391\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for xmr...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPooli  (None, 2, 256)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 1, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0303 - mae: 0.1079 - val_loss: 0.0219 - val_mae: 0.1375 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0158 - mae: 0.0877 - val_loss: 0.0091 - val_mae: 0.0861 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0143 - mae: 0.0831 - val_loss: 0.0120 - val_mae: 0.0974 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0130 - mae: 0.0792 - val_loss: 0.0136 - val_mae: 0.1028 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0125 - mae: 0.0779 - val_loss: 0.0143 - val_mae: 0.1078 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0116 - mae: 0.0761 - val_loss: 0.0081 - val_mae: 0.0782 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0116 - mae: 0.0755 - val_loss: 0.0058 - val_mae: 0.0653 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0109 - mae: 0.0735 - val_loss: 0.0143 - val_mae: 0.1074 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0109 - mae: 0.0735 - val_loss: 0.0129 - val_mae: 0.1027 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0103 - mae: 0.0714 - val_loss: 0.0109 - val_mae: 0.0929 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0103 - mae: 0.0714 - val_loss: 0.0065 - val_mae: 0.0709 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0095 - mae: 0.0688 - val_loss: 0.0051 - val_mae: 0.0649 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0098 - mae: 0.0696 - val_loss: 0.0157 - val_mae: 0.1136 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0093 - mae: 0.0681 - val_loss: 0.0166 - val_mae: 0.1183 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0093 - mae: 0.0684 - val_loss: 0.0153 - val_mae: 0.1146 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0090 - mae: 0.0670 - val_loss: 0.0020 - val_mae: 0.0365 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0091 - mae: 0.0670 - val_loss: 0.0029 - val_mae: 0.0425 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0087 - mae: 0.0665 - val_loss: 0.0062 - val_mae: 0.0673 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0091 - mae: 0.0672 - val_loss: 0.0077 - val_mae: 0.0760 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0083 - mae: 0.0647 - val_loss: 0.0481 - val_mae: 0.1954 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0087 - mae: 0.0656 - val_loss: 0.0105 - val_mae: 0.0882 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0075 - mae: 0.0610 - val_loss: 0.0102 - val_mae: 0.0902 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0075 - mae: 0.0611 - val_loss: 0.0127 - val_mae: 0.0981 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0075 - mae: 0.0616 - val_loss: 0.0343 - val_mae: 0.1617 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0073 - mae: 0.0606 - val_loss: 0.0468 - val_mae: 0.1857 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0074 - mae: 0.0608 - val_loss: 0.0427 - val_mae: 0.1771 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0469\n",
      "121/121 [==============================] - 0s 945us/step\n",
      "Running model for xrp...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 2, 256)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 1, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0296 - mae: 0.1073 - val_loss: 0.0013 - val_mae: 0.0278 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0155 - mae: 0.0860 - val_loss: 0.0025 - val_mae: 0.0406 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0145 - mae: 0.0831 - val_loss: 0.0016 - val_mae: 0.0290 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0129 - mae: 0.0787 - val_loss: 0.0055 - val_mae: 0.0565 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0124 - mae: 0.0775 - val_loss: 0.0020 - val_mae: 0.0359 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0117 - mae: 0.0760 - val_loss: 0.0016 - val_mae: 0.0327 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0098 - mae: 0.0684 - val_loss: 0.0029 - val_mae: 0.0381 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0093 - mae: 0.0675 - val_loss: 0.0033 - val_mae: 0.0379 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0091 - mae: 0.0667 - val_loss: 0.0063 - val_mae: 0.0622 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0089 - mae: 0.0657 - val_loss: 0.0024 - val_mae: 0.0307 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0652 - val_loss: 0.0104 - val_mae: 0.0871 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0261\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for aave...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 2, 256)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 1, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 46ms/step - loss: 0.8486 - mae: 0.8413 - val_loss: 0.0666 - val_mae: 0.1991 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2557 - mae: 0.4058 - val_loss: 0.9707 - val_mae: 0.9703 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1186 - mae: 0.2698 - val_loss: 0.3979 - val_mae: 0.6043 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1309 - mae: 0.2804 - val_loss: 0.3481 - val_mae: 0.5639 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0909 - mae: 0.2382 - val_loss: 0.4865 - val_mae: 0.6770 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0819 - mae: 0.2213 - val_loss: 0.3048 - val_mae: 0.5262 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0845 - mae: 0.2190 - val_loss: 0.2612 - val_mae: 0.4825 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0736 - mae: 0.2075 - val_loss: 0.2696 - val_mae: 0.4902 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0746 - mae: 0.2041 - val_loss: 0.2331 - val_mae: 0.4536 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0715 - mae: 0.2063 - val_loss: 0.2481 - val_mae: 0.4704 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0639 - mae: 0.1887 - val_loss: 0.2063 - val_mae: 0.4246 - lr: 5.0000e-04\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2098 - mae: 0.4425\n",
      "1/1 [==============================] - 0s 235ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Data     Model       MSE       MAE      MAPE\n0   ada  LSTM-CNN  0.008317  0.081877  0.273732\n1   btc  LSTM-CNN  0.002513  0.042862  1.711245\n2  doge  LSTM-CNN  0.003258  0.050316  3.299424\n3   eth  LSTM-CNN  0.002848  0.039123  0.391820\n4   xmr  LSTM-CNN  0.003283  0.046871  1.856860\n5   xrp  LSTM-CNN  0.001034  0.026126  1.083019\n6  aave  LSTM-CNN  0.209810  0.442550  0.633619",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Model</th>\n      <th>MSE</th>\n      <th>MAE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ada</td>\n      <td>LSTM-CNN</td>\n      <td>0.008317</td>\n      <td>0.081877</td>\n      <td>0.273732</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>btc</td>\n      <td>LSTM-CNN</td>\n      <td>0.002513</td>\n      <td>0.042862</td>\n      <td>1.711245</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>doge</td>\n      <td>LSTM-CNN</td>\n      <td>0.003258</td>\n      <td>0.050316</td>\n      <td>3.299424</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eth</td>\n      <td>LSTM-CNN</td>\n      <td>0.002848</td>\n      <td>0.039123</td>\n      <td>0.391820</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xmr</td>\n      <td>LSTM-CNN</td>\n      <td>0.003283</td>\n      <td>0.046871</td>\n      <td>1.856860</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xrp</td>\n      <td>LSTM-CNN</td>\n      <td>0.001034</td>\n      <td>0.026126</td>\n      <td>1.083019</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aave</td>\n      <td>LSTM-CNN</td>\n      <td>0.209810</td>\n      <td>0.442550</td>\n      <td>0.633619</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.scripts.utils import split_data_frame, apply_functions\n",
    "\n",
    "def run_model_for_dataframe(df):\n",
    "    # Split the DataFrame into train, validation, and test sets\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "\n",
    "    # Apply any additional functions to preprocess the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    # Fit the model\n",
    "    model, history = fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Get the evaluation metrics for each set\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the evaluation metrics along with the model and history\n",
    "    return model, history, (mse, mae, mape)\n",
    "\n",
    "# Assuming crypto_dfs is your dictionary of DataFrames for each crypto\n",
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_model_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    lstm_cnn = 'LSTM-CNN'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': lstm_cnn,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "lstm_cnn_df = pd.DataFrame(summary_table)\n",
    "lstm_cnn_df.to_csv('../results/lstm_cnn.csv')\n",
    "lstm_cnn_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:02:40.270799Z",
     "start_time": "2024-05-02T12:56:36.725424Z"
    }
   },
   "id": "454d8468ff65d12f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRANSFORMER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8361dbb4b70b0a7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0, epsilon=1e-6, attention_axes=None, kernel_size=1):\n",
    "    \"\"\"\n",
    "    Creates a single transformer block.\n",
    "    \"\"\"\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout,\n",
    "        attention_axes=attention_axes\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=kernel_size, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=kernel_size)(x)\n",
    "    return x + res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:02:40.294801Z",
     "start_time": "2024-05-02T13:02:40.278192Z"
    }
   },
   "id": "f081ecca6372e338"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def build_transfromer(head_size, num_heads, ff_dim, num_trans_blocks, mlp_units, dropout=0, mlp_dropout=0, attention_axes=None, epsilon=1e-6, kernel_size=1):\n",
    "    \"\"\"\n",
    "    Creates final model by building many transformer blocks.\n",
    "    \"\"\"\n",
    "    n_timesteps, n_features, n_outputs = 5, 12, 1\n",
    "    inputs = tf.keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = inputs\n",
    "    for _ in range(num_trans_blocks):\n",
    "        x = transformer_encoder(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout, attention_axes=attention_axes, kernel_size=kernel_size, epsilon=epsilon)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(n_outputs)(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:02:40.295411Z",
     "start_time": "2024-05-02T13:02:40.282276Z"
    }
   },
   "id": "f1ee42a933468fd7"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fit_transformer(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Compiles and fits our transformer with the provided training and validation data.\n",
    "    \"\"\"\n",
    "    transformer = build_transfromer(head_size=128, num_heads=4, ff_dim=2, num_trans_blocks=4, mlp_units=[256], mlp_dropout=0.10, dropout=0.10, attention_axes=1)    \n",
    "    \n",
    "    transformer.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "        metrics=[\"mae\", \"mape\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = transformer.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=64,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    ).history\n",
    "\n",
    "    print(f\"Training completed in {time.time() - start:.2f} seconds\")\n",
    "    return transformer, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:02:40.295499Z",
     "start_time": "2024-05-02T13:02:40.289175Z"
    }
   },
   "id": "5120f9e78fe27e57"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:02:40.321467Z",
     "start_time": "2024-05-02T13:02:40.292242Z"
    }
   },
   "id": "c08ac846ef275f78"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def run_transformer_for_dataframe(df):\n",
    "    \n",
    "    # Preprocessing steps\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    transformer, history = fit_transformer(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the model, history, and metrics\n",
    "    return transformer, history, (mse, mae, mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:02:40.348935Z",
     "start_time": "2024-05-02T13:02:40.295331Z"
    }
   },
   "id": "4b829c25aab5ed3"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 9s 19ms/step - loss: 0.0228 - mae: 0.0875 - mape: 16.6362 - val_loss: 0.0174 - val_mae: 0.1234 - val_mape: 24.3442 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0051 - mae: 0.0525 - mape: 10.4829 - val_loss: 0.0159 - val_mae: 0.1213 - val_mape: 23.9541 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0038 - mae: 0.0446 - mape: 8.1732 - val_loss: 0.0065 - val_mae: 0.0755 - val_mape: 14.8736 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 7s 17ms/step - loss: 0.0029 - mae: 0.0387 - mape: 6.4640 - val_loss: 0.0052 - val_mae: 0.0683 - val_mape: 13.4735 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0027 - mae: 0.0370 - mape: 6.6404 - val_loss: 0.0029 - val_mae: 0.0472 - val_mape: 9.1510 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0023 - mae: 0.0341 - mape: 5.5040 - val_loss: 0.0021 - val_mae: 0.0418 - val_mape: 8.1133 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0345 - mape: 6.2392 - val_loss: 0.0012 - val_mae: 0.0283 - val_mape: 5.3827 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0022 - mae: 0.0332 - mape: 5.9684 - val_loss: 0.0023 - val_mae: 0.0455 - val_mape: 8.9472 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0021 - mae: 0.0320 - mape: 5.4682 - val_loss: 0.0016 - val_mae: 0.0351 - val_mape: 6.9091 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0323 - mape: 5.4581 - val_loss: 0.0033 - val_mae: 0.0544 - val_mape: 10.7843 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0309 - mape: 5.4205 - val_loss: 7.7915e-04 - val_mae: 0.0234 - val_mape: 4.5111 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0314 - mape: 5.3363 - val_loss: 7.4053e-04 - val_mae: 0.0233 - val_mape: 4.5141 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0313 - mape: 5.0076 - val_loss: 1.4875e-04 - val_mae: 0.0100 - val_mape: 2.0230 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0312 - mape: 5.0894 - val_loss: 0.0012 - val_mae: 0.0315 - val_mape: 6.2032 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0309 - mape: 5.3584 - val_loss: 7.0498e-04 - val_mae: 0.0229 - val_mape: 4.4879 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0301 - mape: 5.2297 - val_loss: 2.8530e-04 - val_mae: 0.0145 - val_mape: 2.8301 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0305 - mape: 5.1776 - val_loss: 4.3780e-04 - val_mae: 0.0192 - val_mape: 3.7586 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0302 - mape: 5.3367 - val_loss: 2.9580e-04 - val_mae: 0.0150 - val_mape: 2.8883 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0274 - mape: 4.3138 - val_loss: 3.9703e-04 - val_mae: 0.0183 - val_mape: 3.5976 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0274 - mape: 4.1592 - val_loss: 6.8213e-04 - val_mae: 0.0240 - val_mape: 4.7307 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0278 - mape: 4.2309 - val_loss: 5.3568e-04 - val_mae: 0.0216 - val_mape: 4.2538 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0274 - mape: 4.4157 - val_loss: 8.8082e-05 - val_mae: 0.0077 - val_mape: 1.5867 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0273 - mape: 4.1835 - val_loss: 1.5766e-04 - val_mae: 0.0102 - val_mape: 1.9998 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0264 - mape: 4.1400 - val_loss: 3.6133e-04 - val_mae: 0.0171 - val_mape: 3.3793 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0264 - mape: 4.2203 - val_loss: 5.1850e-05 - val_mae: 0.0057 - val_mape: 1.1541 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0263 - mape: 4.0535 - val_loss: 4.6445e-05 - val_mae: 0.0053 - val_mape: 1.0678 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0262 - mape: 4.4251 - val_loss: 6.1361e-05 - val_mae: 0.0060 - val_mape: 1.1818 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0264 - mape: 4.4520 - val_loss: 8.5665e-05 - val_mae: 0.0074 - val_mape: 1.4480 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0260 - mape: 4.1486 - val_loss: 2.9428e-04 - val_mae: 0.0156 - val_mape: 3.0951 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0259 - mape: 4.0709 - val_loss: 6.6144e-05 - val_mae: 0.0064 - val_mape: 1.2598 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0262 - mape: 4.0882 - val_loss: 3.3460e-05 - val_mae: 0.0042 - val_mape: 0.8513 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0255 - mape: 4.1073 - val_loss: 5.9368e-05 - val_mae: 0.0061 - val_mape: 1.2194 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0258 - mape: 3.9450 - val_loss: 1.0178e-04 - val_mae: 0.0083 - val_mape: 1.6259 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0252 - mape: 3.8946 - val_loss: 2.8778e-04 - val_mae: 0.0152 - val_mape: 2.9797 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0255 - mape: 3.9613 - val_loss: 1.6889e-04 - val_mae: 0.0109 - val_mape: 2.1209 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0255 - mape: 4.0582 - val_loss: 1.2287e-04 - val_mae: 0.0088 - val_mape: 1.7071 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0250 - mape: 4.0324 - val_loss: 8.6025e-05 - val_mae: 0.0073 - val_mape: 1.4400 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0250 - mape: 3.9628 - val_loss: 6.3820e-05 - val_mae: 0.0059 - val_mape: 1.1477 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0249 - mape: 3.9625 - val_loss: 6.9778e-05 - val_mae: 0.0064 - val_mape: 1.2494 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0013 - mae: 0.0249 - mape: 4.0504 - val_loss: 1.2318e-04 - val_mae: 0.0095 - val_mape: 1.8411 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0013 - mae: 0.0249 - mape: 3.9928 - val_loss: 9.6524e-05 - val_mae: 0.0082 - val_mape: 1.6031 - lr: 6.2500e-05\n",
      "Training completed in 327.75 seconds\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3593 - mae: 0.5818\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for btc...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 9s 19ms/step - loss: 0.0171 - mae: 0.0800 - mape: 28.4025 - val_loss: 0.0320 - val_mae: 0.1715 - val_mape: 579.9918 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0044 - mae: 0.0508 - mape: 16.4742 - val_loss: 0.0128 - val_mae: 0.1089 - val_mape: 343.9909 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0029 - mae: 0.0408 - mape: 7.6146 - val_loss: 0.0021 - val_mae: 0.0417 - val_mape: 134.9325 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0374 - mape: 7.9632 - val_loss: 9.8510e-04 - val_mae: 0.0264 - val_mape: 96.3050 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0022 - mae: 0.0353 - mape: 8.7485 - val_loss: 5.5104e-04 - val_mae: 0.0195 - val_mape: 73.4611 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0341 - mape: 6.9796 - val_loss: 0.0017 - val_mae: 0.0388 - val_mape: 126.7433 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0333 - mape: 9.7397 - val_loss: 8.8171e-04 - val_mae: 0.0262 - val_mape: 83.3866 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0018 - mae: 0.0323 - mape: 10.8888 - val_loss: 6.3853e-04 - val_mae: 0.0203 - val_mape: 62.6677 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0019 - mae: 0.0329 - mape: 9.2995 - val_loss: 0.0031 - val_mae: 0.0522 - val_mape: 178.4947 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0319 - mape: 9.4503 - val_loss: 4.4766e-04 - val_mae: 0.0173 - val_mape: 53.3328 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0317 - mape: 9.8112 - val_loss: 1.6112e-04 - val_mae: 0.0095 - val_mape: 20.3638 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0314 - mape: 9.8968 - val_loss: 2.2907e-04 - val_mae: 0.0114 - val_mape: 26.3653 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0312 - mape: 10.1093 - val_loss: 4.7477e-04 - val_mae: 0.0172 - val_mape: 49.6373 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0304 - mape: 9.2632 - val_loss: 2.3996e-04 - val_mae: 0.0125 - val_mape: 33.6522 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0307 - mape: 9.6786 - val_loss: 4.5482e-04 - val_mae: 0.0178 - val_mape: 37.5640 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0302 - mape: 10.1348 - val_loss: 2.9494e-04 - val_mae: 0.0145 - val_mape: 42.7927 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0284 - mape: 8.9183 - val_loss: 2.9973e-04 - val_mae: 0.0139 - val_mape: 44.8253 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0279 - mape: 8.8970 - val_loss: 1.3923e-04 - val_mae: 0.0090 - val_mape: 26.2275 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0285 - mape: 9.2237 - val_loss: 2.5836e-04 - val_mae: 0.0129 - val_mape: 28.5061 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0286 - mape: 9.0599 - val_loss: 3.3233e-04 - val_mae: 0.0145 - val_mape: 37.3149 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0282 - mape: 7.3504 - val_loss: 3.3161e-04 - val_mae: 0.0155 - val_mape: 40.0274 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0013 - mae: 0.0271 - mape: 8.7183 - val_loss: 3.9196e-04 - val_mae: 0.0174 - val_mape: 54.0538 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0270 - mape: 7.0548 - val_loss: 4.4807e-04 - val_mae: 0.0180 - val_mape: 58.9173 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0013 - mae: 0.0270 - mape: 9.0870 - val_loss: 3.4205e-04 - val_mae: 0.0162 - val_mape: 49.8028 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0013 - mae: 0.0267 - mape: 7.3702 - val_loss: 3.4676e-04 - val_mae: 0.0157 - val_mape: 45.2058 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0013 - mae: 0.0266 - mape: 8.7051 - val_loss: 1.3105e-04 - val_mae: 0.0085 - val_mape: 20.6976 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0013 - mae: 0.0262 - mape: 8.1510 - val_loss: 1.6406e-04 - val_mae: 0.0097 - val_mape: 24.2009 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0259 - mape: 7.5710 - val_loss: 1.7699e-04 - val_mae: 0.0104 - val_mape: 28.3544 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0013 - mae: 0.0262 - mape: 7.8820 - val_loss: 2.5966e-04 - val_mae: 0.0131 - val_mape: 37.9699 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0259 - mape: 7.1317 - val_loss: 1.3083e-04 - val_mae: 0.0085 - val_mape: 23.4209 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0012 - mae: 0.0261 - mape: 6.4515 - val_loss: 1.3985e-04 - val_mae: 0.0086 - val_mape: 23.2142 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0012 - mae: 0.0257 - mape: 7.5931 - val_loss: 1.8847e-04 - val_mae: 0.0108 - val_mape: 34.0366 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.4783 - val_loss: 1.7278e-04 - val_mae: 0.0099 - val_mape: 28.2141 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0012 - mae: 0.0257 - mape: 7.0458 - val_loss: 1.5410e-04 - val_mae: 0.0090 - val_mape: 24.3807 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0012 - mae: 0.0252 - mape: 6.4168 - val_loss: 2.0415e-04 - val_mae: 0.0114 - val_mape: 32.0289 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.7959 - val_loss: 1.2258e-04 - val_mae: 0.0077 - val_mape: 18.9118 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.5634 - val_loss: 1.4431e-04 - val_mae: 0.0087 - val_mape: 24.8869 - lr: 3.1250e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0252 - mape: 8.4798 - val_loss: 1.6859e-04 - val_mae: 0.0098 - val_mape: 29.6730 - lr: 3.1250e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0253 - mape: 6.7816 - val_loss: 1.2213e-04 - val_mae: 0.0078 - val_mape: 20.0074 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.1893 - val_loss: 1.3269e-04 - val_mae: 0.0084 - val_mape: 24.2341 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0012 - mae: 0.0250 - mape: 6.9975 - val_loss: 1.4421e-04 - val_mae: 0.0091 - val_mape: 27.6175 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0011 - mae: 0.0249 - mape: 7.5610 - val_loss: 1.2270e-04 - val_mae: 0.0079 - val_mape: 21.6562 - lr: 1.5625e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.6744 - val_loss: 1.4053e-04 - val_mae: 0.0087 - val_mape: 24.1257 - lr: 1.5625e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0251 - mape: 7.2592 - val_loss: 1.3006e-04 - val_mae: 0.0084 - val_mape: 23.4877 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0012 - mae: 0.0250 - mape: 7.4032 - val_loss: 1.2720e-04 - val_mae: 0.0080 - val_mape: 21.4678 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0251 - mape: 6.9879 - val_loss: 1.0929e-04 - val_mae: 0.0074 - val_mape: 19.4364 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.2726 - val_loss: 1.2427e-04 - val_mae: 0.0080 - val_mape: 21.4870 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0011 - mae: 0.0248 - mape: 6.7216 - val_loss: 1.2848e-04 - val_mae: 0.0082 - val_mape: 23.3759 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0011 - mae: 0.0249 - mape: 6.8702 - val_loss: 1.1348e-04 - val_mae: 0.0076 - val_mape: 21.2738 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0011 - mae: 0.0249 - mape: 7.7582 - val_loss: 1.2991e-04 - val_mae: 0.0083 - val_mape: 24.0526 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0251 - mape: 5.7393 - val_loss: 1.2792e-04 - val_mae: 0.0081 - val_mape: 23.4289 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.2545 - val_loss: 1.1781e-04 - val_mae: 0.0078 - val_mape: 22.1758 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0012 - mae: 0.0250 - mape: 6.9654 - val_loss: 1.2387e-04 - val_mae: 0.0081 - val_mape: 22.7126 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0011 - mae: 0.0249 - mape: 6.4254 - val_loss: 1.2982e-04 - val_mae: 0.0084 - val_mape: 23.6238 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0011 - mae: 0.0249 - mape: 6.3204 - val_loss: 1.0828e-04 - val_mae: 0.0075 - val_mape: 19.2191 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0011 - mae: 0.0249 - mape: 7.0127 - val_loss: 1.1320e-04 - val_mae: 0.0076 - val_mape: 21.3313 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0011 - mae: 0.0250 - mape: 7.3055 - val_loss: 1.2595e-04 - val_mae: 0.0082 - val_mape: 25.1467 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0011 - mae: 0.0247 - mape: 6.4824 - val_loss: 1.0264e-04 - val_mae: 0.0071 - val_mape: 19.0785 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0011 - mae: 0.0249 - mape: 6.3457 - val_loss: 1.1171e-04 - val_mae: 0.0075 - val_mape: 20.5333 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0011 - mae: 0.0248 - mape: 7.9551 - val_loss: 1.2283e-04 - val_mae: 0.0079 - val_mape: 22.1069 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0011 - mae: 0.0249 - mape: 6.7816 - val_loss: 1.0997e-04 - val_mae: 0.0075 - val_mape: 20.8854 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0011 - mae: 0.0247 - mape: 7.4393 - val_loss: 1.2503e-04 - val_mae: 0.0081 - val_mape: 23.5233 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0250 - mape: 7.4772 - val_loss: 1.0859e-04 - val_mae: 0.0075 - val_mape: 19.0309 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0011 - mae: 0.0248 - mape: 7.1308 - val_loss: 1.3972e-04 - val_mae: 0.0086 - val_mape: 24.2757 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0011 - mae: 0.0248 - mape: 9.1178 - val_loss: 1.1884e-04 - val_mae: 0.0078 - val_mape: 22.4291 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0251 - mape: 6.3472 - val_loss: 1.3763e-04 - val_mae: 0.0085 - val_mape: 23.9804 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0250 - mape: 7.0861 - val_loss: 1.6290e-04 - val_mae: 0.0098 - val_mape: 27.9294 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0011 - mae: 0.0248 - mape: 6.6812 - val_loss: 1.3859e-04 - val_mae: 0.0086 - val_mape: 24.4548 - lr: 1.0000e-05\n",
      "Training completed in 580.24 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 2.4893e-04 - mae: 0.0107 - mape: 15.4965\n",
      "121/121 [==============================] - 1s 3ms/step\n",
      "Running model for doge...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 21ms/step - loss: 0.0844 - mae: 0.1817 - mape: 38.6079 - val_loss: 0.0569 - val_mae: 0.2193 - val_mape: 562.6036 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0213 - mae: 0.1051 - mape: 26.2624 - val_loss: 0.0580 - val_mae: 0.2239 - val_mape: 590.3561 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0167 - mae: 0.0913 - mape: 25.7277 - val_loss: 0.0749 - val_mae: 0.2605 - val_mape: 693.1025 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0136 - mae: 0.0795 - mape: 22.5100 - val_loss: 0.0581 - val_mae: 0.2271 - val_mape: 617.9596 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0124 - mae: 0.0754 - mape: 16.2724 - val_loss: 0.0566 - val_mae: 0.2248 - val_mape: 626.9497 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0110 - mae: 0.0702 - mape: 16.2887 - val_loss: 0.0347 - val_mae: 0.1700 - val_mape: 493.7255 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0101 - mae: 0.0674 - mape: 16.2252 - val_loss: 0.0351 - val_mae: 0.1724 - val_mape: 518.2598 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0101 - mae: 0.0678 - mape: 15.0777 - val_loss: 0.0348 - val_mae: 0.1710 - val_mape: 525.4964 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0087 - mae: 0.0628 - mape: 17.6395 - val_loss: 0.0422 - val_mae: 0.1905 - val_mape: 574.0766 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0086 - mae: 0.0612 - mape: 16.2847 - val_loss: 0.0349 - val_mae: 0.1718 - val_mape: 533.7957 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0082 - mae: 0.0600 - mape: 14.2907 - val_loss: 0.0322 - val_mae: 0.1610 - val_mape: 515.4425 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0072 - mae: 0.0555 - mape: 16.8059 - val_loss: 0.0452 - val_mae: 0.1983 - val_mape: 603.0173 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0077 - mae: 0.0586 - mape: 15.6181 - val_loss: 0.0401 - val_mae: 0.1864 - val_mape: 571.5742 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0071 - mae: 0.0561 - mape: 13.9864 - val_loss: 0.0308 - val_mae: 0.1588 - val_mape: 517.5952 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0072 - mae: 0.0560 - mape: 15.3110 - val_loss: 0.0358 - val_mae: 0.1735 - val_mape: 546.9294 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0067 - mae: 0.0536 - mape: 13.8506 - val_loss: 0.0292 - val_mae: 0.1567 - val_mape: 509.3683 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0064 - mae: 0.0529 - mape: 13.0210 - val_loss: 0.0333 - val_mae: 0.1688 - val_mape: 538.1091 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0065 - mae: 0.0540 - mape: 12.4560 - val_loss: 0.0354 - val_mae: 0.1743 - val_mape: 555.5684 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0061 - mae: 0.0518 - mape: 12.8371 - val_loss: 0.0301 - val_mae: 0.1543 - val_mape: 501.1729 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0061 - mae: 0.0511 - mape: 12.4353 - val_loss: 0.0338 - val_mae: 0.1684 - val_mape: 540.5025 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0056 - mae: 0.0495 - mape: 12.4443 - val_loss: 0.0236 - val_mae: 0.1396 - val_mape: 476.9715 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0063 - mae: 0.0526 - mape: 14.6882 - val_loss: 0.0275 - val_mae: 0.1492 - val_mape: 496.6748 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0056 - mae: 0.0493 - mape: 13.3503 - val_loss: 0.0304 - val_mae: 0.1583 - val_mape: 522.5499 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0057 - mae: 0.0497 - mape: 17.5655 - val_loss: 0.0330 - val_mae: 0.1670 - val_mape: 544.3865 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0053 - mae: 0.0476 - mape: 11.8133 - val_loss: 0.0301 - val_mae: 0.1588 - val_mape: 523.1748 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0052 - mae: 0.0479 - mape: 14.6193 - val_loss: 0.0331 - val_mae: 0.1650 - val_mape: 540.7488 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0042 - mae: 0.0428 - mape: 10.9382 - val_loss: 0.0374 - val_mae: 0.1791 - val_mape: 576.2242 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0043 - mae: 0.0425 - mape: 9.8744 - val_loss: 0.0299 - val_mae: 0.1595 - val_mape: 533.7073 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0043 - mae: 0.0431 - mape: 9.1042 - val_loss: 0.0304 - val_mae: 0.1589 - val_mape: 526.1577 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0040 - mae: 0.0419 - mape: 10.6071 - val_loss: 0.0320 - val_mae: 0.1632 - val_mape: 543.2599 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0044 - mae: 0.0437 - mape: 11.1294 - val_loss: 0.0367 - val_mae: 0.1771 - val_mape: 580.1584 - lr: 5.0000e-04\n",
      "Training completed in 261.65 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0261 - mape: 97.1763\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for eth...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 11s 23ms/step - loss: 0.0323 - mae: 0.0971 - mape: 63.3709 - val_loss: 0.0119 - val_mae: 0.0973 - val_mape: 522.6586 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0058 - mae: 0.0540 - mape: 26.7104 - val_loss: 0.0074 - val_mae: 0.0757 - val_mape: 387.8466 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0035 - mae: 0.0433 - mape: 22.1447 - val_loss: 0.0059 - val_mae: 0.0694 - val_mape: 348.9228 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0029 - mae: 0.0398 - mape: 20.0626 - val_loss: 0.0017 - val_mae: 0.0354 - val_mape: 225.4866 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0026 - mae: 0.0372 - mape: 16.8596 - val_loss: 0.0012 - val_mae: 0.0300 - val_mape: 221.8115 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0024 - mae: 0.0360 - mape: 20.6262 - val_loss: 9.0785e-04 - val_mae: 0.0243 - val_mape: 158.0270 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0024 - mae: 0.0357 - mape: 19.2534 - val_loss: 0.0020 - val_mae: 0.0400 - val_mape: 257.7965 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0024 - mae: 0.0352 - mape: 18.2450 - val_loss: 8.2980e-04 - val_mae: 0.0255 - val_mape: 162.6784 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0025 - mae: 0.0350 - mape: 18.7146 - val_loss: 0.0017 - val_mae: 0.0359 - val_mape: 223.0743 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0023 - mae: 0.0338 - mape: 17.0325 - val_loss: 7.5809e-04 - val_mae: 0.0219 - val_mape: 156.6312 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0022 - mae: 0.0331 - mape: 16.2468 - val_loss: 0.0013 - val_mae: 0.0320 - val_mape: 203.5094 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0021 - mae: 0.0328 - mape: 15.2436 - val_loss: 5.4891e-04 - val_mae: 0.0199 - val_mape: 135.7694 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0020 - mae: 0.0321 - mape: 16.4086 - val_loss: 2.6950e-04 - val_mae: 0.0130 - val_mape: 83.8280 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0022 - mae: 0.0334 - mape: 14.6623 - val_loss: 0.0013 - val_mae: 0.0335 - val_mape: 195.1375 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0020 - mae: 0.0321 - mape: 15.3578 - val_loss: 8.9295e-04 - val_mae: 0.0269 - val_mape: 167.1274 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0020 - mae: 0.0313 - mape: 13.4005 - val_loss: 2.5036e-04 - val_mae: 0.0128 - val_mape: 83.0322 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0306 - mape: 13.6841 - val_loss: 2.2847e-04 - val_mae: 0.0123 - val_mape: 90.8921 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0019 - mae: 0.0315 - mape: 15.6342 - val_loss: 1.4671e-04 - val_mae: 0.0091 - val_mape: 56.9336 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0306 - mape: 13.5204 - val_loss: 5.6488e-04 - val_mae: 0.0215 - val_mape: 134.4086 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0019 - mae: 0.0309 - mape: 13.5100 - val_loss: 1.5210e-04 - val_mae: 0.0094 - val_mape: 57.8013 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0305 - mape: 12.9883 - val_loss: 2.3522e-04 - val_mae: 0.0119 - val_mape: 32.3434 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0017 - mae: 0.0296 - mape: 12.0456 - val_loss: 1.8733e-04 - val_mae: 0.0110 - val_mape: 67.3678 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0017 - mae: 0.0298 - mape: 11.8342 - val_loss: 1.3895e-04 - val_mae: 0.0086 - val_mape: 56.6097 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0284 - mape: 12.2026 - val_loss: 9.6556e-05 - val_mae: 0.0071 - val_mape: 36.9083 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0284 - mape: 11.5631 - val_loss: 1.5359e-04 - val_mae: 0.0095 - val_mape: 27.4608 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0282 - mape: 12.0672 - val_loss: 2.6301e-04 - val_mae: 0.0132 - val_mape: 91.9324 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0286 - mape: 12.1220 - val_loss: 1.7437e-04 - val_mae: 0.0106 - val_mape: 65.8054 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0016 - mae: 0.0285 - mape: 13.0441 - val_loss: 1.0827e-04 - val_mae: 0.0075 - val_mape: 29.6377 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0015 - mae: 0.0274 - mape: 12.1773 - val_loss: 7.6596e-05 - val_mae: 0.0058 - val_mape: 24.8739 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0272 - mape: 11.5388 - val_loss: 1.2541e-04 - val_mae: 0.0086 - val_mape: 53.4435 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0269 - mape: 11.8874 - val_loss: 1.0697e-04 - val_mae: 0.0075 - val_mape: 42.8757 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0270 - mape: 11.3623 - val_loss: 1.1627e-04 - val_mae: 0.0082 - val_mape: 44.7624 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0271 - mape: 9.5475 - val_loss: 9.4586e-05 - val_mae: 0.0070 - val_mape: 25.1758 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0265 - mape: 10.2604 - val_loss: 9.2994e-05 - val_mae: 0.0070 - val_mape: 24.8156 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0265 - mape: 10.5034 - val_loss: 8.8215e-05 - val_mae: 0.0068 - val_mape: 40.5271 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0266 - mape: 11.4461 - val_loss: 8.4786e-05 - val_mae: 0.0063 - val_mape: 25.0244 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0265 - mape: 9.6044 - val_loss: 1.0685e-04 - val_mae: 0.0076 - val_mape: 30.8077 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0014 - mae: 0.0267 - mape: 10.5420 - val_loss: 7.6064e-05 - val_mae: 0.0061 - val_mape: 32.9913 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0264 - mape: 10.6578 - val_loss: 8.4188e-05 - val_mae: 0.0065 - val_mape: 29.2542 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0263 - mape: 10.5149 - val_loss: 9.8012e-05 - val_mae: 0.0072 - val_mape: 26.3975 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0263 - mape: 10.6444 - val_loss: 8.5552e-05 - val_mae: 0.0067 - val_mape: 31.7858 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0264 - mape: 10.0160 - val_loss: 9.5884e-05 - val_mae: 0.0072 - val_mape: 43.7215 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0262 - mape: 10.5375 - val_loss: 1.2525e-04 - val_mae: 0.0085 - val_mape: 29.0418 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0014 - mae: 0.0261 - mape: 10.9045 - val_loss: 7.9009e-05 - val_mae: 0.0061 - val_mape: 28.5690 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0013 - mae: 0.0259 - mape: 9.8238 - val_loss: 8.0208e-05 - val_mae: 0.0061 - val_mape: 25.9811 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0013 - mae: 0.0262 - mape: 10.1480 - val_loss: 1.1122e-04 - val_mae: 0.0078 - val_mape: 24.6684 - lr: 3.1250e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0014 - mae: 0.0262 - mape: 10.4959 - val_loss: 7.1606e-05 - val_mae: 0.0057 - val_mape: 25.9143 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0013 - mae: 0.0259 - mape: 11.0852 - val_loss: 7.6665e-05 - val_mae: 0.0060 - val_mape: 26.3654 - lr: 3.1250e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0013 - mae: 0.0259 - mape: 10.0380 - val_loss: 7.6625e-05 - val_mae: 0.0061 - val_mape: 31.4339 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0013 - mae: 0.0260 - mape: 9.3842 - val_loss: 7.4400e-05 - val_mae: 0.0060 - val_mape: 28.4209 - lr: 1.5625e-05\n",
      "Epoch 51/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0013 - mae: 0.0258 - mape: 10.8234 - val_loss: 8.8114e-05 - val_mae: 0.0067 - val_mape: 23.7610 - lr: 1.5625e-05\n",
      "Epoch 52/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0013 - mae: 0.0260 - mape: 10.3690 - val_loss: 8.6514e-05 - val_mae: 0.0065 - val_mape: 24.6336 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0013 - mae: 0.0256 - mape: 9.0799 - val_loss: 8.8300e-05 - val_mae: 0.0066 - val_mape: 24.8121 - lr: 1.5625e-05\n",
      "Epoch 54/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0013 - mae: 0.0259 - mape: 10.8943 - val_loss: 8.6381e-05 - val_mae: 0.0065 - val_mape: 24.1981 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0013 - mae: 0.0258 - mape: 10.2202 - val_loss: 7.8557e-05 - val_mae: 0.0062 - val_mape: 27.1376 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "423/423 [==============================] - 11s 25ms/step - loss: 0.0013 - mae: 0.0259 - mape: 8.8515 - val_loss: 7.4308e-05 - val_mae: 0.0059 - val_mape: 27.3977 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0013 - mae: 0.0259 - mape: 10.0794 - val_loss: 7.3247e-05 - val_mae: 0.0058 - val_mape: 26.6739 - lr: 1.0000e-05\n",
      "Training completed in 522.22 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4196 - mae: 0.6082 - mape: 1335.4856\n",
      "121/121 [==============================] - 1s 4ms/step\n",
      "Running model for xmr...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 22ms/step - loss: 0.1050 - mae: 0.2179 - mape: 221.5905 - val_loss: 0.0646 - val_mae: 0.2213 - val_mape: 9287.7803 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0246 - mae: 0.1200 - mape: 117.9668 - val_loss: 0.0791 - val_mae: 0.2455 - val_mape: 10458.3848 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0159 - mae: 0.0958 - mape: 79.9869 - val_loss: 0.0386 - val_mae: 0.1620 - val_mape: 8284.1387 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0133 - mae: 0.0873 - mape: 63.5653 - val_loss: 0.0508 - val_mae: 0.1899 - val_mape: 10211.7588 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0108 - mae: 0.0777 - mape: 74.1191 - val_loss: 0.0620 - val_mae: 0.2121 - val_mape: 11566.5000 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0098 - mae: 0.0744 - mape: 63.0147 - val_loss: 0.0534 - val_mae: 0.1939 - val_mape: 11237.3418 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0093 - mae: 0.0726 - mape: 86.4748 - val_loss: 0.0483 - val_mae: 0.1888 - val_mape: 11317.8018 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0089 - mae: 0.0708 - mape: 61.9335 - val_loss: 0.0354 - val_mae: 0.1517 - val_mape: 9486.5664 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0082 - mae: 0.0675 - mape: 57.5188 - val_loss: 0.0257 - val_mae: 0.1301 - val_mape: 7695.0903 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0077 - mae: 0.0652 - mape: 58.5329 - val_loss: 0.0263 - val_mae: 0.1312 - val_mape: 8167.1094 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0080 - mae: 0.0671 - mape: 77.7130 - val_loss: 0.0356 - val_mae: 0.1598 - val_mape: 9721.3379 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0073 - mae: 0.0633 - mape: 53.3599 - val_loss: 0.0157 - val_mae: 0.0994 - val_mape: 6406.7534 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0075 - mae: 0.0643 - mape: 65.3593 - val_loss: 0.0258 - val_mae: 0.1351 - val_mape: 8518.3359 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0077 - mae: 0.0649 - mape: 62.2569 - val_loss: 0.0227 - val_mae: 0.1234 - val_mape: 7496.2412 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0070 - mae: 0.0616 - mape: 88.9151 - val_loss: 0.0209 - val_mae: 0.1163 - val_mape: 7064.9424 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0069 - mae: 0.0621 - mape: 67.4195 - val_loss: 0.0221 - val_mae: 0.1203 - val_mape: 8294.0137 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0067 - mae: 0.0614 - mape: 65.3408 - val_loss: 0.0250 - val_mae: 0.1240 - val_mape: 9046.4736 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0053 - mae: 0.0537 - mape: 54.8555 - val_loss: 0.0090 - val_mae: 0.0801 - val_mape: 4451.0381 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0052 - mae: 0.0534 - mape: 50.8118 - val_loss: 0.0119 - val_mae: 0.0864 - val_mape: 5803.0991 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0052 - mae: 0.0533 - mape: 61.8742 - val_loss: 0.0154 - val_mae: 0.0985 - val_mape: 6948.0161 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0052 - mae: 0.0535 - mape: 50.3821 - val_loss: 0.0106 - val_mae: 0.0854 - val_mape: 5528.5845 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0051 - mae: 0.0529 - mape: 49.8978 - val_loss: 0.0222 - val_mae: 0.1193 - val_mape: 8693.8291 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0049 - mae: 0.0519 - mape: 46.1268 - val_loss: 0.0128 - val_mae: 0.0897 - val_mape: 6130.7749 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0043 - mae: 0.0482 - mape: 51.5031 - val_loss: 0.0169 - val_mae: 0.1034 - val_mape: 7189.9478 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0042 - mae: 0.0476 - mape: 41.1936 - val_loss: 0.0218 - val_mae: 0.1210 - val_mape: 8413.2598 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0043 - mae: 0.0480 - mape: 36.5459 - val_loss: 0.0147 - val_mae: 0.0965 - val_mape: 6771.6196 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0042 - mae: 0.0480 - mape: 50.4239 - val_loss: 0.0095 - val_mae: 0.0779 - val_mape: 5331.9727 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0042 - mae: 0.0476 - mape: 40.1508 - val_loss: 0.0146 - val_mae: 0.0962 - val_mape: 7163.2354 - lr: 2.5000e-04\n",
      "Training completed in 232.75 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 3.2649e-04 - mae: 0.0125 - mape: 72.4192\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for xrp...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0213 - mae: 0.0859 - mape: 27.7582 - val_loss: 0.0221 - val_mae: 0.1393 - val_mape: 379.4111 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0057 - mae: 0.0534 - mape: 15.5338 - val_loss: 0.0056 - val_mae: 0.0662 - val_mape: 160.8264 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0044 - mae: 0.0467 - mape: 13.9244 - val_loss: 0.0039 - val_mae: 0.0533 - val_mape: 131.1137 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0036 - mae: 0.0424 - mape: 14.8793 - val_loss: 0.0045 - val_mae: 0.0576 - val_mape: 156.0070 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0032 - mae: 0.0394 - mape: 11.9404 - val_loss: 0.0016 - val_mae: 0.0330 - val_mape: 83.0131 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0031 - mae: 0.0390 - mape: 13.0764 - val_loss: 0.0010 - val_mae: 0.0243 - val_mape: 29.7659 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0029 - mae: 0.0371 - mape: 11.3474 - val_loss: 0.0021 - val_mae: 0.0397 - val_mape: 114.5565 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0029 - mae: 0.0372 - mape: 12.1933 - val_loss: 0.0025 - val_mae: 0.0425 - val_mape: 116.5010 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0028 - mae: 0.0359 - mape: 10.6773 - val_loss: 0.0022 - val_mae: 0.0404 - val_mape: 108.7688 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0027 - mae: 0.0356 - mape: 10.8828 - val_loss: 5.2591e-04 - val_mae: 0.0161 - val_mape: 35.6029 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0025 - mae: 0.0339 - mape: 10.1616 - val_loss: 0.0016 - val_mae: 0.0349 - val_mape: 82.4627 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0025 - mae: 0.0338 - mape: 10.9081 - val_loss: 3.9350e-04 - val_mae: 0.0123 - val_mape: 18.9490 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0025 - mae: 0.0334 - mape: 9.7166 - val_loss: 3.5518e-04 - val_mae: 0.0114 - val_mape: 21.6611 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0023 - mae: 0.0326 - mape: 9.2207 - val_loss: 3.9278e-04 - val_mae: 0.0128 - val_mape: 40.3243 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0023 - mae: 0.0323 - mape: 9.2832 - val_loss: 5.1920e-04 - val_mae: 0.0168 - val_mape: 29.1662 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0023 - mae: 0.0328 - mape: 9.4624 - val_loss: 3.1982e-04 - val_mae: 0.0109 - val_mape: 20.3602 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0022 - mae: 0.0318 - mape: 9.0068 - val_loss: 3.4687e-04 - val_mae: 0.0113 - val_mape: 22.9902 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0019 - mae: 0.0293 - mape: 8.1885 - val_loss: 2.4906e-04 - val_mae: 0.0083 - val_mape: 14.1255 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0019 - mae: 0.0294 - mape: 8.3863 - val_loss: 4.9457e-04 - val_mae: 0.0166 - val_mape: 42.2988 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0019 - mae: 0.0290 - mape: 7.9664 - val_loss: 4.3796e-04 - val_mae: 0.0156 - val_mape: 43.2040 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0290 - mape: 8.6644 - val_loss: 2.8538e-04 - val_mae: 0.0103 - val_mape: 23.9631 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0293 - mape: 8.5099 - val_loss: 2.2097e-04 - val_mae: 0.0072 - val_mape: 14.1866 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0019 - mae: 0.0293 - mape: 8.3145 - val_loss: 2.9024e-04 - val_mae: 0.0107 - val_mape: 19.6844 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0280 - mape: 8.0641 - val_loss: 3.4270e-04 - val_mae: 0.0133 - val_mape: 28.7507 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0017 - mae: 0.0276 - mape: 7.7227 - val_loss: 2.6621e-04 - val_mae: 0.0096 - val_mape: 13.8726 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0277 - mape: 7.6110 - val_loss: 3.9420e-04 - val_mae: 0.0147 - val_mape: 37.2155 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0277 - mape: 8.6867 - val_loss: 2.1931e-04 - val_mae: 0.0078 - val_mape: 13.7876 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0273 - mape: 7.8302 - val_loss: 2.5516e-04 - val_mae: 0.0095 - val_mape: 19.5949 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0266 - mape: 7.5005 - val_loss: 2.1863e-04 - val_mae: 0.0083 - val_mape: 18.5497 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0265 - mape: 7.5780 - val_loss: 2.1115e-04 - val_mae: 0.0081 - val_mape: 16.3749 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0016 - mae: 0.0265 - mape: 7.7129 - val_loss: 2.2184e-04 - val_mae: 0.0085 - val_mape: 14.7081 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0267 - mape: 7.4297 - val_loss: 1.9604e-04 - val_mae: 0.0071 - val_mape: 13.7212 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0270 - mape: 7.1501 - val_loss: 2.5269e-04 - val_mae: 0.0099 - val_mape: 16.6090 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0261 - mape: 7.3524 - val_loss: 2.0289e-04 - val_mae: 0.0077 - val_mape: 16.9267 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0264 - mape: 7.2394 - val_loss: 2.5709e-04 - val_mae: 0.0108 - val_mape: 24.8510 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0264 - mape: 7.0664 - val_loss: 2.1451e-04 - val_mae: 0.0088 - val_mape: 20.5184 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0263 - mape: 7.2602 - val_loss: 2.4973e-04 - val_mae: 0.0106 - val_mape: 24.1439 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0261 - mape: 7.3527 - val_loss: 2.5180e-04 - val_mae: 0.0103 - val_mape: 27.4963 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0259 - mape: 7.0520 - val_loss: 2.0983e-04 - val_mae: 0.0085 - val_mape: 17.5505 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0260 - mape: 7.5371 - val_loss: 2.3393e-04 - val_mae: 0.0099 - val_mape: 23.2647 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0260 - mape: 6.6090 - val_loss: 1.7965e-04 - val_mae: 0.0067 - val_mape: 10.6215 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 7.4663 - val_loss: 1.7948e-04 - val_mae: 0.0068 - val_mape: 11.2369 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0260 - mape: 7.4132 - val_loss: 1.9292e-04 - val_mae: 0.0078 - val_mape: 16.1291 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0259 - mape: 7.1086 - val_loss: 1.8254e-04 - val_mae: 0.0071 - val_mape: 14.2803 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0015 - mae: 0.0259 - mape: 7.1084 - val_loss: 1.8673e-04 - val_mae: 0.0074 - val_mape: 13.8392 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.4588 - val_loss: 1.9578e-04 - val_mae: 0.0081 - val_mape: 17.0088 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 6.7919 - val_loss: 1.9055e-04 - val_mae: 0.0078 - val_mape: 17.8994 - lr: 1.5625e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 6.7136 - val_loss: 2.0154e-04 - val_mae: 0.0085 - val_mape: 18.9919 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0259 - mape: 6.9856 - val_loss: 1.9579e-04 - val_mae: 0.0081 - val_mape: 18.3726 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 7.2158 - val_loss: 1.7215e-04 - val_mae: 0.0066 - val_mape: 12.2934 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.8762 - val_loss: 1.9501e-04 - val_mae: 0.0082 - val_mape: 17.6348 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.7247 - val_loss: 1.7377e-04 - val_mae: 0.0067 - val_mape: 12.2841 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0253 - mape: 6.7205 - val_loss: 1.7256e-04 - val_mae: 0.0066 - val_mape: 12.4817 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 6.7475 - val_loss: 1.7789e-04 - val_mae: 0.0071 - val_mape: 13.4596 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0255 - mape: 6.6153 - val_loss: 1.7145e-04 - val_mae: 0.0066 - val_mape: 11.9460 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 6.9076 - val_loss: 1.9543e-04 - val_mae: 0.0082 - val_mape: 17.6767 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 7.5105 - val_loss: 1.8241e-04 - val_mae: 0.0074 - val_mape: 15.3669 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 7.0286 - val_loss: 1.7278e-04 - val_mae: 0.0067 - val_mape: 11.5134 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 6.8698 - val_loss: 1.7139e-04 - val_mae: 0.0066 - val_mape: 10.9392 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 6.6251 - val_loss: 1.7970e-04 - val_mae: 0.0072 - val_mape: 13.7803 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 6.9635 - val_loss: 1.8634e-04 - val_mae: 0.0078 - val_mape: 15.6374 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0259 - mape: 6.9455 - val_loss: 1.7171e-04 - val_mae: 0.0068 - val_mape: 12.0143 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 7.1557 - val_loss: 1.7373e-04 - val_mae: 0.0069 - val_mape: 11.1420 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0255 - mape: 6.8892 - val_loss: 1.8769e-04 - val_mae: 0.0078 - val_mape: 14.9978 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 7.2322 - val_loss: 1.7317e-04 - val_mae: 0.0068 - val_mape: 11.3283 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 7.0931 - val_loss: 1.8033e-04 - val_mae: 0.0073 - val_mape: 12.9412 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 6.8253 - val_loss: 1.7539e-04 - val_mae: 0.0071 - val_mape: 13.1514 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 7.2382 - val_loss: 1.8035e-04 - val_mae: 0.0075 - val_mape: 14.9790 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.9016 - val_loss: 1.6939e-04 - val_mae: 0.0067 - val_mape: 11.8155 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 7.0492 - val_loss: 1.7228e-04 - val_mae: 0.0069 - val_mape: 12.5588 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0255 - mape: 6.9391 - val_loss: 1.6721e-04 - val_mae: 0.0065 - val_mape: 11.2670 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.5841 - val_loss: 1.8342e-04 - val_mae: 0.0077 - val_mape: 15.0883 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.7606 - val_loss: 1.7471e-04 - val_mae: 0.0072 - val_mape: 13.6967 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 7.2475 - val_loss: 1.6718e-04 - val_mae: 0.0066 - val_mape: 11.5631 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0255 - mape: 7.2244 - val_loss: 1.7021e-04 - val_mae: 0.0068 - val_mape: 11.2301 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0254 - mape: 7.1089 - val_loss: 1.6534e-04 - val_mae: 0.0065 - val_mape: 10.3731 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0255 - mape: 6.5433 - val_loss: 1.6996e-04 - val_mae: 0.0068 - val_mape: 11.9061 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 6.9932 - val_loss: 1.7996e-04 - val_mae: 0.0076 - val_mape: 15.2341 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.8967 - val_loss: 1.7163e-04 - val_mae: 0.0071 - val_mape: 13.0946 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0256 - mape: 6.9977 - val_loss: 1.6518e-04 - val_mae: 0.0066 - val_mape: 10.4557 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0258 - mape: 7.3437 - val_loss: 1.6645e-04 - val_mae: 0.0067 - val_mape: 10.8110 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 7.3789 - val_loss: 1.6978e-04 - val_mae: 0.0070 - val_mape: 13.4653 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0256 - mape: 7.0795 - val_loss: 1.7239e-04 - val_mae: 0.0072 - val_mape: 14.2552 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0254 - mape: 6.5647 - val_loss: 1.7992e-04 - val_mae: 0.0077 - val_mape: 14.4838 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0254 - mape: 6.9484 - val_loss: 1.6544e-04 - val_mae: 0.0067 - val_mape: 11.0082 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0255 - mape: 6.8749 - val_loss: 1.7115e-04 - val_mae: 0.0072 - val_mape: 12.8682 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0255 - mape: 6.5424 - val_loss: 1.6973e-04 - val_mae: 0.0070 - val_mape: 11.8630 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0255 - mape: 6.6210 - val_loss: 1.6536e-04 - val_mae: 0.0068 - val_mape: 10.9815 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0253 - mape: 6.4840 - val_loss: 1.7055e-04 - val_mae: 0.0072 - val_mape: 12.3526 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0256 - mape: 6.7003 - val_loss: 1.6689e-04 - val_mae: 0.0069 - val_mape: 11.1873 - lr: 1.0000e-05\n",
      "Training completed in 739.05 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1738 - mape: 679.6935\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for aave...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 65ms/step - loss: 1.0968 - mae: 0.9602 - mape: 107.7391 - val_loss: 0.0665 - val_mae: 0.2088 - val_mape: 134.8238 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8937 - mae: 0.8573 - mape: 96.8652 - val_loss: 0.1009 - val_mae: 0.2481 - val_mape: 315.9568 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5253 - mae: 0.6244 - mape: 71.9969 - val_loss: 0.2829 - val_mae: 0.4873 - val_mape: 717.5879 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1441 - mae: 0.3022 - mape: 52.5426 - val_loss: 0.5144 - val_mae: 0.6937 - val_mape: 1022.6611 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1779 - mae: 0.3525 - mape: 62.4092 - val_loss: 0.2235 - val_mae: 0.4404 - val_mape: 664.7032 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0864 - mae: 0.2301 - mape: 43.3048 - val_loss: 0.1134 - val_mae: 0.2954 - val_mape: 473.1892 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0888 - mae: 0.2416 - mape: 45.2240 - val_loss: 0.0890 - val_mae: 0.2538 - val_mape: 413.9680 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0860 - mae: 0.2354 - mape: 44.3599 - val_loss: 0.0913 - val_mae: 0.2567 - val_mape: 423.4761 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0708 - mae: 0.1978 - mape: 40.1839 - val_loss: 0.1400 - val_mae: 0.3349 - val_mape: 536.3014 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0735 - mae: 0.1976 - mape: 42.1108 - val_loss: 0.1370 - val_mae: 0.3312 - val_mape: 529.0204 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0689 - mae: 0.1991 - mape: 39.4084 - val_loss: 0.1483 - val_mae: 0.3498 - val_mape: 548.5384 - lr: 5.0000e-04\n",
      "Training completed in 1.85 seconds\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0139 - mae: 0.0930 - mape: 14.5395\n",
      "1/1 [==============================] - 0s 122ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Data        Model       MSE       MAE       MAPE\n0   ada  Transformer  0.359337  0.581803   1.581122\n1   btc  Transformer  0.000249  0.010700   0.154965\n2  doge  Transformer  0.001240  0.026137   0.971763\n3   eth  Transformer  0.419650  0.608224  13.354861\n4   xmr  Transformer  0.000326  0.012544   0.724192\n5   xrp  Transformer  0.041647  0.173767   6.796935\n6  aave  Transformer  0.013883  0.093047   0.145395",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Model</th>\n      <th>MSE</th>\n      <th>MAE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ada</td>\n      <td>Transformer</td>\n      <td>0.359337</td>\n      <td>0.581803</td>\n      <td>1.581122</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>btc</td>\n      <td>Transformer</td>\n      <td>0.000249</td>\n      <td>0.010700</td>\n      <td>0.154965</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>doge</td>\n      <td>Transformer</td>\n      <td>0.001240</td>\n      <td>0.026137</td>\n      <td>0.971763</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eth</td>\n      <td>Transformer</td>\n      <td>0.419650</td>\n      <td>0.608224</td>\n      <td>13.354861</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xmr</td>\n      <td>Transformer</td>\n      <td>0.000326</td>\n      <td>0.012544</td>\n      <td>0.724192</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xrp</td>\n      <td>Transformer</td>\n      <td>0.041647</td>\n      <td>0.173767</td>\n      <td>6.796935</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aave</td>\n      <td>Transformer</td>\n      <td>0.013883</td>\n      <td>0.093047</td>\n      <td>0.145395</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    \n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_transformer_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    transformer = 'Transformer'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': transformer,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "transformer_df = pd.DataFrame(summary_table)\n",
    "transformer_df.to_csv('../results/transformer.csv')\n",
    "transformer_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:47:27.883360Z",
     "start_time": "2024-05-02T13:02:40.299338Z"
    }
   },
   "id": "f8a3d73d589f19c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8d461914cba7065"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                  ada       btc      doge       eth       xmr       xrp  \\\nLSTM         0.039191  0.036518   0.04523  0.058626  0.034918    0.0142   \nLSTM-CNN     0.081877  0.042862  0.050316  0.039123  0.046871  0.026126   \nTransformer  0.581803    0.0107  0.026137  0.608224  0.012544  0.173767   \n\n                 aave  \nLSTM         0.402494  \nLSTM-CNN      0.44255  \nTransformer  0.093047  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ada</th>\n      <th>btc</th>\n      <th>doge</th>\n      <th>eth</th>\n      <th>xmr</th>\n      <th>xrp</th>\n      <th>aave</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LSTM</th>\n      <td>0.039191</td>\n      <td>0.036518</td>\n      <td>0.04523</td>\n      <td>0.058626</td>\n      <td>0.034918</td>\n      <td>0.0142</td>\n      <td>0.402494</td>\n    </tr>\n    <tr>\n      <th>LSTM-CNN</th>\n      <td>0.081877</td>\n      <td>0.042862</td>\n      <td>0.050316</td>\n      <td>0.039123</td>\n      <td>0.046871</td>\n      <td>0.026126</td>\n      <td>0.44255</td>\n    </tr>\n    <tr>\n      <th>Transformer</th>\n      <td>0.581803</td>\n      <td>0.0107</td>\n      <td>0.026137</td>\n      <td>0.608224</td>\n      <td>0.012544</td>\n      <td>0.173767</td>\n      <td>0.093047</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['LSTM', 'LSTM-CNN', 'Transformer']\n",
    "cryptos = ['ada', 'btc', 'doge', 'eth', 'xmr', 'xrp', 'aave']\n",
    "file_paths = ['../results/lstm.csv', '../results/lstm_cnn.csv', '../results/transformer.csv']\n",
    "\n",
    "results = pd.DataFrame(index=models, columns=cryptos)\n",
    "\n",
    "# Loop through each file and each crypto to fill the DataFrame\n",
    "for model, file_path in zip(models, file_paths):\n",
    "    df = pd.read_csv(file_path)\n",
    "    for crypto in cryptos:\n",
    "        # Assuming the MAE column in each file is named 'test_mae'\n",
    "        results.at[model, crypto] = df.loc[df['Data'] == crypto, 'MAE'].values[0]\n",
    "\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:48:58.518176Z",
     "start_time": "2024-05-02T13:48:58.502803Z"
    }
   },
   "id": "880f3e064afc9f91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
