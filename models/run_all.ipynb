{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180c947e7839a277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:48:17.906417Z",
     "start_time": "2024-06-03T13:48:14.484397Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:14.763116Z",
     "start_time": "2024-06-03T13:51:11.274016Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scripts.utils import preprocess\n",
    "\n",
    "file_paths = ['../data/hourly/ada_lunarcrush_timeseries_hourly.csv', '../data/hourly/btc_lunarcrush_timeseries_hourly.csv', '../data/hourly/doge_lunarcrush_timeseries_hourly.csv', '../data/hourly/eth_lunarcrush_timeseries_hourly.csv', '../data/hourly/xmr_lunarcrush_timeseries_hourly.csv', '../data/hourly/xrp_lunarcrush_timeseries_hourly.csv', '../data/hourly/aave_lunarcrash_timeseries_hourly.csv']\n",
    "\n",
    "crypto_dfs = {}\n",
    "for path in file_paths:\n",
    "    crypto = os.path.basename(path).split('_')[0]\n",
    "    if os.path.exists(path):  # Check if the file exists\n",
    "        crypto_dfs[crypto] = preprocess(path)\n",
    "    else:\n",
    "        print(f\"File does not exist: {path}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11179a2896eceb81",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Training on Financial-only data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69bc7905d190b44e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:14.777175Z",
     "start_time": "2024-06-03T13:51:14.764057Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scripts.utils import simplify_df\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    crypto_dfs[crypto] = simplify_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927bf944a6e119a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25c3eec94c289b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:14.781982Z",
     "start_time": "2024-06-03T13:51:14.778220Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model(df):\n",
    "    df['predicted_close'] = df['close'].shift(1)\n",
    "    df = df.dropna(subset=['predicted_close'])\n",
    "    mae = mean_absolute_error(df['close'], df['predicted_close'])\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df6fba09ac1cb35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:15.050321Z",
     "start_time": "2024-06-03T13:51:15.028684Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE results for each cryptocurrency:\n",
      "ada: 0.0047\n",
      "btc: 121.2149\n",
      "doge: 0.0008\n",
      "eth: 8.7742\n",
      "xmr: 1.0392\n",
      "xrp: 0.0036\n",
      "aave: 17.2299\n"
     ]
    }
   ],
   "source": [
    "baseline_results = {}\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    mae = baseline_model(df)\n",
    "    baseline_results[crypto] = mae\n",
    "\n",
    "# Output the baseline MAE results\n",
    "print(\"Baseline MAE results for each cryptocurrency:\")\n",
    "for crypto, mae in baseline_results.items():\n",
    "    print(f\"{crypto}: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f8917256c21be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6fecc91004f7446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:16.265080Z",
     "start_time": "2024-06-03T13:51:16.257968Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras.models import Model as tfkModel\n",
    "\n",
    "def build_simple_LSTM_regressor(input_shape, output_units=1):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm = tfkl.LSTM(16, activation='leaky_relu', return_sequences=True)(input_layer)\n",
    "    lstm = tfkl.LSTM(16, activation='leaky_relu')(lstm)\n",
    "\n",
    "    # Output layer for regression\n",
    "    output_layer = tfkl.Dense(output_units)(lstm)  # Single unit for regression output\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfkModel(inputs=input_layer, outputs=output_layer, name='Simple_LSTM_regressor')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5333f00c89b193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:16.898737Z",
     "start_time": "2024-06-03T13:51:16.897040Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    # Assuming input_shape is (5, n_features)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_units = 1\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_simple_LSTM_regressor(input_shape, output_units)\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    ).history\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4695c6a453c2d6de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:17.454408Z",
     "start_time": "2024-06-03T13:51:17.452368Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e2bfcb35ca11c0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:51:29.172236Z",
     "start_time": "2024-06-03T13:51:18.142619Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.0790 - mae: 0.1203 - val_loss: 0.0024 - val_mae: 0.0408 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 0.0020 - val_mae: 0.0369 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.0668e-04 - mae: 0.0191 - val_loss: 0.0035 - val_mae: 0.0506 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.9772e-04 - mae: 0.0170 - val_loss: 0.0045 - val_mae: 0.0582 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.9002e-04 - mae: 0.0153 - val_loss: 0.0064 - val_mae: 0.0697 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.5159e-04 - mae: 0.0146 - val_loss: 0.0093 - val_mae: 0.0833 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.8862e-04 - mae: 0.0136 - val_loss: 0.0086 - val_mae: 0.0808 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.7370e-04 - mae: 0.0121 - val_loss: 0.0101 - val_mae: 0.0876 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.5094e-04 - mae: 0.0117 - val_loss: 0.0073 - val_mae: 0.0758 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.3128e-04 - mae: 0.0115 - val_loss: 0.0104 - val_mae: 0.0892 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0433e-04 - mae: 0.0111 - val_loss: 0.0147 - val_mae: 0.1059 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.9124e-04 - mae: 0.0110 - val_loss: 0.0118 - val_mae: 0.0946 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 498us/step - loss: 0.0190 - mae: 0.1217\n",
      "121/121 [==============================] - 0s 572us/step\n",
      "Running model for btc...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.0487 - mae: 0.1018 - val_loss: 0.0084 - val_mae: 0.0726 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.0722e-04 - mae: 0.0222 - val_loss: 0.0040 - val_mae: 0.0507 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.5113e-04 - mae: 0.0177 - val_loss: 0.0029 - val_mae: 0.0427 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.6056e-04 - mae: 0.0158 - val_loss: 0.0021 - val_mae: 0.0362 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9707e-04 - mae: 0.0146 - val_loss: 0.0022 - val_mae: 0.0389 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.6677e-04 - mae: 0.0139 - val_loss: 0.0016 - val_mae: 0.0330 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.4421e-04 - mae: 0.0135 - val_loss: 0.0019 - val_mae: 0.0365 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.1427e-04 - mae: 0.0131 - val_loss: 0.0015 - val_mae: 0.0318 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.8578e-04 - mae: 0.0126 - val_loss: 9.4494e-04 - val_mae: 0.0249 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.9391e-04 - mae: 0.0128 - val_loss: 6.5596e-04 - val_mae: 0.0204 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.3670e-04 - mae: 0.0120 - val_loss: 9.1111e-04 - val_mae: 0.0244 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.8118e-04 - mae: 0.0110 - val_loss: 5.2417e-04 - val_mae: 0.0178 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.5349e-04 - mae: 0.0105 - val_loss: 7.4254e-04 - val_mae: 0.0220 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.3193e-04 - mae: 0.0102 - val_loss: 0.0010 - val_mae: 0.0270 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.2941e-04 - mae: 0.0102 - val_loss: 7.6897e-04 - val_mae: 0.0232 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.9451e-04 - mae: 0.0094 - val_loss: 8.7104e-04 - val_mae: 0.0237 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.9339e-04 - mae: 0.0094 - val_loss: 0.0014 - val_mae: 0.0310 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.5786e-04 - mae: 0.0082 - val_loss: 6.9605e-04 - val_mae: 0.0193 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.5160e-04 - mae: 0.0080 - val_loss: 0.0011 - val_mae: 0.0258 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.5198e-04 - mae: 0.0080 - val_loss: 6.9324e-04 - val_mae: 0.0189 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.5253e-04 - mae: 0.0081 - val_loss: 7.3095e-04 - val_mae: 0.0195 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.4874e-04 - mae: 0.0080 - val_loss: 8.3860e-04 - val_mae: 0.0198 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 501us/step - loss: 0.0049 - mae: 0.0588\n",
      "121/121 [==============================] - 0s 572us/step\n",
      "Running model for doge...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.0617 - mae: 0.1046 - val_loss: 0.0024 - val_mae: 0.0382 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0027 - mae: 0.0256 - val_loss: 0.0022 - val_mae: 0.0372 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0219 - val_loss: 0.0017 - val_mae: 0.0324 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0188 - val_loss: 0.0029 - val_mae: 0.0459 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0173 - val_loss: 0.0015 - val_mae: 0.0320 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0168 - val_loss: 0.0015 - val_mae: 0.0321 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 9.3374e-04 - val_mae: 0.0246 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0157 - val_loss: 8.0218e-04 - val_mae: 0.0231 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.2679e-04 - mae: 0.0139 - val_loss: 8.0243e-04 - val_mae: 0.0228 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.5041e-04 - mae: 0.0143 - val_loss: 5.9341e-04 - val_mae: 0.0188 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.3087e-04 - mae: 0.0139 - val_loss: 3.4022e-04 - val_mae: 0.0141 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.1529e-04 - mae: 0.0129 - val_loss: 3.8021e-04 - val_mae: 0.0148 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.0629e-04 - mae: 0.0126 - val_loss: 0.0011 - val_mae: 0.0283 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.1437e-04 - mae: 0.0128 - val_loss: 7.3209e-04 - val_mae: 0.0227 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.2921e-04 - mae: 0.0121 - val_loss: 6.6821e-04 - val_mae: 0.0216 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.8561e-04 - mae: 0.0126 - val_loss: 5.0631e-04 - val_mae: 0.0178 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.0941e-04 - mae: 0.0100 - val_loss: 5.2220e-04 - val_mae: 0.0190 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9593e-04 - mae: 0.0101 - val_loss: 5.2524e-04 - val_mae: 0.0189 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9914e-04 - mae: 0.0102 - val_loss: 3.2696e-04 - val_mae: 0.0138 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.6872e-04 - mae: 0.0099 - val_loss: 3.5027e-04 - val_mae: 0.0146 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.7277e-04 - mae: 0.0100 - val_loss: 0.0011 - val_mae: 0.0305 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0997e-04 - mae: 0.0088 - val_loss: 4.1698e-04 - val_mae: 0.0166 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.1438e-04 - mae: 0.0089 - val_loss: 4.6236e-04 - val_mae: 0.0175 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0971e-04 - mae: 0.0089 - val_loss: 7.3834e-04 - val_mae: 0.0239 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0848e-04 - mae: 0.0089 - val_loss: 3.9821e-04 - val_mae: 0.0160 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0005e-04 - mae: 0.0088 - val_loss: 7.3909e-04 - val_mae: 0.0237 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7798e-04 - mae: 0.0083 - val_loss: 7.2338e-04 - val_mae: 0.0236 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7543e-04 - mae: 0.0083 - val_loss: 4.4049e-04 - val_mae: 0.0172 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7015e-04 - mae: 0.0083 - val_loss: 5.7470e-04 - val_mae: 0.0205 - lr: 1.2500e-04\n",
      "121/121 [==============================] - 0s 581us/step - loss: 8.5921e-04 - mae: 0.0231\n",
      "121/121 [==============================] - 0s 623us/step\n",
      "Running model for eth...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.1017 - mae: 0.1562 - val_loss: 0.0045 - val_mae: 0.0550 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 0.0045 - val_mae: 0.0545 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.5354e-04 - mae: 0.0170 - val_loss: 0.0034 - val_mae: 0.0455 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.1883e-04 - mae: 0.0156 - val_loss: 0.0025 - val_mae: 0.0380 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.5353e-04 - mae: 0.0148 - val_loss: 0.0024 - val_mae: 0.0366 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.1408e-04 - mae: 0.0142 - val_loss: 0.0022 - val_mae: 0.0354 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.0141e-04 - mae: 0.0139 - val_loss: 0.0027 - val_mae: 0.0396 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.6369e-04 - mae: 0.0133 - val_loss: 0.0023 - val_mae: 0.0359 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.5320e-04 - mae: 0.0132 - val_loss: 0.0023 - val_mae: 0.0366 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.2856e-04 - mae: 0.0127 - val_loss: 0.0013 - val_mae: 0.0279 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.1442e-04 - mae: 0.0125 - val_loss: 0.0017 - val_mae: 0.0315 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0588e-04 - mae: 0.0120 - val_loss: 0.0011 - val_mae: 0.0266 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.6631e-04 - mae: 0.0117 - val_loss: 0.0012 - val_mae: 0.0273 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.4349e-04 - mae: 0.0116 - val_loss: 0.0010 - val_mae: 0.0249 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.0018e-04 - mae: 0.0107 - val_loss: 0.0017 - val_mae: 0.0357 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.8187e-04 - mae: 0.0104 - val_loss: 0.0016 - val_mae: 0.0350 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.5594e-04 - mae: 0.0098 - val_loss: 6.1471e-04 - val_mae: 0.0199 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.3017e-04 - mae: 0.0092 - val_loss: 8.4632e-04 - val_mae: 0.0236 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.2105e-04 - mae: 0.0093 - val_loss: 0.0010 - val_mae: 0.0274 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.1994e-04 - mae: 0.0093 - val_loss: 0.0014 - val_mae: 0.0332 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 2.0492e-04 - mae: 0.0090 - val_loss: 0.0015 - val_mae: 0.0330 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.8645e-04 - mae: 0.0085 - val_loss: 0.0011 - val_mae: 0.0283 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6819e-04 - mae: 0.0077 - val_loss: 0.0022 - val_mae: 0.0413 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6202e-04 - mae: 0.0077 - val_loss: 0.0023 - val_mae: 0.0426 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.6215e-04 - mae: 0.0077 - val_loss: 0.0018 - val_mae: 0.0374 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.5799e-04 - mae: 0.0076 - val_loss: 0.0018 - val_mae: 0.0373 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.4975e-04 - mae: 0.0074 - val_loss: 0.0020 - val_mae: 0.0403 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 508us/step - loss: 0.0022 - mae: 0.0397\n",
      "121/121 [==============================] - 0s 574us/step\n",
      "Running model for xmr...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.0853 - mae: 0.1348 - val_loss: 0.0120 - val_mae: 0.0960 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0307 - val_loss: 0.0057 - val_mae: 0.0667 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0271 - val_loss: 0.0039 - val_mae: 0.0547 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0245 - val_loss: 0.0012 - val_mae: 0.0295 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0219 - val_loss: 6.3156e-04 - val_mae: 0.0200 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.8921e-04 - mae: 0.0197 - val_loss: 3.7382e-04 - val_mae: 0.0154 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.7685e-04 - mae: 0.0188 - val_loss: 3.3342e-04 - val_mae: 0.0145 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.4504e-04 - mae: 0.0175 - val_loss: 4.9568e-04 - val_mae: 0.0175 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.6804e-04 - mae: 0.0165 - val_loss: 0.0014 - val_mae: 0.0345 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.1848e-04 - mae: 0.0159 - val_loss: 1.7326e-04 - val_mae: 0.0100 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.6591e-04 - mae: 0.0153 - val_loss: 1.5084e-04 - val_mae: 0.0093 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.2230e-04 - mae: 0.0146 - val_loss: 2.2806e-04 - val_mae: 0.0117 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9039e-04 - mae: 0.0141 - val_loss: 3.5579e-04 - val_mae: 0.0154 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.9235e-04 - mae: 0.0141 - val_loss: 5.7506e-04 - val_mae: 0.0195 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.3408e-04 - mae: 0.0134 - val_loss: 2.4826e-04 - val_mae: 0.0124 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.8796e-04 - mae: 0.0124 - val_loss: 2.1314e-04 - val_mae: 0.0119 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.6754e-04 - mae: 0.0119 - val_loss: 2.4957e-04 - val_mae: 0.0121 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.6163e-04 - mae: 0.0119 - val_loss: 3.1836e-04 - val_mae: 0.0138 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.7476e-04 - mae: 0.0121 - val_loss: 1.5856e-04 - val_mae: 0.0102 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.4568e-04 - mae: 0.0116 - val_loss: 2.7791e-04 - val_mae: 0.0131 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 3.2799e-04 - mae: 0.0113 - val_loss: 4.1598e-04 - val_mae: 0.0166 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 502us/step - loss: 4.9820e-04 - mae: 0.0181\n",
      "121/121 [==============================] - 0s 582us/step\n",
      "Running model for xrp...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 2ms/step - loss: 0.0691 - mae: 0.1065 - val_loss: 0.0383 - val_mae: 0.1700 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0266 - val_loss: 0.0354 - val_mae: 0.1643 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0226 - val_loss: 0.0250 - val_mae: 0.1377 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0206 - val_loss: 0.0131 - val_mae: 0.0999 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0191 - val_loss: 0.0080 - val_mae: 0.0774 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0185 - val_loss: 0.0044 - val_mae: 0.0556 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 9.2160e-04 - mae: 0.0172 - val_loss: 0.0033 - val_mae: 0.0485 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.8699e-04 - mae: 0.0171 - val_loss: 0.0022 - val_mae: 0.0392 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 8.2830e-04 - mae: 0.0163 - val_loss: 0.0014 - val_mae: 0.0297 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 7.0853e-04 - mae: 0.0154 - val_loss: 5.2747e-04 - val_mae: 0.0168 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.5045e-04 - mae: 0.0150 - val_loss: 4.1997e-04 - val_mae: 0.0141 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 6.3850e-04 - mae: 0.0147 - val_loss: 4.6573e-04 - val_mae: 0.0145 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.8602e-04 - mae: 0.0142 - val_loss: 6.0989e-04 - val_mae: 0.0195 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.7617e-04 - mae: 0.0142 - val_loss: 4.8724e-04 - val_mae: 0.0160 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.1779e-04 - mae: 0.0133 - val_loss: 4.3355e-04 - val_mae: 0.0149 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 5.2007e-04 - mae: 0.0132 - val_loss: 4.8097e-04 - val_mae: 0.0163 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.5102e-04 - mae: 0.0118 - val_loss: 5.3563e-04 - val_mae: 0.0170 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.3222e-04 - mae: 0.0117 - val_loss: 5.3391e-04 - val_mae: 0.0176 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.2298e-04 - mae: 0.0116 - val_loss: 5.8130e-04 - val_mae: 0.0187 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.2980e-04 - mae: 0.0116 - val_loss: 5.5942e-04 - val_mae: 0.0169 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 4.0554e-04 - mae: 0.0114 - val_loss: 5.6264e-04 - val_mae: 0.0170 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 592us/step - loss: 5.4108e-04 - mae: 0.0182\n",
      "121/121 [==============================] - 0s 601us/step\n",
      "Running model for aave...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 5, 16)             1856      \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3985 (15.57 KB)\n",
      "Trainable params: 3985 (15.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 47ms/step - loss: 1.1636 - mae: 1.0001 - val_loss: 0.0999 - val_mae: 0.2681 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1036 - mae: 0.9725 - val_loss: 0.0874 - val_mae: 0.2499 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0582 - mae: 0.9502 - val_loss: 0.0786 - val_mae: 0.2350 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0165 - mae: 0.9299 - val_loss: 0.0727 - val_mae: 0.2226 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9764 - mae: 0.9095 - val_loss: 0.0683 - val_mae: 0.2125 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9308 - mae: 0.8862 - val_loss: 0.0655 - val_mae: 0.2050 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8783 - mae: 0.8590 - val_loss: 0.0653 - val_mae: 0.2003 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8181 - mae: 0.8270 - val_loss: 0.0682 - val_mae: 0.2011 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7463 - mae: 0.7878 - val_loss: 0.0751 - val_mae: 0.2133 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6574 - mae: 0.7377 - val_loss: 0.0880 - val_mae: 0.2340 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5379 - mae: 0.6637 - val_loss: 0.1122 - val_mae: 0.2732 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4051 - mae: 0.5605 - val_loss: 0.1551 - val_mae: 0.3415 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2992 - mae: 0.4560 - val_loss: 0.1888 - val_mae: 0.3889 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2613 - mae: 0.4174 - val_loss: 0.2369 - val_mae: 0.4492 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2302 - mae: 0.3896 - val_loss: 0.3049 - val_mae: 0.5211 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1991 - mae: 0.3567 - val_loss: 0.3981 - val_mae: 0.6045 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1674 - mae: 0.3206 - val_loss: 0.5178 - val_mae: 0.6953 - lr: 5.0000e-04\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3076 - mae: 0.5409\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ada</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.121723</td>\n",
       "      <td>0.494236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btc</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.058811</td>\n",
       "      <td>0.382770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doge</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>2.298499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eth</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.039746</td>\n",
       "      <td>1.327664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xmr</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.518633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xrp</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.880469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aave</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.307624</td>\n",
       "      <td>0.540885</td>\n",
       "      <td>0.780253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Model       MSE       MAE      MAPE\n",
       "0   ada  LSTM  0.018989  0.121723  0.494236\n",
       "1   btc  LSTM  0.004930  0.058811  0.382770\n",
       "2  doge  LSTM  0.000859  0.023134  2.298499\n",
       "3   eth  LSTM  0.002221  0.039746  1.327664\n",
       "4   xmr  LSTM  0.000498  0.018086  0.518633\n",
       "5   xrp  LSTM  0.000541  0.018221  0.880469\n",
       "6  aave  LSTM  0.307624  0.540885  0.780253"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.utils import split_data_frame, apply_functions\n",
    "\n",
    "def run_model_for_dataframe(df):\n",
    "    # Split the DataFrame into train, validation, and test sets\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "\n",
    "    # Apply any additional functions to preprocess the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    # Fit the model\n",
    "    model, history = fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Get the evaluation metrics for each set\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the evaluation metrics along with the model and history\n",
    "    return model, history, (mse, mae, mape)\n",
    "\n",
    "# Assuming crypto_dfs is your dictionary of DataFrames for each crypto\n",
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_model_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    lstm = 'LSTM'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': lstm,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "lstm_df = pd.DataFrame(summary_table)\n",
    "lstm_df.to_csv('../results/lstm.csv')\n",
    "lstm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff103f172728cb9f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b23a37520f60656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:48:44.016150Z",
     "start_time": "2024-06-03T13:48:44.014883Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras.models import Model as tfkModel\n",
    "\n",
    "def build_improved_LSTM_CNN(input_shape, output_units):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # CNN Layer 1\n",
    "    cnn = tfkl.Conv1D(256, 3, padding='same')(input_layer)  # Increased number of filters and adjusted kernel size\n",
    "    cnn = tfkl.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tfkl.MaxPooling1D(pool_size=2)(cnn)  # Added pool_size\n",
    "\n",
    "    # CNN Layer 2\n",
    "    cnn = tfkl.Conv1D(128, 3, padding='same')(cnn)  # Adjusted number of filters and kernel size\n",
    "    cnn = tfkl.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tfkl.MaxPooling1D(pool_size=2)(cnn)  # Added pool_size\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    lstm = tfkl.LSTM(128, return_sequences=True)(cnn)  # Increased the number of units\n",
    "    lstm = tfkl.Dropout(0.2)(lstm)  # Added dropout for regularization\n",
    "\n",
    "    # LSTM Layer 2\n",
    "    lstm = tfkl.LSTM(128)(lstm)  # Adjusted the number of units\n",
    "    lstm = tfkl.Dropout(0.2)(lstm)  # Added dropout for regularization\n",
    "\n",
    "    # Feature Extractor Layer\n",
    "    dense = tfkl.Dense(64)(lstm)  # Adjusted the number of units\n",
    "    dense = tfkl.LeakyReLU(alpha=0.2)(dense)\n",
    "    dense = tfkl.Dropout(0.2)(dense)  # Added dropout for regularization\n",
    "\n",
    "    # Output layer for regression\n",
    "    output_layer = tfkl.Dense(output_units)(dense)  # No activation for regression output\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfkModel(inputs=input_layer, outputs=output_layer, name='Improved_LSTM_CNN')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e195f9f3ecc94ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.016764Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def fit(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_units = 1  # Assuming we want to predict one feature, e.g., close price for one day ahead\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_improved_LSTM_CNN(input_shape, output_units)\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    ).history\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5e9f29ef73d30fc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.017857Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "454d8468ff65d12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:48:44.018965Z",
     "start_time": "2024-06-03T13:48:44.018803Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 2, 256)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 5s 4ms/step - loss: 0.0276 - mae: 0.1025 - val_loss: 0.0169 - val_mae: 0.1242 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0134 - mae: 0.0806 - val_loss: 0.0156 - val_mae: 0.1191 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0119 - mae: 0.0761 - val_loss: 0.0179 - val_mae: 0.1278 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0107 - mae: 0.0731 - val_loss: 0.0078 - val_mae: 0.0809 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0106 - mae: 0.0720 - val_loss: 0.0051 - val_mae: 0.0626 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0103 - mae: 0.0717 - val_loss: 0.0093 - val_mae: 0.0872 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0097 - mae: 0.0688 - val_loss: 0.0104 - val_mae: 0.0942 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0673 - val_loss: 0.0133 - val_mae: 0.1084 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0669 - val_loss: 0.0068 - val_mae: 0.0726 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0087 - mae: 0.0653 - val_loss: 0.0087 - val_mae: 0.0827 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0074 - mae: 0.0604 - val_loss: 0.0185 - val_mae: 0.1283 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0074 - mae: 0.0601 - val_loss: 0.0089 - val_mae: 0.0830 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0594 - val_loss: 0.0136 - val_mae: 0.1076 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0071 - mae: 0.0593 - val_loss: 0.0146 - val_mae: 0.1117 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0593 - val_loss: 0.0162 - val_mae: 0.1179 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 924us/step - loss: 0.0108 - mae: 0.0941\n",
      "121/121 [==============================] - 0s 879us/step\n",
      "Running model for btc...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 5s 4ms/step - loss: 0.0255 - mae: 0.1050 - val_loss: 0.0024 - val_mae: 0.0409 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0123 - mae: 0.0817 - val_loss: 0.0030 - val_mae: 0.0442 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0110 - mae: 0.0778 - val_loss: 0.0099 - val_mae: 0.0833 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0104 - mae: 0.0756 - val_loss: 0.0032 - val_mae: 0.0495 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0096 - mae: 0.0732 - val_loss: 0.0032 - val_mae: 0.0522 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0093 - mae: 0.0721 - val_loss: 0.0082 - val_mae: 0.0795 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0081 - mae: 0.0667 - val_loss: 0.0039 - val_mae: 0.0541 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0082 - mae: 0.0673 - val_loss: 0.0082 - val_mae: 0.0785 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0078 - mae: 0.0655 - val_loss: 0.0021 - val_mae: 0.0413 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0077 - mae: 0.0654 - val_loss: 0.0081 - val_mae: 0.0816 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0075 - mae: 0.0644 - val_loss: 0.0067 - val_mae: 0.0714 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0074 - mae: 0.0643 - val_loss: 0.0076 - val_mae: 0.0738 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0645 - val_loss: 0.0026 - val_mae: 0.0456 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0631 - val_loss: 0.0020 - val_mae: 0.0359 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0631 - val_loss: 0.0064 - val_mae: 0.0688 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0629 - val_loss: 0.0067 - val_mae: 0.0718 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0068 - mae: 0.0619 - val_loss: 0.0060 - val_mae: 0.0552 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0070 - mae: 0.0621 - val_loss: 0.0134 - val_mae: 0.0995 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0068 - mae: 0.0612 - val_loss: 0.0132 - val_mae: 0.0880 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0589 - val_loss: 0.0127 - val_mae: 0.0866 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0583 - val_loss: 0.0259 - val_mae: 0.1337 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0581 - val_loss: 0.0285 - val_mae: 0.1377 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0436 - val_mae: 0.1659 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0528 - val_mae: 0.1799 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 956us/step - loss: 0.0017 - mae: 0.0357\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for doge...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 5s 4ms/step - loss: 0.0296 - mae: 0.1012 - val_loss: 0.0061 - val_mae: 0.0659 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0155 - mae: 0.0786 - val_loss: 0.0064 - val_mae: 0.0661 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0139 - mae: 0.0750 - val_loss: 0.0032 - val_mae: 0.0444 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0138 - mae: 0.0752 - val_loss: 0.0040 - val_mae: 0.0476 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0133 - mae: 0.0744 - val_loss: 0.0022 - val_mae: 0.0362 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0124 - mae: 0.0723 - val_loss: 0.0040 - val_mae: 0.0491 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0118 - mae: 0.0713 - val_loss: 0.0031 - val_mae: 0.0421 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0108 - mae: 0.0686 - val_loss: 0.0023 - val_mae: 0.0380 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0113 - mae: 0.0694 - val_loss: 0.0038 - val_mae: 0.0480 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0103 - mae: 0.0665 - val_loss: 0.0030 - val_mae: 0.0426 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0621 - val_loss: 0.0049 - val_mae: 0.0576 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0614 - val_loss: 0.0030 - val_mae: 0.0437 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0086 - mae: 0.0610 - val_loss: 0.0047 - val_mae: 0.0560 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0085 - mae: 0.0600 - val_loss: 0.0029 - val_mae: 0.0437 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0084 - mae: 0.0598 - val_loss: 0.0038 - val_mae: 0.0488 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 888us/step - loss: 0.0046 - mae: 0.0552\n",
      "121/121 [==============================] - 0s 888us/step\n",
      "Running model for eth...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0263 - mae: 0.1029 - val_loss: 0.0029 - val_mae: 0.0454 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0131 - mae: 0.0825 - val_loss: 0.0021 - val_mae: 0.0392 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0118 - mae: 0.0782 - val_loss: 0.0024 - val_mae: 0.0419 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0100 - mae: 0.0728 - val_loss: 0.0022 - val_mae: 0.0393 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0103 - mae: 0.0734 - val_loss: 0.0018 - val_mae: 0.0352 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0095 - mae: 0.0709 - val_loss: 0.0016 - val_mae: 0.0331 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0093 - mae: 0.0698 - val_loss: 0.0012 - val_mae: 0.0299 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0090 - mae: 0.0688 - val_loss: 0.0019 - val_mae: 0.0363 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0084 - mae: 0.0664 - val_loss: 9.1325e-04 - val_mae: 0.0231 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0085 - mae: 0.0675 - val_loss: 0.0021 - val_mae: 0.0414 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0081 - mae: 0.0661 - val_loss: 0.0029 - val_mae: 0.0431 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0082 - mae: 0.0662 - val_loss: 0.0012 - val_mae: 0.0309 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0081 - mae: 0.0659 - val_loss: 0.0015 - val_mae: 0.0338 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0639 - val_loss: 0.0041 - val_mae: 0.0568 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0608 - val_loss: 0.0031 - val_mae: 0.0482 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0601 - val_loss: 0.0011 - val_mae: 0.0273 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0604 - val_loss: 0.0034 - val_mae: 0.0541 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0599 - val_loss: 0.0024 - val_mae: 0.0440 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0586 - val_loss: 0.0040 - val_mae: 0.0545 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.5231e-04 - mae: 0.0163\n",
      "121/121 [==============================] - 0s 987us/step\n",
      "Running model for xmr...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 5s 4ms/step - loss: 0.0334 - mae: 0.1098 - val_loss: 0.0101 - val_mae: 0.0930 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0153 - mae: 0.0856 - val_loss: 0.0081 - val_mae: 0.0768 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0138 - mae: 0.0814 - val_loss: 0.0060 - val_mae: 0.0662 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0126 - mae: 0.0794 - val_loss: 0.0075 - val_mae: 0.0710 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0126 - mae: 0.0786 - val_loss: 0.0215 - val_mae: 0.1386 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0122 - mae: 0.0772 - val_loss: 0.0107 - val_mae: 0.0887 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0117 - mae: 0.0754 - val_loss: 0.0116 - val_mae: 0.0969 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0113 - mae: 0.0748 - val_loss: 0.0135 - val_mae: 0.1024 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0094 - mae: 0.0674 - val_loss: 0.0101 - val_mae: 0.0854 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0094 - mae: 0.0678 - val_loss: 0.0088 - val_mae: 0.0798 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0670 - val_loss: 0.0094 - val_mae: 0.0845 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0089 - mae: 0.0666 - val_loss: 0.0134 - val_mae: 0.1013 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0086 - mae: 0.0651 - val_loss: 0.0167 - val_mae: 0.1156 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0124 - mae: 0.0942\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for xrp...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPooli  (None, 2, 256)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 1, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0299 - mae: 0.1060 - val_loss: 0.0037 - val_mae: 0.0503 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0156 - mae: 0.0866 - val_loss: 7.3459e-04 - val_mae: 0.0179 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0136 - mae: 0.0810 - val_loss: 0.0016 - val_mae: 0.0298 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0124 - mae: 0.0771 - val_loss: 0.0024 - val_mae: 0.0380 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0122 - mae: 0.0771 - val_loss: 0.0015 - val_mae: 0.0299 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0115 - mae: 0.0736 - val_loss: 0.0022 - val_mae: 0.0351 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0115 - mae: 0.0736 - val_loss: 0.0034 - val_mae: 0.0513 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0644 - val_loss: 0.0013 - val_mae: 0.0266 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0646 - val_loss: 0.0018 - val_mae: 0.0288 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0087 - mae: 0.0642 - val_loss: 0.0011 - val_mae: 0.0230 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0085 - mae: 0.0637 - val_loss: 0.0043 - val_mae: 0.0595 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0644 - val_loss: 0.0043 - val_mae: 0.0554 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 907us/step - loss: 0.0011 - mae: 0.0266\n",
      "121/121 [==============================] - 0s 940us/step\n",
      "Running model for aave...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 12)]           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 5, 256)            9472      \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 2, 256)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 1, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379393 (1.45 MB)\n",
      "Trainable params: 379393 (1.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 53ms/step - loss: 0.8095 - mae: 0.8203 - val_loss: 0.0931 - val_mae: 0.2406 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2211 - mae: 0.3819 - val_loss: 1.1009 - val_mae: 1.0360 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1238 - mae: 0.2789 - val_loss: 0.3255 - val_mae: 0.5409 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1138 - mae: 0.2543 - val_loss: 0.3539 - val_mae: 0.5686 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0885 - mae: 0.2252 - val_loss: 0.4906 - val_mae: 0.6805 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0935 - mae: 0.2319 - val_loss: 0.4141 - val_mae: 0.6213 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0774 - mae: 0.2047 - val_loss: 0.3068 - val_mae: 0.5280 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0815 - mae: 0.2175 - val_loss: 0.3028 - val_mae: 0.5243 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0821 - mae: 0.2141 - val_loss: 0.3425 - val_mae: 0.5602 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0731 - mae: 0.2055 - val_loss: 0.3042 - val_mae: 0.5256 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.1930 - val_loss: 0.2782 - val_mae: 0.5018 - lr: 5.0000e-04\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1111 - mae: 0.3128\n",
      "1/1 [==============================] - 0s 254ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ada</td>\n",
       "      <td>LSTM-CNN</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.094137</td>\n",
       "      <td>0.299837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btc</td>\n",
       "      <td>LSTM-CNN</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.035705</td>\n",
       "      <td>1.077848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doge</td>\n",
       "      <td>LSTM-CNN</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.055242</td>\n",
       "      <td>6.120459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eth</td>\n",
       "      <td>LSTM-CNN</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.016264</td>\n",
       "      <td>0.348036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xmr</td>\n",
       "      <td>LSTM-CNN</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>3.755125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xrp</td>\n",
       "      <td>LSTM-CNN</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.026604</td>\n",
       "      <td>1.588341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aave</td>\n",
       "      <td>LSTM-CNN</td>\n",
       "      <td>0.111124</td>\n",
       "      <td>0.312760</td>\n",
       "      <td>0.439349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data     Model       MSE       MAE      MAPE\n",
       "0   ada  LSTM-CNN  0.010752  0.094137  0.299837\n",
       "1   btc  LSTM-CNN  0.001655  0.035705  1.077848\n",
       "2  doge  LSTM-CNN  0.004618  0.055242  6.120459\n",
       "3   eth  LSTM-CNN  0.000452  0.016264  0.348036\n",
       "4   xmr  LSTM-CNN  0.012357  0.094177  3.755125\n",
       "5   xrp  LSTM-CNN  0.001085  0.026604  1.588341\n",
       "6  aave  LSTM-CNN  0.111124  0.312760  0.439349"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.utils import split_data_frame, apply_functions\n",
    "\n",
    "def run_model_for_dataframe(df):\n",
    "    # Split the DataFrame into train, validation, and test sets\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "\n",
    "    # Apply any additional functions to preprocess the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    # Fit the model\n",
    "    model, history = fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Get the evaluation metrics for each set\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the evaluation metrics along with the model and history\n",
    "    return model, history, (mse, mae, mape)\n",
    "\n",
    "# Assuming crypto_dfs is your dictionary of DataFrames for each crypto\n",
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_model_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    lstm_cnn = 'LSTM-CNN'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': lstm_cnn,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "lstm_cnn_df = pd.DataFrame(summary_table)\n",
    "lstm_cnn_df.to_csv('../results/lstm_cnn.csv')\n",
    "lstm_cnn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8361dbb4b70b0a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f081ecca6372e338",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.019984Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0, epsilon=1e-6, attention_axes=None, kernel_size=1):\n",
    "    \"\"\"\n",
    "    Creates a single transformer block.\n",
    "    \"\"\"\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout,\n",
    "        attention_axes=attention_axes\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=kernel_size, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=kernel_size)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1ee42a933468fd7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.021122Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_transfromer(head_size, num_heads, ff_dim, num_trans_blocks, mlp_units, dropout=0, mlp_dropout=0, attention_axes=None, epsilon=1e-6, kernel_size=1):\n",
    "    \"\"\"\n",
    "    Creates final model by building many transformer blocks.\n",
    "    \"\"\"\n",
    "    n_timesteps, n_features, n_outputs = 5, 12, 1\n",
    "    inputs = tf.keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = inputs\n",
    "    for _ in range(num_trans_blocks):\n",
    "        x = transformer_encoder(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout, attention_axes=attention_axes, kernel_size=kernel_size, epsilon=epsilon)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(n_outputs)(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5120f9e78fe27e57",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.022109Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fit_transformer(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Compiles and fits our transformer with the provided training and validation data.\n",
    "    \"\"\"\n",
    "    transformer = build_transfromer(head_size=128, num_heads=4, ff_dim=2, num_trans_blocks=4, mlp_units=[256], mlp_dropout=0.10, dropout=0.10, attention_axes=1)    \n",
    "    \n",
    "    transformer.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "        metrics=[\"mae\", \"mape\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = transformer.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=64,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    ).history\n",
    "\n",
    "    print(f\"Training completed in {time.time() - start:.2f} seconds\")\n",
    "    return transformer, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c08ac846ef275f78",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.022706Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b829c25aab5ed3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.023267Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_transformer_for_dataframe(df):\n",
    "    \n",
    "    # Preprocessing steps\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    transformer, history = fit_transformer(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the model, history, and metrics\n",
    "    return transformer, history, (mse, mae, mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8a3d73d589f19c9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.024017Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 20ms/step - loss: 0.0238 - mae: 0.0931 - mape: 18.1522 - val_loss: 0.0577 - val_mae: 0.2300 - val_mape: 45.7766 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0058 - mae: 0.0568 - mape: 12.3554 - val_loss: 0.0399 - val_mae: 0.1859 - val_mape: 36.8241 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0042 - mae: 0.0479 - mape: 10.0046 - val_loss: 0.0537 - val_mae: 0.2197 - val_mape: 43.7317 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0037 - mae: 0.0447 - mape: 9.2815 - val_loss: 0.0531 - val_mae: 0.2201 - val_mape: 43.8272 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0031 - mae: 0.0407 - mape: 7.9881 - val_loss: 0.0324 - val_mae: 0.1698 - val_mape: 33.6986 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0029 - mae: 0.0385 - mape: 7.8488 - val_loss: 0.0358 - val_mae: 0.1777 - val_mape: 35.3553 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0026 - mae: 0.0371 - mape: 7.2268 - val_loss: 0.0262 - val_mae: 0.1522 - val_mape: 30.1728 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0025 - mae: 0.0360 - mape: 7.5634 - val_loss: 0.0240 - val_mae: 0.1448 - val_mape: 28.7500 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0025 - mae: 0.0356 - mape: 6.9166 - val_loss: 0.0159 - val_mae: 0.1149 - val_mape: 22.6952 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0352 - mape: 7.1736 - val_loss: 0.0162 - val_mae: 0.1182 - val_mape: 23.4256 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0345 - mape: 6.1169 - val_loss: 0.0184 - val_mae: 0.1275 - val_mape: 25.2212 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0023 - mae: 0.0341 - mape: 5.6189 - val_loss: 0.0210 - val_mae: 0.1387 - val_mape: 27.5245 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0022 - mae: 0.0330 - mape: 6.3519 - val_loss: 0.0161 - val_mae: 0.1204 - val_mape: 23.9038 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0327 - mape: 5.7525 - val_loss: 0.0063 - val_mae: 0.0720 - val_mape: 14.1614 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0022 - mae: 0.0331 - mape: 5.7389 - val_loss: 0.0149 - val_mae: 0.1149 - val_mape: 22.7795 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0022 - mae: 0.0327 - mape: 6.3555 - val_loss: 0.0136 - val_mae: 0.1120 - val_mape: 22.2734 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0320 - mape: 4.9539 - val_loss: 0.0054 - val_mae: 0.0669 - val_mape: 13.1405 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0314 - mape: 5.4421 - val_loss: 0.0055 - val_mae: 0.0682 - val_mape: 13.5195 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0309 - mape: 5.1877 - val_loss: 0.0051 - val_mae: 0.0665 - val_mape: 13.1563 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0314 - mape: 5.1252 - val_loss: 0.0043 - val_mae: 0.0606 - val_mape: 11.9716 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0308 - mape: 4.8971 - val_loss: 0.0070 - val_mae: 0.0792 - val_mape: 15.7205 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0302 - mape: 5.1803 - val_loss: 0.0015 - val_mae: 0.0358 - val_mape: 7.0428 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0309 - mape: 5.7556 - val_loss: 0.0048 - val_mae: 0.0669 - val_mape: 13.2750 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0298 - mape: 5.1445 - val_loss: 0.0024 - val_mae: 0.0456 - val_mape: 8.9376 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0295 - mape: 5.0172 - val_loss: 0.0034 - val_mae: 0.0566 - val_mape: 11.2202 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0292 - mape: 4.6279 - val_loss: 0.0024 - val_mae: 0.0462 - val_mape: 9.0563 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0293 - mape: 4.7203 - val_loss: 2.4607e-04 - val_mae: 0.0124 - val_mape: 2.3326 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0289 - mape: 4.5963 - val_loss: 7.8491e-04 - val_mae: 0.0246 - val_mape: 4.7667 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0290 - mape: 4.8671 - val_loss: 0.0010 - val_mae: 0.0307 - val_mape: 6.0620 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0017 - mae: 0.0283 - mape: 4.8837 - val_loss: 4.8478e-04 - val_mae: 0.0184 - val_mape: 3.5460 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0291 - mape: 4.5133 - val_loss: 5.7345e-04 - val_mae: 0.0221 - val_mape: 4.3618 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0017 - mae: 0.0289 - mape: 4.7361 - val_loss: 5.0552e-04 - val_mae: 0.0197 - val_mape: 3.8905 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0269 - mape: 4.2412 - val_loss: 3.3981e-04 - val_mae: 0.0151 - val_mape: 2.9081 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0273 - mape: 4.2409 - val_loss: 9.1982e-04 - val_mae: 0.0277 - val_mape: 5.4352 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0270 - mape: 4.2057 - val_loss: 2.1269e-04 - val_mae: 0.0119 - val_mape: 2.3221 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0271 - mape: 4.3156 - val_loss: 1.2105e-04 - val_mae: 0.0085 - val_mape: 1.6323 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0273 - mape: 4.1090 - val_loss: 8.8505e-04 - val_mae: 0.0271 - val_mape: 5.2904 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0268 - mape: 3.9928 - val_loss: 3.1793e-04 - val_mae: 0.0153 - val_mape: 2.9555 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0270 - mape: 4.3458 - val_loss: 3.4200e-04 - val_mae: 0.0166 - val_mape: 3.2380 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0271 - mape: 4.4509 - val_loss: 9.2382e-04 - val_mae: 0.0286 - val_mape: 5.6679 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0271 - mape: 4.1747 - val_loss: 3.6019e-04 - val_mae: 0.0168 - val_mape: 3.2800 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0260 - mape: 4.2498 - val_loss: 9.4729e-04 - val_mae: 0.0284 - val_mape: 5.6044 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0260 - mape: 4.1331 - val_loss: 0.0010 - val_mae: 0.0300 - val_mape: 5.9446 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0263 - mape: 3.9494 - val_loss: 6.9694e-04 - val_mae: 0.0245 - val_mape: 4.8194 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0260 - mape: 4.0650 - val_loss: 2.1050e-04 - val_mae: 0.0119 - val_mape: 2.3341 - lr: 2.5000e-04\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0261 - mape: 4.0316 - val_loss: 4.4240e-04 - val_mae: 0.0185 - val_mape: 3.6249 - lr: 2.5000e-04\n",
      "Training completed in 366.05 seconds\n",
      "121/121 [==============================] - 0s 995us/step - loss: 0.4785 - mae: 0.6786\n",
      "121/121 [==============================] - 0s 937us/step\n",
      "Running model for btc...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 20ms/step - loss: 0.0375 - mae: 0.1025 - mape: 47.0140 - val_loss: 0.0390 - val_mae: 0.1852 - val_mape: 657.2678 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0048 - mae: 0.0527 - mape: 16.5786 - val_loss: 0.0071 - val_mae: 0.0783 - val_mape: 254.9626 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0033 - mae: 0.0443 - mape: 9.8792 - val_loss: 0.0053 - val_mae: 0.0676 - val_mape: 203.7564 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0027 - mae: 0.0393 - mape: 8.9529 - val_loss: 0.0090 - val_mae: 0.0894 - val_mape: 287.6057 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0023 - mae: 0.0365 - mape: 10.0241 - val_loss: 0.0040 - val_mae: 0.0574 - val_mape: 187.5706 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0022 - mae: 0.0355 - mape: 8.8618 - val_loss: 0.0027 - val_mae: 0.0478 - val_mape: 160.3125 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0021 - mae: 0.0346 - mape: 13.0891 - val_loss: 0.0016 - val_mae: 0.0345 - val_mape: 108.7874 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0020 - mae: 0.0336 - mape: 8.5941 - val_loss: 0.0022 - val_mae: 0.0419 - val_mape: 154.2265 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0321 - mape: 8.1234 - val_loss: 0.0017 - val_mae: 0.0360 - val_mape: 125.8594 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0020 - mae: 0.0337 - mape: 8.3353 - val_loss: 6.4785e-04 - val_mae: 0.0222 - val_mape: 63.0767 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0315 - mape: 10.4809 - val_loss: 0.0011 - val_mae: 0.0281 - val_mape: 98.9842 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0321 - mape: 10.1445 - val_loss: 0.0015 - val_mae: 0.0352 - val_mape: 126.2246 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0325 - mape: 9.6502 - val_loss: 3.9421e-04 - val_mae: 0.0163 - val_mape: 50.2530 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0312 - mape: 8.7558 - val_loss: 4.2910e-04 - val_mae: 0.0175 - val_mape: 26.5574 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0300 - mape: 9.9211 - val_loss: 1.9819e-04 - val_mae: 0.0110 - val_mape: 20.6654 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0312 - mape: 7.8019 - val_loss: 0.0012 - val_mae: 0.0296 - val_mape: 110.7463 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0017 - mae: 0.0308 - mape: 9.0530 - val_loss: 6.5998e-04 - val_mae: 0.0217 - val_mape: 78.7425 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0298 - mape: 9.1052 - val_loss: 6.5861e-04 - val_mae: 0.0208 - val_mape: 70.4397 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0305 - mape: 7.2152 - val_loss: 2.9429e-04 - val_mae: 0.0140 - val_mape: 52.9939 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0299 - mape: 8.5988 - val_loss: 3.8322e-04 - val_mae: 0.0162 - val_mape: 49.1640 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0281 - mape: 8.7828 - val_loss: 3.5360e-04 - val_mae: 0.0156 - val_mape: 51.7843 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0282 - mape: 8.4375 - val_loss: 1.4374e-04 - val_mae: 0.0089 - val_mape: 27.4406 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0280 - mape: 8.7333 - val_loss: 1.5046e-04 - val_mae: 0.0090 - val_mape: 27.0279 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0279 - mape: 7.5590 - val_loss: 2.3189e-04 - val_mae: 0.0120 - val_mape: 28.1941 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0281 - mape: 7.6571 - val_loss: 1.4889e-04 - val_mae: 0.0092 - val_mape: 21.3048 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0271 - mape: 8.2650 - val_loss: 1.4290e-04 - val_mae: 0.0089 - val_mape: 26.3647 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0270 - mape: 7.2577 - val_loss: 2.3702e-04 - val_mae: 0.0123 - val_mape: 43.3368 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0271 - mape: 7.5833 - val_loss: 1.1556e-04 - val_mae: 0.0081 - val_mape: 18.7991 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0267 - mape: 7.3164 - val_loss: 2.2822e-04 - val_mae: 0.0123 - val_mape: 46.3237 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0268 - mape: 7.3899 - val_loss: 1.1272e-04 - val_mae: 0.0076 - val_mape: 21.6914 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0013 - mae: 0.0264 - mape: 8.3164 - val_loss: 1.5114e-04 - val_mae: 0.0096 - val_mape: 26.2276 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0263 - mape: 7.9789 - val_loss: 1.2168e-04 - val_mae: 0.0083 - val_mape: 26.2043 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0262 - mape: 8.1574 - val_loss: 1.7296e-04 - val_mae: 0.0103 - val_mape: 30.2906 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0264 - mape: 8.3224 - val_loss: 1.3102e-04 - val_mae: 0.0084 - val_mape: 22.2541 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0263 - mape: 7.4185 - val_loss: 1.3600e-04 - val_mae: 0.0089 - val_mape: 18.3420 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0260 - mape: 8.0168 - val_loss: 1.2386e-04 - val_mae: 0.0081 - val_mape: 19.7547 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0259 - mape: 7.3049 - val_loss: 1.0276e-04 - val_mae: 0.0077 - val_mape: 17.0836 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0257 - mape: 7.3333 - val_loss: 1.3675e-04 - val_mae: 0.0089 - val_mape: 23.3982 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0259 - mape: 8.1386 - val_loss: 2.0747e-04 - val_mae: 0.0115 - val_mape: 34.7154 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0258 - mape: 7.3248 - val_loss: 1.4758e-04 - val_mae: 0.0089 - val_mape: 24.2923 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0255 - mape: 7.4372 - val_loss: 1.4955e-04 - val_mae: 0.0088 - val_mape: 26.3144 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0259 - mape: 7.3769 - val_loss: 9.8437e-05 - val_mae: 0.0071 - val_mape: 17.6164 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0257 - mape: 7.5804 - val_loss: 9.9889e-05 - val_mae: 0.0070 - val_mape: 18.1456 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.0403 - val_loss: 1.6715e-04 - val_mae: 0.0093 - val_mape: 27.7653 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0256 - mape: 7.2284 - val_loss: 1.0638e-04 - val_mae: 0.0072 - val_mape: 20.0715 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.0966 - val_loss: 1.0897e-04 - val_mae: 0.0074 - val_mape: 19.1356 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0257 - mape: 8.0931 - val_loss: 1.0802e-04 - val_mae: 0.0072 - val_mape: 20.3654 - lr: 1.5625e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0254 - mape: 6.5443 - val_loss: 1.0057e-04 - val_mae: 0.0071 - val_mape: 18.5397 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.3885 - val_loss: 8.8606e-05 - val_mae: 0.0065 - val_mape: 16.8074 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.3406 - val_loss: 8.7402e-05 - val_mae: 0.0067 - val_mape: 16.2345 - lr: 1.5625e-05\n",
      "Epoch 51/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.2870 - val_loss: 9.1589e-05 - val_mae: 0.0071 - val_mape: 16.5126 - lr: 1.5625e-05\n",
      "Epoch 52/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0254 - mape: 6.7836 - val_loss: 8.3740e-05 - val_mae: 0.0065 - val_mape: 15.9029 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.3012 - val_loss: 9.3267e-05 - val_mae: 0.0066 - val_mape: 18.0224 - lr: 1.5625e-05\n",
      "Epoch 54/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0255 - mape: 7.9806 - val_loss: 9.6925e-05 - val_mae: 0.0070 - val_mape: 17.5407 - lr: 1.5625e-05\n",
      "Epoch 55/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.1081 - val_loss: 9.9308e-05 - val_mae: 0.0069 - val_mape: 17.5261 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0255 - mape: 7.3386 - val_loss: 9.2491e-05 - val_mae: 0.0068 - val_mape: 17.2647 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0251 - mape: 7.2681 - val_loss: 9.3857e-05 - val_mae: 0.0067 - val_mape: 16.5696 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0252 - mape: 7.3115 - val_loss: 9.1458e-05 - val_mae: 0.0066 - val_mape: 16.3617 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.1390 - val_loss: 1.0313e-04 - val_mae: 0.0070 - val_mape: 19.3836 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0254 - mape: 8.2432 - val_loss: 9.5256e-05 - val_mae: 0.0069 - val_mape: 16.9364 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0012 - mae: 0.0253 - mape: 6.1118 - val_loss: 9.3148e-05 - val_mae: 0.0068 - val_mape: 15.8955 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0012 - mae: 0.0254 - mape: 7.2151 - val_loss: 9.0535e-05 - val_mae: 0.0066 - val_mape: 16.9150 - lr: 1.0000e-05\n",
      "Training completed in 503.17 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 3.5396e-04 - mae: 0.0160 - mape: 37.3019\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for doge...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 9s 19ms/step - loss: 0.0278 - mae: 0.0891 - mape: 26.1878 - val_loss: 0.0044 - val_mae: 0.0548 - val_mape: 133.9818 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0066 - mae: 0.0535 - mape: 12.6491 - val_loss: 0.0024 - val_mae: 0.0418 - val_mape: 62.2836 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0051 - mae: 0.0468 - mape: 12.7125 - val_loss: 0.0024 - val_mae: 0.0416 - val_mape: 65.9373 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0041 - mae: 0.0416 - mape: 9.6420 - val_loss: 0.0022 - val_mae: 0.0413 - val_mape: 88.1205 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0040 - mae: 0.0402 - mape: 10.8151 - val_loss: 0.0012 - val_mae: 0.0299 - val_mape: 77.6012 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0036 - mae: 0.0376 - mape: 11.2118 - val_loss: 0.0030 - val_mae: 0.0519 - val_mape: 119.7876 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0035 - mae: 0.0362 - mape: 8.5247 - val_loss: 3.4741e-04 - val_mae: 0.0142 - val_mape: 29.7053 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0033 - mae: 0.0354 - mape: 8.8283 - val_loss: 8.8059e-04 - val_mae: 0.0258 - val_mape: 53.7632 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0032 - mae: 0.0353 - mape: 6.6560 - val_loss: 7.3059e-04 - val_mae: 0.0209 - val_mape: 51.7445 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0029 - mae: 0.0338 - mape: 8.4045 - val_loss: 3.8993e-04 - val_mae: 0.0149 - val_mape: 36.4947 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0027 - mae: 0.0324 - mape: 7.2706 - val_loss: 5.5128e-04 - val_mae: 0.0120 - val_mape: 31.9281 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0030 - mae: 0.0336 - mape: 8.5353 - val_loss: 3.0596e-04 - val_mae: 0.0134 - val_mape: 36.7994 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0023 - mae: 0.0293 - mape: 6.0245 - val_loss: 2.3641e-04 - val_mae: 0.0100 - val_mape: 25.2835 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0023 - mae: 0.0293 - mape: 6.3611 - val_loss: 3.5629e-04 - val_mae: 0.0153 - val_mape: 30.2283 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0023 - mae: 0.0297 - mape: 7.8777 - val_loss: 5.1880e-04 - val_mae: 0.0171 - val_mape: 34.9335 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0021 - mae: 0.0288 - mape: 5.9620 - val_loss: 2.1702e-04 - val_mae: 0.0106 - val_mape: 23.0835 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0022 - mae: 0.0290 - mape: 5.2822 - val_loss: 3.5532e-04 - val_mae: 0.0101 - val_mape: 29.7208 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0023 - mae: 0.0294 - mape: 6.2624 - val_loss: 4.9840e-04 - val_mae: 0.0195 - val_mape: 44.7310 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0020 - mae: 0.0272 - mape: 7.2742 - val_loss: 1.5512e-04 - val_mae: 0.0080 - val_mape: 21.6193 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0020 - mae: 0.0276 - mape: 6.2508 - val_loss: 2.4171e-04 - val_mae: 0.0124 - val_mape: 27.8185 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0019 - mae: 0.0270 - mape: 5.3920 - val_loss: 1.4427e-04 - val_mae: 0.0078 - val_mape: 19.1736 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0019 - mae: 0.0272 - mape: 5.6499 - val_loss: 1.7253e-04 - val_mae: 0.0094 - val_mape: 23.5405 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0019 - mae: 0.0271 - mape: 6.5637 - val_loss: 1.7838e-04 - val_mae: 0.0088 - val_mape: 22.0467 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0264 - mape: 4.9279 - val_loss: 1.6206e-04 - val_mae: 0.0078 - val_mape: 21.2558 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0262 - mape: 5.5742 - val_loss: 2.1824e-04 - val_mae: 0.0109 - val_mape: 23.0307 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0263 - mape: 6.2013 - val_loss: 1.5847e-04 - val_mae: 0.0077 - val_mape: 19.2483 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0017 - mae: 0.0263 - mape: 4.8925 - val_loss: 1.8809e-04 - val_mae: 0.0096 - val_mape: 20.5750 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0017 - mae: 0.0262 - mape: 5.0367 - val_loss: 1.9696e-04 - val_mae: 0.0099 - val_mape: 22.7898 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0018 - mae: 0.0258 - mape: 5.6989 - val_loss: 1.5711e-04 - val_mae: 0.0087 - val_mape: 19.0339 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0259 - mape: 5.5326 - val_loss: 2.3442e-04 - val_mae: 0.0093 - val_mape: 21.8467 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0017 - mae: 0.0259 - mape: 5.1541 - val_loss: 3.5900e-04 - val_mae: 0.0098 - val_mape: 33.8094 - lr: 6.2500e-05\n",
      "Training completed in 266.23 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0230 - mape: 87.4563\n",
      "121/121 [==============================] - 1s 3ms/step\n",
      "Running model for eth...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 20ms/step - loss: 0.0610 - mae: 0.1268 - mape: 59.9777 - val_loss: 0.0382 - val_mae: 0.1737 - val_mape: 988.5375 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 10s 22ms/step - loss: 0.0062 - mae: 0.0580 - mape: 34.3575 - val_loss: 0.0216 - val_mae: 0.1314 - val_mape: 781.4222 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0042 - mae: 0.0483 - mape: 24.7673 - val_loss: 0.0224 - val_mae: 0.1326 - val_mape: 754.6145 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0034 - mae: 0.0436 - mape: 25.2679 - val_loss: 0.0121 - val_mae: 0.0973 - val_mape: 552.6086 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0030 - mae: 0.0411 - mape: 23.3437 - val_loss: 0.0086 - val_mae: 0.0836 - val_mape: 466.2053 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0027 - mae: 0.0379 - mape: 20.7608 - val_loss: 0.0041 - val_mae: 0.0533 - val_mape: 353.5705 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0028 - mae: 0.0386 - mape: 19.6749 - val_loss: 0.0025 - val_mae: 0.0394 - val_mape: 276.0325 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0025 - mae: 0.0364 - mape: 19.1677 - val_loss: 0.0016 - val_mae: 0.0337 - val_mape: 179.9080 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0028 - mae: 0.0363 - mape: 22.9031 - val_loss: 0.0022 - val_mae: 0.0416 - val_mape: 291.8856 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0028 - mae: 0.0363 - mape: 18.9443 - val_loss: 8.8078e-04 - val_mae: 0.0226 - val_mape: 207.8651 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0026 - mae: 0.0354 - mape: 19.6713 - val_loss: 0.0029 - val_mae: 0.0451 - val_mape: 300.9014 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0022 - mae: 0.0336 - mape: 17.9001 - val_loss: 9.2426e-04 - val_mae: 0.0240 - val_mape: 158.6266 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0021 - mae: 0.0333 - mape: 15.3424 - val_loss: 4.4746e-04 - val_mae: 0.0162 - val_mape: 105.3666 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0022 - mae: 0.0329 - mape: 15.3784 - val_loss: 0.0032 - val_mae: 0.0527 - val_mape: 315.0641 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0025 - mae: 0.0339 - mape: 16.0796 - val_loss: 3.1484e-04 - val_mae: 0.0142 - val_mape: 42.3582 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0022 - mae: 0.0330 - mape: 15.5591 - val_loss: 3.5427e-04 - val_mae: 0.0148 - val_mape: 97.0317 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0020 - mae: 0.0319 - mape: 14.7111 - val_loss: 3.7240e-04 - val_mae: 0.0159 - val_mape: 81.5010 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0021 - mae: 0.0328 - mape: 16.5911 - val_loss: 2.4777e-04 - val_mae: 0.0131 - val_mape: 65.5121 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0019 - mae: 0.0316 - mape: 14.5742 - val_loss: 1.4452e-04 - val_mae: 0.0091 - val_mape: 35.7993 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0019 - mae: 0.0314 - mape: 15.0943 - val_loss: 3.8291e-04 - val_mae: 0.0157 - val_mape: 107.2914 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0022 - mae: 0.0324 - mape: 14.8507 - val_loss: 9.9438e-04 - val_mae: 0.0283 - val_mape: 127.8793 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0020 - mae: 0.0315 - mape: 13.7335 - val_loss: 1.8612e-04 - val_mae: 0.0098 - val_mape: 56.3890 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0020 - mae: 0.0309 - mape: 14.2963 - val_loss: 1.1871e-04 - val_mae: 0.0080 - val_mape: 33.8599 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0303 - mape: 14.0516 - val_loss: 2.9919e-04 - val_mae: 0.0138 - val_mape: 47.8484 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0017 - mae: 0.0287 - mape: 11.0786 - val_loss: 3.2552e-04 - val_mae: 0.0148 - val_mape: 57.0204 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0286 - mape: 12.1148 - val_loss: 2.0857e-04 - val_mae: 0.0113 - val_mape: 29.5405 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0282 - mape: 12.9141 - val_loss: 2.1018e-04 - val_mae: 0.0113 - val_mape: 70.0157 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0287 - mape: 12.6851 - val_loss: 1.5873e-04 - val_mae: 0.0098 - val_mape: 46.1080 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0287 - mape: 12.5579 - val_loss: 1.5382e-04 - val_mae: 0.0094 - val_mape: 27.6693 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0016 - mae: 0.0277 - mape: 11.3103 - val_loss: 1.9001e-04 - val_mae: 0.0104 - val_mape: 55.4902 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0274 - mape: 11.3977 - val_loss: 4.2644e-04 - val_mae: 0.0175 - val_mape: 69.7126 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0275 - mape: 11.3495 - val_loss: 5.8135e-04 - val_mae: 0.0214 - val_mape: 91.6675 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0276 - mape: 13.4830 - val_loss: 1.3728e-04 - val_mae: 0.0087 - val_mape: 41.2818 - lr: 2.5000e-04\n",
      "Training completed in 290.68 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0900 - mape: 42.0364\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for xmr...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 9s 19ms/step - loss: 0.0163 - mae: 0.0781 - mape: 72.9502 - val_loss: 0.0021 - val_mae: 0.0400 - val_mape: 1943.5966 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0052 - mae: 0.0524 - mape: 43.9262 - val_loss: 0.0042 - val_mae: 0.0582 - val_mape: 3741.0894 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0037 - mae: 0.0436 - mape: 28.1689 - val_loss: 0.0016 - val_mae: 0.0359 - val_mape: 2251.2046 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0033 - mae: 0.0412 - mape: 35.1725 - val_loss: 6.2598e-04 - val_mae: 0.0217 - val_mape: 1243.8193 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0031 - mae: 0.0397 - mape: 35.8399 - val_loss: 5.8333e-04 - val_mae: 0.0200 - val_mape: 1390.4194 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0029 - mae: 0.0384 - mape: 37.7182 - val_loss: 0.0028 - val_mae: 0.0495 - val_mape: 2902.7402 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0028 - mae: 0.0373 - mape: 32.2846 - val_loss: 5.6022e-04 - val_mae: 0.0197 - val_mape: 1321.4484 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0026 - mae: 0.0360 - mape: 34.3098 - val_loss: 0.0010 - val_mae: 0.0285 - val_mape: 1649.0646 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0025 - mae: 0.0355 - mape: 28.9933 - val_loss: 3.1718e-04 - val_mae: 0.0142 - val_mape: 907.9081 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0024 - mae: 0.0349 - mape: 27.6980 - val_loss: 0.0012 - val_mae: 0.0315 - val_mape: 1715.1104 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0023 - mae: 0.0343 - mape: 42.6695 - val_loss: 3.2188e-04 - val_mae: 0.0145 - val_mape: 650.1829 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0024 - mae: 0.0348 - mape: 31.6526 - val_loss: 1.7399e-04 - val_mae: 0.0097 - val_mape: 636.7244 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0022 - mae: 0.0330 - mape: 21.2836 - val_loss: 1.8862e-04 - val_mae: 0.0104 - val_mape: 281.5509 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0022 - mae: 0.0334 - mape: 26.2482 - val_loss: 1.8831e-04 - val_mae: 0.0106 - val_mape: 180.7348 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0022 - mae: 0.0328 - mape: 25.1585 - val_loss: 1.6616e-04 - val_mae: 0.0096 - val_mape: 358.3419 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0020 - mae: 0.0319 - mape: 33.0788 - val_loss: 1.1790e-04 - val_mae: 0.0077 - val_mape: 159.9325 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0317 - mape: 23.6246 - val_loss: 8.7862e-04 - val_mae: 0.0274 - val_mape: 1320.7743 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0293 - mape: 22.1233 - val_loss: 1.1238e-04 - val_mae: 0.0077 - val_mape: 184.2539 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0017 - mae: 0.0294 - mape: 18.5730 - val_loss: 2.0091e-04 - val_mae: 0.0114 - val_mape: 654.8549 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0017 - mae: 0.0293 - mape: 22.9181 - val_loss: 1.0172e-04 - val_mae: 0.0071 - val_mape: 210.5876 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0292 - mape: 25.8091 - val_loss: 1.1306e-04 - val_mae: 0.0078 - val_mape: 236.0453 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0291 - mape: 33.4501 - val_loss: 1.2515e-04 - val_mae: 0.0083 - val_mape: 109.0699 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0278 - mape: 27.8511 - val_loss: 1.1116e-04 - val_mae: 0.0077 - val_mape: 288.2821 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0016 - mae: 0.0279 - mape: 16.3610 - val_loss: 1.1099e-04 - val_mae: 0.0076 - val_mape: 185.6702 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0276 - mape: 20.9412 - val_loss: 9.4477e-05 - val_mae: 0.0070 - val_mape: 83.7359 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0276 - mape: 19.9222 - val_loss: 8.6483e-05 - val_mae: 0.0064 - val_mape: 183.2583 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0275 - mape: 20.2822 - val_loss: 8.7462e-05 - val_mae: 0.0065 - val_mape: 38.7341 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0015 - mae: 0.0266 - mape: 17.5705 - val_loss: 9.9347e-05 - val_mae: 0.0074 - val_mape: 186.6472 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0264 - mape: 16.5759 - val_loss: 1.6960e-04 - val_mae: 0.0108 - val_mape: 523.9640 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0266 - mape: 14.8633 - val_loss: 1.2387e-04 - val_mae: 0.0087 - val_mape: 417.1274 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0270 - mape: 19.7595 - val_loss: 9.6544e-05 - val_mae: 0.0073 - val_mape: 267.0626 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0266 - mape: 15.8422 - val_loss: 2.0997e-04 - val_mae: 0.0123 - val_mape: 499.3749 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0264 - mape: 16.2489 - val_loss: 7.0000e-05 - val_mae: 0.0056 - val_mape: 99.8974 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0262 - mape: 14.7472 - val_loss: 8.3785e-05 - val_mae: 0.0064 - val_mape: 180.6530 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0263 - mape: 21.8104 - val_loss: 7.5730e-05 - val_mae: 0.0060 - val_mape: 184.8351 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0261 - mape: 16.4434 - val_loss: 8.1362e-05 - val_mae: 0.0064 - val_mape: 187.8595 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0260 - mape: 13.9725 - val_loss: 7.2909e-05 - val_mae: 0.0059 - val_mape: 187.3339 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0260 - mape: 18.5965 - val_loss: 9.1950e-05 - val_mae: 0.0071 - val_mape: 182.1993 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0259 - mape: 17.6962 - val_loss: 6.9953e-05 - val_mae: 0.0057 - val_mape: 181.2198 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0257 - mape: 15.5577 - val_loss: 7.0799e-05 - val_mae: 0.0057 - val_mape: 121.8858 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0259 - mape: 20.3512 - val_loss: 7.2214e-05 - val_mae: 0.0059 - val_mape: 136.4983 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0258 - mape: 18.4885 - val_loss: 7.5877e-05 - val_mae: 0.0061 - val_mape: 147.9943 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0256 - mape: 15.6693 - val_loss: 8.9435e-05 - val_mae: 0.0070 - val_mape: 289.3907 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0256 - mape: 14.9261 - val_loss: 7.1500e-05 - val_mae: 0.0058 - val_mape: 160.4366 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0256 - mape: 13.8181 - val_loss: 7.1031e-05 - val_mae: 0.0058 - val_mape: 175.5048 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0257 - mape: 16.8186 - val_loss: 7.3334e-05 - val_mae: 0.0059 - val_mape: 192.6062 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0257 - mape: 15.8897 - val_loss: 7.8644e-05 - val_mae: 0.0064 - val_mape: 231.0715 - lr: 1.5625e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0013 - mae: 0.0253 - mape: 12.1073 - val_loss: 7.3354e-05 - val_mae: 0.0060 - val_mape: 228.6049 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0255 - mape: 17.4701 - val_loss: 7.3235e-05 - val_mae: 0.0060 - val_mape: 214.4760 - lr: 1.0000e-05\n",
      "Training completed in 412.73 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 5.9094e-04 - mae: 0.0161 - mape: 106.5858\n",
      "121/121 [==============================] - 1s 3ms/step\n",
      "Running model for xrp...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 9s 18ms/step - loss: 0.0222 - mae: 0.0864 - mape: 31.1211 - val_loss: 0.0071 - val_mae: 0.0756 - val_mape: 210.8768 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0056 - mae: 0.0527 - mape: 15.1537 - val_loss: 0.0031 - val_mae: 0.0476 - val_mape: 121.7100 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0043 - mae: 0.0461 - mape: 13.1909 - val_loss: 0.0059 - val_mae: 0.0704 - val_mape: 185.5171 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0037 - mae: 0.0423 - mape: 12.4088 - val_loss: 0.0016 - val_mae: 0.0339 - val_mape: 87.4553 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0033 - mae: 0.0398 - mape: 12.2257 - val_loss: 0.0014 - val_mae: 0.0308 - val_mape: 85.0574 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0031 - mae: 0.0383 - mape: 11.1985 - val_loss: 0.0017 - val_mae: 0.0348 - val_mape: 96.4139 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0029 - mae: 0.0369 - mape: 11.6138 - val_loss: 0.0015 - val_mae: 0.0327 - val_mape: 88.1860 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0030 - mae: 0.0367 - mape: 11.1992 - val_loss: 0.0020 - val_mae: 0.0383 - val_mape: 118.1180 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 7s 18ms/step - loss: 0.0028 - mae: 0.0360 - mape: 11.3754 - val_loss: 7.6385e-04 - val_mae: 0.0208 - val_mape: 66.4324 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0027 - mae: 0.0352 - mape: 10.2600 - val_loss: 6.5922e-04 - val_mae: 0.0197 - val_mape: 46.0686 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0027 - mae: 0.0347 - mape: 10.1582 - val_loss: 7.0169e-04 - val_mae: 0.0201 - val_mape: 57.0697 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0026 - mae: 0.0344 - mape: 9.8789 - val_loss: 5.9416e-04 - val_mae: 0.0174 - val_mape: 41.6399 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0025 - mae: 0.0331 - mape: 9.9006 - val_loss: 9.9909e-04 - val_mae: 0.0271 - val_mape: 75.1210 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0025 - mae: 0.0341 - mape: 10.0237 - val_loss: 6.2909e-04 - val_mae: 0.0191 - val_mape: 60.7245 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0023 - mae: 0.0325 - mape: 9.3363 - val_loss: 5.5860e-04 - val_mae: 0.0177 - val_mape: 46.1747 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0025 - mae: 0.0338 - mape: 10.4916 - val_loss: 3.9155e-04 - val_mae: 0.0118 - val_mape: 18.5014 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0023 - mae: 0.0325 - mape: 9.3195 - val_loss: 4.2457e-04 - val_mae: 0.0141 - val_mape: 28.0743 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 7s 18ms/step - loss: 0.0023 - mae: 0.0323 - mape: 9.5724 - val_loss: 3.6698e-04 - val_mae: 0.0119 - val_mape: 22.7962 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 7s 18ms/step - loss: 0.0022 - mae: 0.0317 - mape: 9.4198 - val_loss: 4.0016e-04 - val_mae: 0.0143 - val_mape: 32.6340 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0021 - mae: 0.0315 - mape: 8.8490 - val_loss: 9.6743e-04 - val_mae: 0.0270 - val_mape: 64.2229 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0021 - mae: 0.0309 - mape: 9.1166 - val_loss: 8.6957e-04 - val_mae: 0.0260 - val_mape: 53.7571 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0018 - mae: 0.0289 - mape: 8.1765 - val_loss: 2.6337e-04 - val_mae: 0.0090 - val_mape: 22.0558 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0290 - mape: 7.9836 - val_loss: 2.9940e-04 - val_mae: 0.0111 - val_mape: 35.0181 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 7s 18ms/step - loss: 0.0018 - mae: 0.0285 - mape: 8.4105 - val_loss: 2.7543e-04 - val_mae: 0.0102 - val_mape: 19.1392 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0286 - mape: 7.4511 - val_loss: 2.6479e-04 - val_mae: 0.0089 - val_mape: 14.7958 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0283 - mape: 8.3706 - val_loss: 3.1989e-04 - val_mae: 0.0117 - val_mape: 22.2923 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0289 - mape: 8.0192 - val_loss: 5.5771e-04 - val_mae: 0.0192 - val_mape: 42.0496 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0017 - mae: 0.0277 - mape: 7.5210 - val_loss: 2.8552e-04 - val_mae: 0.0109 - val_mape: 20.2622 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0017 - mae: 0.0277 - mape: 7.2058 - val_loss: 5.0549e-04 - val_mae: 0.0185 - val_mape: 44.5944 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0017 - mae: 0.0275 - mape: 7.7618 - val_loss: 2.1110e-04 - val_mae: 0.0075 - val_mape: 16.1855 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0274 - mape: 6.8441 - val_loss: 2.1000e-04 - val_mae: 0.0075 - val_mape: 10.8688 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0272 - mape: 7.6326 - val_loss: 2.1110e-04 - val_mae: 0.0073 - val_mape: 17.7887 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0017 - mae: 0.0270 - mape: 7.1184 - val_loss: 2.2669e-04 - val_mae: 0.0089 - val_mape: 21.3031 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0266 - mape: 7.3462 - val_loss: 2.2996e-04 - val_mae: 0.0090 - val_mape: 17.2613 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0267 - mape: 7.0764 - val_loss: 3.3448e-04 - val_mae: 0.0137 - val_mape: 29.0472 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0264 - mape: 7.3264 - val_loss: 2.0079e-04 - val_mae: 0.0069 - val_mape: 11.7064 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0265 - mape: 6.9937 - val_loss: 1.9121e-04 - val_mae: 0.0064 - val_mape: 10.3033 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0261 - mape: 6.9447 - val_loss: 1.9320e-04 - val_mae: 0.0069 - val_mape: 11.9669 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0262 - mape: 6.7860 - val_loss: 1.9754e-04 - val_mae: 0.0073 - val_mape: 12.4472 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0260 - mape: 6.5744 - val_loss: 1.9965e-04 - val_mae: 0.0070 - val_mape: 11.8164 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0263 - mape: 7.0686 - val_loss: 1.8537e-04 - val_mae: 0.0063 - val_mape: 9.7780 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0262 - mape: 7.0941 - val_loss: 2.4697e-04 - val_mae: 0.0102 - val_mape: 19.3945 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0261 - mape: 7.1286 - val_loss: 2.0206e-04 - val_mae: 0.0076 - val_mape: 12.0474 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0261 - mape: 6.9259 - val_loss: 1.9483e-04 - val_mae: 0.0072 - val_mape: 13.1151 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0261 - mape: 7.1290 - val_loss: 1.9406e-04 - val_mae: 0.0070 - val_mape: 11.0427 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0260 - mape: 7.1580 - val_loss: 2.1384e-04 - val_mae: 0.0085 - val_mape: 15.8497 - lr: 3.1250e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0260 - mape: 7.0306 - val_loss: 1.9645e-04 - val_mae: 0.0074 - val_mape: 14.9552 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0258 - mape: 6.9805 - val_loss: 1.8712e-04 - val_mae: 0.0068 - val_mape: 11.3345 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0257 - mape: 7.0266 - val_loss: 1.7899e-04 - val_mae: 0.0060 - val_mape: 9.2808 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0260 - mape: 7.0099 - val_loss: 1.9031e-04 - val_mae: 0.0071 - val_mape: 13.5277 - lr: 1.5625e-05\n",
      "Epoch 51/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0257 - mape: 6.5217 - val_loss: 1.8109e-04 - val_mae: 0.0061 - val_mape: 9.4828 - lr: 1.5625e-05\n",
      "Epoch 52/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0259 - mape: 6.7750 - val_loss: 1.8886e-04 - val_mae: 0.0070 - val_mape: 13.4878 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0257 - mape: 6.5428 - val_loss: 1.8380e-04 - val_mae: 0.0065 - val_mape: 11.9731 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0255 - mape: 6.6532 - val_loss: 1.9129e-04 - val_mae: 0.0072 - val_mape: 13.3323 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0257 - mape: 7.0011 - val_loss: 1.8009e-04 - val_mae: 0.0063 - val_mape: 10.7732 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0258 - mape: 7.0270 - val_loss: 1.7980e-04 - val_mae: 0.0063 - val_mape: 11.0152 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0256 - mape: 6.8451 - val_loss: 1.8226e-04 - val_mae: 0.0065 - val_mape: 11.5441 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0259 - mape: 6.7412 - val_loss: 1.8406e-04 - val_mae: 0.0067 - val_mape: 12.1307 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0259 - mape: 6.6338 - val_loss: 1.9901e-04 - val_mae: 0.0077 - val_mape: 15.9239 - lr: 1.0000e-05\n",
      "Training completed in 453.96 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 1.6218e-04 - mae: 0.0085 - mape: 30.1665\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for aave...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 76ms/step - loss: 0.7130 - mae: 0.7572 - mape: 88.2935 - val_loss: 0.0390 - val_mae: 0.1654 - val_mape: 114.2217 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2945 - mae: 0.4153 - mape: 58.4588 - val_loss: 0.1816 - val_mae: 0.3873 - val_mape: 576.7669 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1615 - mae: 0.3279 - mape: 58.9830 - val_loss: 0.3755 - val_mae: 0.5858 - val_mape: 877.1075 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1129 - mae: 0.2645 - mape: 47.0809 - val_loss: 0.1522 - val_mae: 0.3506 - val_mape: 555.3702 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1207 - mae: 0.2722 - mape: 55.2102 - val_loss: 0.0643 - val_mae: 0.2153 - val_mape: 330.4379 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0981 - mae: 0.2354 - mape: 59.3035 - val_loss: 0.0435 - val_mae: 0.1720 - val_mape: 203.5553 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0742 - mae: 0.2080 - mape: 37.9282 - val_loss: 0.0363 - val_mae: 0.1560 - val_mape: 192.1570 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0698 - mae: 0.1967 - mape: 37.5734 - val_loss: 0.0391 - val_mae: 0.1563 - val_mape: 208.5334 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0622 - mae: 0.1925 - mape: 33.2609 - val_loss: 0.0410 - val_mae: 0.1588 - val_mape: 214.8794 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0694 - mae: 0.1966 - mape: 34.3835 - val_loss: 0.0386 - val_mae: 0.1539 - val_mape: 195.9573 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0702 - mae: 0.1939 - mape: 36.8173 - val_loss: 0.0362 - val_mae: 0.1504 - val_mape: 178.7485 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0728 - mae: 0.2043 - mape: 36.6896 - val_loss: 0.0359 - val_mae: 0.1478 - val_mape: 178.2253 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0658 - mae: 0.1962 - mape: 38.3058 - val_loss: 0.0380 - val_mae: 0.1519 - val_mape: 195.8380 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0697 - mae: 0.1977 - mape: 37.0088 - val_loss: 0.0406 - val_mae: 0.1563 - val_mape: 219.2080 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0571 - mae: 0.1765 - mape: 34.8111 - val_loss: 0.0351 - val_mae: 0.1435 - val_mape: 189.3771 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0587 - mae: 0.1811 - mape: 33.9496 - val_loss: 0.0325 - val_mae: 0.1392 - val_mape: 165.5507 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0598 - mae: 0.1855 - mape: 35.2762 - val_loss: 0.0383 - val_mae: 0.1570 - val_mape: 195.1548 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0603 - mae: 0.1833 - mape: 34.9580 - val_loss: 0.0494 - val_mae: 0.1855 - val_mape: 233.4325 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0574 - mae: 0.1782 - mape: 32.7562 - val_loss: 0.0391 - val_mae: 0.1588 - val_mape: 192.6166 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0573 - mae: 0.1799 - mape: 33.5127 - val_loss: 0.0374 - val_mae: 0.1538 - val_mape: 187.9625 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0610 - mae: 0.1869 - mape: 33.1955 - val_loss: 0.0501 - val_mae: 0.1891 - val_mape: 237.7569 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0572 - mae: 0.1799 - mape: 31.5326 - val_loss: 0.0428 - val_mae: 0.1708 - val_mape: 212.6192 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0578 - mae: 0.1780 - mape: 34.0437 - val_loss: 0.0366 - val_mae: 0.1536 - val_mape: 189.1027 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0516 - mae: 0.1633 - mape: 29.3211 - val_loss: 0.0342 - val_mae: 0.1464 - val_mape: 178.3242 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0545 - mae: 0.1740 - mape: 32.2657 - val_loss: 0.0335 - val_mae: 0.1454 - val_mape: 174.0018 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0562 - mae: 0.1821 - mape: 33.5797 - val_loss: 0.0339 - val_mae: 0.1480 - val_mape: 170.3373 - lr: 2.5000e-04\n",
      "Training completed in 3.05 seconds\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0159 - mae: 0.1021 - mape: 16.1040\n",
      "1/1 [==============================] - 0s 143ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ada</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.478494</td>\n",
       "      <td>0.678623</td>\n",
       "      <td>1.920413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btc</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.373019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doge</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.023030</td>\n",
       "      <td>0.874563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eth</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>0.420364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xmr</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>1.065858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xrp</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>0.301665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aave</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.102130</td>\n",
       "      <td>0.161040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data        Model       MSE       MAE      MAPE\n",
       "0   ada  Transformer  0.478494  0.678623  1.920413\n",
       "1   btc  Transformer  0.000354  0.016008  0.373019\n",
       "2  doge  Transformer  0.001068  0.023030  0.874563\n",
       "3   eth  Transformer  0.012137  0.090027  0.420364\n",
       "4   xmr  Transformer  0.000591  0.016065  1.065858\n",
       "5   xrp  Transformer  0.000162  0.008548  0.301665\n",
       "6  aave  Transformer  0.015875  0.102130  0.161040"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    \n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_transformer_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    transformer = 'Transformer'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': transformer,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "transformer_df = pd.DataFrame(summary_table)\n",
    "transformer_df.to_csv('../results/transformer.csv')\n",
    "transformer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d461914cba7065",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "880f3e064afc9f91",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T13:48:44.024813Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada</th>\n",
       "      <th>btc</th>\n",
       "      <th>doge</th>\n",
       "      <th>eth</th>\n",
       "      <th>xmr</th>\n",
       "      <th>xrp</th>\n",
       "      <th>aave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.121723</td>\n",
       "      <td>0.058811</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>0.039746</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.540885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM-CNN</th>\n",
       "      <td>0.094137</td>\n",
       "      <td>0.035705</td>\n",
       "      <td>0.055242</td>\n",
       "      <td>0.016264</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>0.026604</td>\n",
       "      <td>0.31276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transformer</th>\n",
       "      <td>0.678623</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.02303</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>0.10213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ada       btc      doge       eth       xmr       xrp  \\\n",
       "LSTM         0.121723  0.058811  0.023134  0.039746  0.018086  0.018221   \n",
       "LSTM-CNN     0.094137  0.035705  0.055242  0.016264  0.094177  0.026604   \n",
       "Transformer  0.678623  0.016008   0.02303  0.090027  0.016065  0.008548   \n",
       "\n",
       "                 aave  \n",
       "LSTM         0.540885  \n",
       "LSTM-CNN      0.31276  \n",
       "Transformer   0.10213  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['LSTM', 'LSTM-CNN', 'Transformer']\n",
    "cryptos = ['ada', 'btc', 'doge', 'eth', 'xmr', 'xrp', 'aave']\n",
    "file_paths = ['../results/lstm.csv', '../results/lstm_cnn.csv', '../results/transformer.csv']\n",
    "\n",
    "results = pd.DataFrame(index=models, columns=cryptos)\n",
    "\n",
    "# Loop through each file and each crypto to fill the DataFrame\n",
    "for model, file_path in zip(models, file_paths):\n",
    "    df = pd.read_csv(file_path)\n",
    "    for crypto in cryptos:\n",
    "        # Assuming the MAE column in each file is named 'test_mae'\n",
    "        results.at[model, crypto] = df.loc[df['Data'] == crypto, 'MAE'].values[0]\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
