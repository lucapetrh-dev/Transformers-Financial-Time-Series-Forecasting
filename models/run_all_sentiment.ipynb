{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:33:56.556032Z",
     "start_time": "2024-05-02T14:33:56.537840Z"
    }
   },
   "id": "180c947e7839a277"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:34:00.255944Z",
     "start_time": "2024-05-02T14:33:57.030804Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.scripts.utils import preprocess, trigonometric_date_encoding\n",
    "\n",
    "file_paths = ['../data/hourly/ada_lunarcrush_timeseries_hourly.csv', '../data/hourly/btc_lunarcrush_timeseries_hourly.csv', '../data/hourly/doge_lunarcrush_timeseries_hourly.csv', '../data/hourly/eth_lunarcrush_timeseries_hourly.csv', '../data/hourly/xmr_lunarcrush_timeseries_hourly.csv', '../data/hourly/xrp_lunarcrush_timeseries_hourly.csv', '../data/hourly/aave_lunarcrash_timeseries_hourly.csv']\n",
    "\n",
    "columns_to_keep = ['timestamp', 'time', 'open', 'close', 'high', 'low', 'volume_24h', 'market_cap', 'social_contributors', 'social_volume', 'tweets', 'day', 'month', 'year', 'Month_Category_Bearish', 'Month_Category_Bullish', 'Month_Category_Normal', 'ROC_0', 'ROC_1', 'ROC_2']\n",
    "\n",
    "crypto_dfs = {}\n",
    "for path in file_paths:\n",
    "    crypto = os.path.basename(path).split('_')[0]\n",
    "    if os.path.exists(path):  # Check if the file exists\n",
    "        crypto_dfs[crypto] = preprocess(path)\n",
    "        crypto_dfs[crypto] = crypto_dfs[crypto][[col for col in crypto_dfs[crypto].columns if col in columns_to_keep]]\n",
    "    else:\n",
    "        print(f\"File does not exist: {path}\")  # For debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training on Sentiment-enhanced data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11179a2896eceb81"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "597f8917256c21be"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras.models import Model as tfkModel\n",
    "\n",
    "def build_simple_LSTM_regressor(input_shape, output_units=1):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm = tfkl.LSTM(64, activation='leaky_relu', return_sequences=True)(input_layer)\n",
    "    lstm = tfkl.LSTM(64, activation='leaky_relu')(lstm)\n",
    "\n",
    "    # Output layer for regression\n",
    "    output_layer = tfkl.Dense(output_units)(lstm)  # Single unit for regression output\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfkModel(inputs=input_layer, outputs=output_layer, name='Simple_LSTM_regressor')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:34:45.199283Z",
     "start_time": "2024-05-02T14:34:42.517186Z"
    }
   },
   "id": "d6fecc91004f7446"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def fit(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    # Assuming input_shape is (5, n_features)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_units = 1\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_simple_LSTM_regressor(input_shape, output_units)\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    ).history\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:34:45.200063Z",
     "start_time": "2024-05-02T14:34:45.197375Z"
    }
   },
   "id": "e5333f00c89b193"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:34:45.251888Z",
     "start_time": "2024-05-02T14:34:45.200338Z"
    }
   },
   "id": "4695c6a453c2d6de"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 5, 64)             22272     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55361 (216.25 KB)\n",
      "Trainable params: 55361 (216.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0240 - mae: 0.0581 - val_loss: 0.0021 - val_mae: 0.0370 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0195 - val_loss: 6.8806e-04 - val_mae: 0.0199 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 8.2191e-04 - mae: 0.0172 - val_loss: 6.2626e-04 - val_mae: 0.0200 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 7.3670e-04 - mae: 0.0159 - val_loss: 7.5602e-04 - val_mae: 0.0227 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 6.6532e-04 - mae: 0.0150 - val_loss: 7.8714e-04 - val_mae: 0.0244 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 6.0933e-04 - mae: 0.0145 - val_loss: 0.0011 - val_mae: 0.0268 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 5.2643e-04 - mae: 0.0138 - val_loss: 8.1769e-04 - val_mae: 0.0242 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.8524e-04 - mae: 0.0112 - val_loss: 7.2777e-04 - val_mae: 0.0234 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.4216e-04 - mae: 0.0106 - val_loss: 7.4537e-04 - val_mae: 0.0233 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.3949e-04 - mae: 0.0108 - val_loss: 0.0012 - val_mae: 0.0301 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.0263e-04 - mae: 0.0102 - val_loss: 7.4980e-04 - val_mae: 0.0237 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.9905e-04 - mae: 0.0102 - val_loss: 6.2360e-04 - val_mae: 0.0216 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4501e-04 - mae: 0.0089 - val_loss: 6.9708e-04 - val_mae: 0.0229 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4293e-04 - mae: 0.0089 - val_loss: 8.9617e-04 - val_mae: 0.0261 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4353e-04 - mae: 0.0091 - val_loss: 7.0941e-04 - val_mae: 0.0230 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.3104e-04 - mae: 0.0088 - val_loss: 7.8907e-04 - val_mae: 0.0252 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.2114e-04 - mae: 0.0086 - val_loss: 0.0010 - val_mae: 0.0282 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.0170e-04 - mae: 0.0080 - val_loss: 7.7290e-04 - val_mae: 0.0246 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.9729e-04 - mae: 0.0079 - val_loss: 7.6035e-04 - val_mae: 0.0242 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.9119e-04 - mae: 0.0079 - val_loss: 9.1298e-04 - val_mae: 0.0268 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.8678e-04 - mae: 0.0078 - val_loss: 7.7213e-04 - val_mae: 0.0245 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.8513e-04 - mae: 0.0078 - val_loss: 8.0105e-04 - val_mae: 0.0250 - lr: 1.2500e-04\n",
      "121/121 [==============================] - 0s 762us/step - loss: 0.0033 - mae: 0.0504\n",
      "121/121 [==============================] - 0s 776us/step\n",
      "Running model for btc...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 5, 64)             22272     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55361 (216.25 KB)\n",
      "Trainable params: 55361 (216.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0310 - mae: 0.0678 - val_loss: 0.0032 - val_mae: 0.0419 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.7273e-04 - mae: 0.0180 - val_loss: 0.0016 - val_mae: 0.0297 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 6.1121e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mae: 0.0257 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.4645e-04 - mae: 0.0154 - val_loss: 6.8332e-04 - val_mae: 0.0203 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.0133e-04 - mae: 0.0146 - val_loss: 6.5256e-04 - val_mae: 0.0198 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.4120e-04 - mae: 0.0138 - val_loss: 7.7183e-04 - val_mae: 0.0216 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.0924e-04 - mae: 0.0135 - val_loss: 0.0011 - val_mae: 0.0256 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.7998e-04 - mae: 0.0131 - val_loss: 5.8005e-04 - val_mae: 0.0184 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.0984e-04 - mae: 0.0134 - val_loss: 7.1832e-04 - val_mae: 0.0207 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.1918e-04 - mae: 0.0118 - val_loss: 4.3526e-04 - val_mae: 0.0160 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.7318e-04 - mae: 0.0111 - val_loss: 4.8555e-04 - val_mae: 0.0168 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.6116e-04 - mae: 0.0111 - val_loss: 3.1324e-04 - val_mae: 0.0142 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.7358e-04 - mae: 0.0114 - val_loss: 5.2144e-04 - val_mae: 0.0191 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.3241e-04 - mae: 0.0104 - val_loss: 2.7212e-04 - val_mae: 0.0133 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.9935e-04 - mae: 0.0097 - val_loss: 2.3788e-04 - val_mae: 0.0123 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.1391e-04 - mae: 0.0100 - val_loss: 3.4861e-04 - val_mae: 0.0144 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.1026e-04 - mae: 0.0098 - val_loss: 3.0176e-04 - val_mae: 0.0140 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.4883e-04 - mae: 0.0079 - val_loss: 2.0495e-04 - val_mae: 0.0116 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.4247e-04 - mae: 0.0079 - val_loss: 1.6027e-04 - val_mae: 0.0102 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.3680e-04 - mae: 0.0078 - val_loss: 1.6894e-04 - val_mae: 0.0104 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.4612e-04 - mae: 0.0082 - val_loss: 1.6377e-04 - val_mae: 0.0106 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.3707e-04 - mae: 0.0078 - val_loss: 1.3510e-04 - val_mae: 0.0093 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.3393e-04 - mae: 0.0079 - val_loss: 1.7484e-04 - val_mae: 0.0106 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.1587e-04 - mae: 0.0068 - val_loss: 1.3837e-04 - val_mae: 0.0097 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.1412e-04 - mae: 0.0069 - val_loss: 1.3288e-04 - val_mae: 0.0095 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.1023e-04 - mae: 0.0068 - val_loss: 1.2742e-04 - val_mae: 0.0091 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.1318e-04 - mae: 0.0069 - val_loss: 9.8472e-05 - val_mae: 0.0079 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.0764e-04 - mae: 0.0067 - val_loss: 1.4064e-04 - val_mae: 0.0099 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.0751e-04 - mae: 0.0068 - val_loss: 1.1330e-04 - val_mae: 0.0088 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.0648e-04 - mae: 0.0068 - val_loss: 1.5752e-04 - val_mae: 0.0106 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.0185e-04 - mae: 0.0066 - val_loss: 1.0820e-04 - val_mae: 0.0083 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.0340e-04 - mae: 0.0067 - val_loss: 1.2352e-04 - val_mae: 0.0091 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 9.0676e-05 - mae: 0.0060 - val_loss: 1.1092e-04 - val_mae: 0.0086 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 9.1791e-05 - mae: 0.0061 - val_loss: 8.3254e-05 - val_mae: 0.0073 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 9.0843e-05 - mae: 0.0061 - val_loss: 9.1939e-05 - val_mae: 0.0078 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 8.9279e-05 - mae: 0.0060 - val_loss: 1.1036e-04 - val_mae: 0.0086 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 9.0572e-05 - mae: 0.0061 - val_loss: 1.1361e-04 - val_mae: 0.0088 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 8.3486e-05 - mae: 0.0057 - val_loss: 1.0281e-04 - val_mae: 0.0082 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 8.2902e-05 - mae: 0.0057 - val_loss: 1.3090e-04 - val_mae: 0.0093 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 8.2113e-05 - mae: 0.0057 - val_loss: 8.2261e-05 - val_mae: 0.0073 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 8.2577e-05 - mae: 0.0057 - val_loss: 1.0820e-04 - val_mae: 0.0085 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 8.1797e-05 - mae: 0.0057 - val_loss: 9.7457e-05 - val_mae: 0.0080 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.8912e-05 - mae: 0.0055 - val_loss: 1.1127e-04 - val_mae: 0.0086 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 7.8845e-05 - mae: 0.0055 - val_loss: 1.1034e-04 - val_mae: 0.0086 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.8226e-05 - mae: 0.0055 - val_loss: 9.9043e-05 - val_mae: 0.0081 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.8024e-05 - mae: 0.0055 - val_loss: 1.2023e-04 - val_mae: 0.0089 - lr: 3.1250e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.8274e-05 - mae: 0.0055 - val_loss: 1.1347e-04 - val_mae: 0.0087 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 7.6641e-05 - mae: 0.0054 - val_loss: 1.1803e-04 - val_mae: 0.0089 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 7.6203e-05 - mae: 0.0054 - val_loss: 1.0393e-04 - val_mae: 0.0084 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.6015e-05 - mae: 0.0054 - val_loss: 1.0190e-04 - val_mae: 0.0082 - lr: 1.5625e-05\n",
      "121/121 [==============================] - 0s 801us/step - loss: 4.8568e-04 - mae: 0.0159\n",
      "121/121 [==============================] - 0s 817us/step\n",
      "Running model for doge...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 5, 64)             22272     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55361 (216.25 KB)\n",
      "Trainable params: 55361 (216.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0291 - mae: 0.0644 - val_loss: 0.0042 - val_mae: 0.0570 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0218 - val_loss: 0.0034 - val_mae: 0.0520 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0018 - mae: 0.0198 - val_loss: 0.0019 - val_mae: 0.0380 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 5.2869e-04 - val_mae: 0.0182 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0179 - val_loss: 4.9202e-04 - val_mae: 0.0169 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0155 - val_loss: 6.4557e-04 - val_mae: 0.0204 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 8.4860e-04 - mae: 0.0145 - val_loss: 5.3236e-04 - val_mae: 0.0181 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 4.9424e-04 - val_mae: 0.0166 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 8.6530e-04 - mae: 0.0151 - val_loss: 6.3748e-04 - val_mae: 0.0199 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.4686e-04 - mae: 0.0107 - val_loss: 5.4128e-04 - val_mae: 0.0171 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 5.0082e-04 - mae: 0.0104 - val_loss: 4.0921e-04 - val_mae: 0.0153 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 5.1739e-04 - mae: 0.0108 - val_loss: 3.7828e-04 - val_mae: 0.0144 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 4.7880e-04 - mae: 0.0106 - val_loss: 5.6483e-04 - val_mae: 0.0203 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.3355e-04 - mae: 0.0111 - val_loss: 4.9361e-04 - val_mae: 0.0187 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.4173e-04 - mae: 0.0114 - val_loss: 2.8708e-04 - val_mae: 0.0133 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.7866e-04 - mae: 0.0105 - val_loss: 3.7205e-04 - val_mae: 0.0146 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.1976e-04 - mae: 0.0101 - val_loss: 3.5242e-04 - val_mae: 0.0148 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.8898e-04 - mae: 0.0108 - val_loss: 9.2427e-04 - val_mae: 0.0271 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.5483e-04 - mae: 0.0103 - val_loss: 5.3708e-04 - val_mae: 0.0164 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.2169e-04 - mae: 0.0100 - val_loss: 6.6062e-04 - val_mae: 0.0223 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.4019e-04 - mae: 0.0085 - val_loss: 3.0646e-04 - val_mae: 0.0140 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.3731e-04 - mae: 0.0084 - val_loss: 2.5589e-04 - val_mae: 0.0119 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.4686e-04 - mae: 0.0088 - val_loss: 3.2997e-04 - val_mae: 0.0139 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.3969e-04 - mae: 0.0087 - val_loss: 4.0218e-04 - val_mae: 0.0169 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.1998e-04 - mae: 0.0083 - val_loss: 3.8200e-04 - val_mae: 0.0163 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.8272e-04 - mae: 0.0075 - val_loss: 3.0764e-04 - val_mae: 0.0143 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.8201e-04 - mae: 0.0075 - val_loss: 3.5345e-04 - val_mae: 0.0158 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.7343e-04 - mae: 0.0073 - val_loss: 3.2623e-04 - val_mae: 0.0143 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.7858e-04 - mae: 0.0074 - val_loss: 3.1364e-04 - val_mae: 0.0143 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.6691e-04 - mae: 0.0073 - val_loss: 3.6909e-04 - val_mae: 0.0162 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.5029e-04 - mae: 0.0069 - val_loss: 2.9446e-04 - val_mae: 0.0139 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4600e-04 - mae: 0.0069 - val_loss: 3.3444e-04 - val_mae: 0.0149 - lr: 6.2500e-05\n",
      "121/121 [==============================] - 0s 779us/step - loss: 2.5478e-04 - mae: 0.0131\n",
      "121/121 [==============================] - 0s 791us/step\n",
      "Running model for eth...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 5, 64)             22272     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55361 (216.25 KB)\n",
      "Trainable params: 55361 (216.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 3s 5ms/step - loss: 0.0365 - mae: 0.0717 - val_loss: 0.0082 - val_mae: 0.0740 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 7.9858e-04 - mae: 0.0189 - val_loss: 0.0098 - val_mae: 0.0824 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 6.4549e-04 - mae: 0.0162 - val_loss: 0.0058 - val_mae: 0.0643 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 5.6647e-04 - mae: 0.0151 - val_loss: 0.0042 - val_mae: 0.0557 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 5.1233e-04 - mae: 0.0145 - val_loss: 0.0054 - val_mae: 0.0635 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 4.7041e-04 - mae: 0.0134 - val_loss: 0.0041 - val_mae: 0.0557 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 4.5328e-04 - mae: 0.0133 - val_loss: 0.0044 - val_mae: 0.0567 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.0015e-04 - mae: 0.0130 - val_loss: 0.0025 - val_mae: 0.0435 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 4.3054e-04 - mae: 0.0126 - val_loss: 0.0046 - val_mae: 0.0594 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.6813e-04 - mae: 0.0122 - val_loss: 0.0035 - val_mae: 0.0510 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.1801e-04 - mae: 0.0114 - val_loss: 0.0016 - val_mae: 0.0368 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.1624e-04 - mae: 0.0117 - val_loss: 0.0019 - val_mae: 0.0390 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.7769e-04 - mae: 0.0110 - val_loss: 0.0019 - val_mae: 0.0389 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4347e-04 - mae: 0.0104 - val_loss: 0.0024 - val_mae: 0.0428 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.8076e-04 - mae: 0.0108 - val_loss: 0.0022 - val_mae: 0.0414 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.6351e-04 - mae: 0.0098 - val_loss: 0.0013 - val_mae: 0.0325 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4893e-04 - mae: 0.0103 - val_loss: 0.0014 - val_mae: 0.0334 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4065e-04 - mae: 0.0100 - val_loss: 6.2807e-04 - val_mae: 0.0222 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.2705e-04 - mae: 0.0099 - val_loss: 7.0395e-04 - val_mae: 0.0238 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.6606e-04 - mae: 0.0101 - val_loss: 0.0012 - val_mae: 0.0291 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.1517e-04 - mae: 0.0094 - val_loss: 7.5652e-04 - val_mae: 0.0240 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.1068e-04 - mae: 0.0094 - val_loss: 6.5594e-04 - val_mae: 0.0232 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.0600e-04 - mae: 0.0092 - val_loss: 8.0777e-04 - val_mae: 0.0244 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.4859e-04 - mae: 0.0075 - val_loss: 8.7639e-04 - val_mae: 0.0253 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.4432e-04 - mae: 0.0075 - val_loss: 7.9999e-04 - val_mae: 0.0244 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.4139e-04 - mae: 0.0075 - val_loss: 4.3452e-04 - val_mae: 0.0183 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.3761e-04 - mae: 0.0074 - val_loss: 0.0012 - val_mae: 0.0291 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.4191e-04 - mae: 0.0075 - val_loss: 8.7983e-04 - val_mae: 0.0255 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.3837e-04 - mae: 0.0074 - val_loss: 6.3815e-04 - val_mae: 0.0220 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.3697e-04 - mae: 0.0074 - val_loss: 9.1894e-04 - val_mae: 0.0253 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.4201e-04 - mae: 0.0076 - val_loss: 9.0523e-04 - val_mae: 0.0259 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.1387e-04 - mae: 0.0064 - val_loss: 7.0191e-04 - val_mae: 0.0229 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.1361e-04 - mae: 0.0065 - val_loss: 8.8531e-04 - val_mae: 0.0254 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.1469e-04 - mae: 0.0065 - val_loss: 9.6437e-04 - val_mae: 0.0265 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.0843e-04 - mae: 0.0064 - val_loss: 0.0011 - val_mae: 0.0281 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.1153e-04 - mae: 0.0065 - val_loss: 6.8543e-04 - val_mae: 0.0227 - lr: 2.5000e-04\n",
      "121/121 [==============================] - 0s 801us/step - loss: 0.0013 - mae: 0.0343\n",
      "121/121 [==============================] - 0s 801us/step\n",
      "Running model for xmr...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 5, 64)             22272     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55361 (216.25 KB)\n",
      "Trainable params: 55361 (216.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0361 - mae: 0.0733 - val_loss: 0.0013 - val_mae: 0.0268 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0263 - val_loss: 6.9421e-04 - val_mae: 0.0200 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 0.0011 - val_mae: 0.0270 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 3.5095e-04 - val_mae: 0.0143 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 9.0661e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0345 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.8374e-04 - mae: 0.0184 - val_loss: 2.3942e-04 - val_mae: 0.0115 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.6553e-04 - mae: 0.0183 - val_loss: 2.8472e-04 - val_mae: 0.0134 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.9862e-04 - mae: 0.0164 - val_loss: 2.5704e-04 - val_mae: 0.0118 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 6.0208e-04 - mae: 0.0168 - val_loss: 2.4528e-04 - val_mae: 0.0124 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.1569e-04 - mae: 0.0155 - val_loss: 2.0872e-04 - val_mae: 0.0111 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.3268e-04 - mae: 0.0156 - val_loss: 1.4463e-04 - val_mae: 0.0090 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.4503e-04 - mae: 0.0123 - val_loss: 2.5518e-04 - val_mae: 0.0131 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.2748e-04 - mae: 0.0121 - val_loss: 1.9119e-04 - val_mae: 0.0112 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.1638e-04 - mae: 0.0120 - val_loss: 1.5163e-04 - val_mae: 0.0091 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.2427e-04 - mae: 0.0122 - val_loss: 5.7364e-04 - val_mae: 0.0214 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 3.1995e-04 - mae: 0.0121 - val_loss: 1.7123e-04 - val_mae: 0.0104 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.6644e-04 - mae: 0.0108 - val_loss: 1.4287e-04 - val_mae: 0.0094 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.4911e-04 - mae: 0.0105 - val_loss: 2.6734e-04 - val_mae: 0.0135 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.5908e-04 - mae: 0.0107 - val_loss: 1.7396e-04 - val_mae: 0.0107 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.4254e-04 - mae: 0.0103 - val_loss: 2.0871e-04 - val_mae: 0.0119 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.4544e-04 - mae: 0.0105 - val_loss: 1.3509e-04 - val_mae: 0.0092 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.4254e-04 - mae: 0.0103 - val_loss: 1.6518e-04 - val_mae: 0.0104 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.4667e-04 - mae: 0.0105 - val_loss: 1.3786e-04 - val_mae: 0.0095 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.4065e-04 - mae: 0.0103 - val_loss: 1.4558e-04 - val_mae: 0.0094 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.4324e-04 - mae: 0.0104 - val_loss: 9.1118e-05 - val_mae: 0.0070 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.3286e-04 - mae: 0.0102 - val_loss: 1.1729e-04 - val_mae: 0.0086 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.0741e-04 - mae: 0.0093 - val_loss: 7.9554e-05 - val_mae: 0.0066 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.0706e-04 - mae: 0.0094 - val_loss: 9.1594e-05 - val_mae: 0.0074 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.0559e-04 - mae: 0.0093 - val_loss: 9.9108e-05 - val_mae: 0.0076 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 2.0618e-04 - mae: 0.0093 - val_loss: 8.0689e-05 - val_mae: 0.0065 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 2.0517e-04 - mae: 0.0093 - val_loss: 8.5827e-05 - val_mae: 0.0070 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.9268e-04 - mae: 0.0089 - val_loss: 1.1254e-04 - val_mae: 0.0083 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.9207e-04 - mae: 0.0089 - val_loss: 8.6070e-05 - val_mae: 0.0070 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.9186e-04 - mae: 0.0089 - val_loss: 8.6981e-05 - val_mae: 0.0070 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 2s 6ms/step - loss: 1.9376e-04 - mae: 0.0089 - val_loss: 8.9666e-05 - val_mae: 0.0073 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 1.9405e-04 - mae: 0.0089 - val_loss: 8.4419e-05 - val_mae: 0.0069 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 1.8513e-04 - mae: 0.0087 - val_loss: 1.1196e-04 - val_mae: 0.0083 - lr: 3.1250e-05\n",
      "121/121 [==============================] - 0s 852us/step - loss: 2.3858e-04 - mae: 0.0127\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for xrp...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 5, 64)             22272     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55361 (216.25 KB)\n",
      "Trainable params: 55361 (216.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 3s 5ms/step - loss: 0.0682 - mae: 0.0728 - val_loss: 0.0060 - val_mae: 0.0461 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0252 - val_loss: 0.0025 - val_mae: 0.0283 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0016 - mae: 0.0223 - val_loss: 0.0025 - val_mae: 0.0359 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0013 - mae: 0.0211 - val_loss: 0.0018 - val_mae: 0.0294 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 0.0010 - val_mae: 0.0226 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 9.7087e-04 - mae: 0.0183 - val_loss: 6.8102e-04 - val_mae: 0.0161 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 9.2274e-04 - mae: 0.0181 - val_loss: 8.6269e-04 - val_mae: 0.0176 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 7.7050e-04 - mae: 0.0168 - val_loss: 6.3970e-04 - val_mae: 0.0160 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 7.6749e-04 - mae: 0.0165 - val_loss: 7.1755e-04 - val_mae: 0.0179 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 7.2746e-04 - mae: 0.0158 - val_loss: 5.1813e-04 - val_mae: 0.0141 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0028 - mae: 0.0179 - val_loss: 9.3946e-04 - val_mae: 0.0214 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0073 - mae: 0.0195 - val_loss: 0.0010 - val_mae: 0.0203 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0150 - mae: 0.0227 - val_loss: 0.0021 - val_mae: 0.0230 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 0.0105 - mae: 0.0190 - val_loss: 0.0043 - val_mae: 0.0270 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0165 - val_loss: 0.0015 - val_mae: 0.0241 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 2s 5ms/step - loss: 8.1318e-04 - mae: 0.0134 - val_loss: 0.0014 - val_mae: 0.0248 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 6.1027e-04 - mae: 0.0129 - val_loss: 0.0013 - val_mae: 0.0234 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.4368e-04 - mae: 0.0128 - val_loss: 0.0015 - val_mae: 0.0229 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.5305e-04 - mae: 0.0127 - val_loss: 0.0017 - val_mae: 0.0307 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 2s 4ms/step - loss: 5.2592e-04 - mae: 0.0125 - val_loss: 0.0012 - val_mae: 0.0231 - lr: 5.0000e-04\n",
      "121/121 [==============================] - 0s 787us/step - loss: 0.0011 - mae: 0.0227\n",
      "121/121 [==============================] - 0s 816us/step\n",
      "Running model for aave...\n",
      "Model: \"Simple_LSTM_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 20)]           0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 5, 64)             21760     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54849 (214.25 KB)\n",
      "Trainable params: 54849 (214.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 41ms/step - loss: 0.8631 - mae: 0.8530 - val_loss: 0.0716 - val_mae: 0.2084 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6152 - mae: 0.7118 - val_loss: 0.1360 - val_mae: 0.3075 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3322 - mae: 0.5107 - val_loss: 0.3295 - val_mae: 0.5331 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1338 - mae: 0.2832 - val_loss: 0.7760 - val_mae: 0.8604 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1991 - mae: 0.3243 - val_loss: 0.8509 - val_mae: 0.9043 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1107 - mae: 0.2288 - val_loss: 0.5692 - val_mae: 0.7297 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0914 - mae: 0.2307 - val_loss: 0.4962 - val_mae: 0.6771 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0918 - mae: 0.2317 - val_loss: 0.4773 - val_mae: 0.6631 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0843 - mae: 0.2132 - val_loss: 0.4767 - val_mae: 0.6632 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0768 - mae: 0.1971 - val_loss: 0.4887 - val_mae: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0719 - mae: 0.1930 - val_loss: 0.5035 - val_mae: 0.6848 - lr: 5.0000e-04\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2398 - mae: 0.4700\n",
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Data           Model       MSE       MAE      MAPE\n0   ada  LSTM_sentiment  0.003298  0.050398  0.196977\n1   btc  LSTM_sentiment  0.000486  0.015871  0.171378\n2  doge  LSTM_sentiment  0.000255  0.013051  1.090816\n3   eth  LSTM_sentiment  0.001343  0.034302  0.852801\n4   xmr  LSTM_sentiment  0.000239  0.012693  0.307682\n5   xrp  LSTM_sentiment  0.001102  0.022688  0.899633\n6  aave  LSTM_sentiment  0.239753  0.470003  0.671878",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Model</th>\n      <th>MSE</th>\n      <th>MAE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ada</td>\n      <td>LSTM_sentiment</td>\n      <td>0.003298</td>\n      <td>0.050398</td>\n      <td>0.196977</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>btc</td>\n      <td>LSTM_sentiment</td>\n      <td>0.000486</td>\n      <td>0.015871</td>\n      <td>0.171378</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>doge</td>\n      <td>LSTM_sentiment</td>\n      <td>0.000255</td>\n      <td>0.013051</td>\n      <td>1.090816</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eth</td>\n      <td>LSTM_sentiment</td>\n      <td>0.001343</td>\n      <td>0.034302</td>\n      <td>0.852801</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xmr</td>\n      <td>LSTM_sentiment</td>\n      <td>0.000239</td>\n      <td>0.012693</td>\n      <td>0.307682</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xrp</td>\n      <td>LSTM_sentiment</td>\n      <td>0.001102</td>\n      <td>0.022688</td>\n      <td>0.899633</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aave</td>\n      <td>LSTM_sentiment</td>\n      <td>0.239753</td>\n      <td>0.470003</td>\n      <td>0.671878</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.scripts.utils import split_data_frame, apply_functions\n",
    "\n",
    "def run_model_for_dataframe(df):\n",
    "    # Split the DataFrame into train, validation, and test sets\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "\n",
    "    # Apply any additional functions to preprocess the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    # Fit the model\n",
    "    model, history = fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Get the evaluation metrics for each set\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the evaluation metrics along with the model and history\n",
    "    return model, history, (mse, mae, mape)\n",
    "\n",
    "# Assuming crypto_dfs is your dictionary of DataFrames for each crypto\n",
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_model_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    lstm = 'LSTM_sentiment'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': lstm,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "lstm_df = pd.DataFrame(summary_table)\n",
    "lstm_df.to_csv('../results/lstm_sentiment.csv')\n",
    "lstm_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:41:26.741516Z",
     "start_time": "2024-05-02T14:34:45.253892Z"
    }
   },
   "id": "6e2bfcb35ca11c0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM-CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff103f172728cb9f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras.models import Model as tfkModel\n",
    "\n",
    "def build_improved_LSTM_CNN(input_shape, output_units):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # CNN Layer 1\n",
    "    cnn = tfkl.Conv1D(256, 3, padding='same')(input_layer)  # Increased number of filters and adjusted kernel size\n",
    "    cnn = tfkl.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tfkl.MaxPooling1D(pool_size=2)(cnn)  # Added pool_size\n",
    "\n",
    "    # CNN Layer 2\n",
    "    cnn = tfkl.Conv1D(128, 3, padding='same')(cnn)  # Adjusted number of filters and kernel size\n",
    "    cnn = tfkl.LeakyReLU(alpha=0.2)(cnn)\n",
    "    cnn = tfkl.MaxPooling1D(pool_size=2)(cnn)  # Added pool_size\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    lstm = tfkl.LSTM(128, return_sequences=True)(cnn)  # Increased the number of units\n",
    "    lstm = tfkl.Dropout(0.2)(lstm)  # Added dropout for regularization\n",
    "\n",
    "    # LSTM Layer 2\n",
    "    lstm = tfkl.LSTM(128)(lstm)  # Adjusted the number of units\n",
    "    lstm = tfkl.Dropout(0.2)(lstm)  # Added dropout for regularization\n",
    "\n",
    "    # Feature Extractor Layer\n",
    "    dense = tfkl.Dense(64)(lstm)  # Adjusted the number of units\n",
    "    dense = tfkl.LeakyReLU(alpha=0.2)(dense)\n",
    "    dense = tfkl.Dropout(0.2)(dense)  # Added dropout for regularization\n",
    "\n",
    "    # Output layer for regression\n",
    "    output_layer = tfkl.Dense(output_units)(dense)  # No activation for regression output\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfkModel(inputs=input_layer, outputs=output_layer, name='Improved_LSTM_CNN')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:41:26.745164Z",
     "start_time": "2024-05-02T14:41:26.744572Z"
    }
   },
   "id": "5b23a37520f60656"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def fit(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_units = 1  # Assuming we want to predict one feature, e.g., close price for one day ahead\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_improved_LSTM_CNN(input_shape, output_units)\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    ).history\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:41:26.748587Z",
     "start_time": "2024-05-02T14:41:26.744691Z"
    }
   },
   "id": "5e195f9f3ecc94ee"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:41:26.763233Z",
     "start_time": "2024-05-02T14:41:26.749246Z"
    }
   },
   "id": "c5e9f29ef73d30fc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 5, 256)            17152     \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 2, 256)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387073 (1.48 MB)\n",
      "Trainable params: 387073 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0288 - mae: 0.1035 - val_loss: 0.0076 - val_mae: 0.0804 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0147 - mae: 0.0835 - val_loss: 0.0276 - val_mae: 0.1615 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0125 - mae: 0.0783 - val_loss: 0.0213 - val_mae: 0.1401 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0112 - mae: 0.0742 - val_loss: 0.0150 - val_mae: 0.1156 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0110 - mae: 0.0738 - val_loss: 0.0239 - val_mae: 0.1498 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0103 - mae: 0.0714 - val_loss: 0.0144 - val_mae: 0.1130 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0084 - mae: 0.0645 - val_loss: 0.0123 - val_mae: 0.1039 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0086 - mae: 0.0654 - val_loss: 0.0125 - val_mae: 0.1047 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0079 - mae: 0.0627 - val_loss: 0.0211 - val_mae: 0.1389 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0083 - mae: 0.0632 - val_loss: 0.0200 - val_mae: 0.1349 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0080 - mae: 0.0629 - val_loss: 0.0193 - val_mae: 0.1326 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0596 - val_loss: 0.0237 - val_mae: 0.1476 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0070 - mae: 0.0585 - val_loss: 0.0161 - val_mae: 0.1204 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0581 - val_loss: 0.0181 - val_mae: 0.1284 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0070 - mae: 0.0586 - val_loss: 0.0232 - val_mae: 0.1461 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0068 - mae: 0.0580 - val_loss: 0.0175 - val_mae: 0.1255 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0067 - mae: 0.0568 - val_loss: 0.0176 - val_mae: 0.1251 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0565 - val_loss: 0.0210 - val_mae: 0.1378 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0564 - val_loss: 0.0160 - val_mae: 0.1184 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0558 - val_loss: 0.0164 - val_mae: 0.1210 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0063 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.1224 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0556 - val_loss: 0.0166 - val_mae: 0.1217 - lr: 6.2500e-05\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0060 - mae: 0.0544 - val_loss: 0.0182 - val_mae: 0.1277 - lr: 6.2500e-05\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0540 - val_loss: 0.0163 - val_mae: 0.1199 - lr: 6.2500e-05\n",
      "Epoch 25/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0060 - mae: 0.0542 - val_loss: 0.0173 - val_mae: 0.1241 - lr: 6.2500e-05\n",
      "Epoch 26/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0549 - val_loss: 0.0176 - val_mae: 0.1252 - lr: 6.2500e-05\n",
      "Epoch 27/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 0.0162 - val_mae: 0.1197 - lr: 3.1250e-05\n",
      "Epoch 28/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0062 - mae: 0.0545 - val_loss: 0.0196 - val_mae: 0.1329 - lr: 3.1250e-05\n",
      "Epoch 29/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0061 - mae: 0.0545 - val_loss: 0.0159 - val_mae: 0.1183 - lr: 3.1250e-05\n",
      "Epoch 30/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0060 - mae: 0.0542 - val_loss: 0.0164 - val_mae: 0.1203 - lr: 3.1250e-05\n",
      "Epoch 31/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0540 - val_loss: 0.0178 - val_mae: 0.1260 - lr: 3.1250e-05\n",
      "Epoch 32/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 0.0168 - val_mae: 0.1218 - lr: 1.5625e-05\n",
      "Epoch 33/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0538 - val_loss: 0.0168 - val_mae: 0.1219 - lr: 1.5625e-05\n",
      "Epoch 34/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0182 - val_mae: 0.1275 - lr: 1.5625e-05\n",
      "Epoch 35/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 0.0175 - val_mae: 0.1249 - lr: 1.5625e-05\n",
      "Epoch 36/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0171 - val_mae: 0.1232 - lr: 1.5625e-05\n",
      "Epoch 37/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0537 - val_loss: 0.0177 - val_mae: 0.1255 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0537 - val_loss: 0.0168 - val_mae: 0.1220 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0169 - val_mae: 0.1220 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0538 - val_loss: 0.0167 - val_mae: 0.1216 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0535 - val_loss: 0.0179 - val_mae: 0.1264 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0060 - mae: 0.0537 - val_loss: 0.0171 - val_mae: 0.1228 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0164 - val_mae: 0.1202 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0534 - val_loss: 0.0172 - val_mae: 0.1235 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0171 - val_mae: 0.1230 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0167 - val_mae: 0.1212 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0164 - val_mae: 0.1203 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0537 - val_loss: 0.0166 - val_mae: 0.1210 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0535 - val_loss: 0.0169 - val_mae: 0.1222 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0061 - mae: 0.0540 - val_loss: 0.0161 - val_mae: 0.1186 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0168 - val_mae: 0.1217 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0533 - val_loss: 0.0168 - val_mae: 0.1218 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0536 - val_loss: 0.0171 - val_mae: 0.1231 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0166 - val_mae: 0.1211 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0537 - val_loss: 0.0165 - val_mae: 0.1208 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0535 - val_loss: 0.0172 - val_mae: 0.1234 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0534 - val_loss: 0.0170 - val_mae: 0.1225 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0536 - val_loss: 0.0169 - val_mae: 0.1222 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0175 - val_mae: 0.1247 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0535 - val_loss: 0.0167 - val_mae: 0.1211 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0533 - val_loss: 0.0168 - val_mae: 0.1217 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0531 - val_loss: 0.0171 - val_mae: 0.1231 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0531 - val_loss: 0.0171 - val_mae: 0.1230 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0533 - val_loss: 0.0168 - val_mae: 0.1216 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0538 - val_loss: 0.0174 - val_mae: 0.1239 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0533 - val_loss: 0.0178 - val_mae: 0.1257 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0529 - val_loss: 0.0172 - val_mae: 0.1233 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0535 - val_loss: 0.0167 - val_mae: 0.1210 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0534 - val_loss: 0.0180 - val_mae: 0.1266 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0528 - val_loss: 0.0175 - val_mae: 0.1248 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0530 - val_loss: 0.0161 - val_mae: 0.1189 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0531 - val_loss: 0.0170 - val_mae: 0.1227 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0537 - val_loss: 0.0170 - val_mae: 0.1226 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0531 - val_loss: 0.0173 - val_mae: 0.1238 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0057 - mae: 0.0528 - val_loss: 0.0171 - val_mae: 0.1229 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0531 - val_loss: 0.0170 - val_mae: 0.1223 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0170 - val_mae: 0.1225 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0533 - val_loss: 0.0174 - val_mae: 0.1242 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.1223 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0536 - val_loss: 0.0172 - val_mae: 0.1233 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0057 - mae: 0.0528 - val_loss: 0.0165 - val_mae: 0.1204 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0531 - val_loss: 0.0168 - val_mae: 0.1214 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0171 - val_mae: 0.1228 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0528 - val_loss: 0.0162 - val_mae: 0.1191 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0059 - mae: 0.0535 - val_loss: 0.0177 - val_mae: 0.1255 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0533 - val_loss: 0.0173 - val_mae: 0.1238 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0535 - val_loss: 0.0173 - val_mae: 0.1236 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0167 - val_mae: 0.1209 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0531 - val_loss: 0.0171 - val_mae: 0.1228 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0531 - val_loss: 0.0164 - val_mae: 0.1198 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0056 - mae: 0.0530 - val_loss: 0.0174 - val_mae: 0.1240 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0164 - val_mae: 0.1201 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0058 - mae: 0.0532 - val_loss: 0.0171 - val_mae: 0.1230 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0057 - mae: 0.0529 - val_loss: 0.0166 - val_mae: 0.1207 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0057 - mae: 0.0529 - val_loss: 0.0167 - val_mae: 0.1210 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0529 - val_loss: 0.0165 - val_mae: 0.1204 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0528 - val_loss: 0.0161 - val_mae: 0.1189 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0057 - mae: 0.0526 - val_loss: 0.0166 - val_mae: 0.1208 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0528 - val_loss: 0.0167 - val_mae: 0.1214 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0059 - mae: 0.0532 - val_loss: 0.0165 - val_mae: 0.1203 - lr: 1.0000e-05\n",
      "121/121 [==============================] - 0s 855us/step - loss: 0.0203 - mae: 0.1214\n",
      "121/121 [==============================] - 0s 896us/step\n",
      "Running model for btc...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 5, 256)            17152     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387073 (1.48 MB)\n",
      "Trainable params: 387073 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0284 - mae: 0.1090 - val_loss: 0.0064 - val_mae: 0.0572 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0126 - mae: 0.0835 - val_loss: 0.0039 - val_mae: 0.0525 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0114 - mae: 0.0795 - val_loss: 0.0029 - val_mae: 0.0441 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0106 - mae: 0.0766 - val_loss: 0.0041 - val_mae: 0.0570 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0103 - mae: 0.0748 - val_loss: 0.0051 - val_mae: 0.0610 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0090 - mae: 0.0705 - val_loss: 0.0014 - val_mae: 0.0308 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0091 - mae: 0.0706 - val_loss: 0.0020 - val_mae: 0.0358 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0087 - mae: 0.0691 - val_loss: 0.0045 - val_mae: 0.0606 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0087 - mae: 0.0693 - val_loss: 0.0025 - val_mae: 0.0392 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0084 - mae: 0.0683 - val_loss: 0.0044 - val_mae: 0.0555 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0083 - mae: 0.0677 - val_loss: 0.0073 - val_mae: 0.0704 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0073 - mae: 0.0630 - val_loss: 0.0053 - val_mae: 0.0570 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0616 - val_loss: 0.0075 - val_mae: 0.0572 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0617 - val_loss: 0.0151 - val_mae: 0.0907 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0622 - val_loss: 0.0118 - val_mae: 0.0719 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0605 - val_loss: 0.0223 - val_mae: 0.1090 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0587 - val_loss: 0.0260 - val_mae: 0.1100 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0061 - mae: 0.0584 - val_loss: 0.0219 - val_mae: 0.0994 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0578 - val_loss: 0.0202 - val_mae: 0.0976 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0581 - val_loss: 0.0235 - val_mae: 0.1107 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0575 - val_loss: 0.0257 - val_mae: 0.1156 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0569 - val_loss: 0.0287 - val_mae: 0.1227 - lr: 1.2500e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0564 - val_loss: 0.0220 - val_mae: 0.1006 - lr: 1.2500e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0563 - val_loss: 0.0263 - val_mae: 0.1167 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0227 - val_mae: 0.1144 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0564 - val_loss: 0.0253 - val_mae: 0.1164 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0055 - mae: 0.0551 - val_loss: 0.0272 - val_mae: 0.1146 - lr: 6.2500e-05\n",
      "Epoch 28/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0254 - val_mae: 0.1150 - lr: 6.2500e-05\n",
      "Epoch 29/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0275 - val_mae: 0.1235 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0558 - val_loss: 0.0276 - val_mae: 0.1238 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0556 - val_loss: 0.0276 - val_mae: 0.1189 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0263 - val_mae: 0.1163 - lr: 3.1250e-05\n",
      "Epoch 33/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0055 - mae: 0.0550 - val_loss: 0.0278 - val_mae: 0.1220 - lr: 3.1250e-05\n",
      "Epoch 34/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0240 - val_mae: 0.1123 - lr: 3.1250e-05\n",
      "Epoch 35/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0262 - val_mae: 0.1170 - lr: 3.1250e-05\n",
      "Epoch 36/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0264 - val_mae: 0.1140 - lr: 3.1250e-05\n",
      "Epoch 37/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0255 - val_mae: 0.1147 - lr: 1.5625e-05\n",
      "Epoch 38/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0262 - val_mae: 0.1185 - lr: 1.5625e-05\n",
      "Epoch 39/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0542 - val_loss: 0.0267 - val_mae: 0.1175 - lr: 1.5625e-05\n",
      "Epoch 40/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0055 - mae: 0.0549 - val_loss: 0.0284 - val_mae: 0.1225 - lr: 1.5625e-05\n",
      "Epoch 41/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0279 - val_mae: 0.1203 - lr: 1.5625e-05\n",
      "Epoch 42/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0272 - val_mae: 0.1195 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0283 - val_mae: 0.1210 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0280 - val_mae: 0.1216 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0273 - val_mae: 0.1194 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0289 - val_mae: 0.1219 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0273 - val_mae: 0.1161 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0270 - val_mae: 0.1164 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0281 - val_mae: 0.1201 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0275 - val_mae: 0.1183 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0271 - val_mae: 0.1183 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0279 - val_mae: 0.1194 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0273 - val_mae: 0.1173 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0275 - val_mae: 0.1173 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0281 - val_mae: 0.1181 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0261 - val_mae: 0.1155 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0260 - val_mae: 0.1139 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0267 - val_mae: 0.1147 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0249 - val_mae: 0.1102 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0264 - val_mae: 0.1161 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0269 - val_mae: 0.1162 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0266 - val_mae: 0.1153 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0262 - val_mae: 0.1135 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0268 - val_mae: 0.1161 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0271 - val_mae: 0.1167 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0278 - val_mae: 0.1174 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0283 - val_mae: 0.1177 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0543 - val_loss: 0.0267 - val_mae: 0.1128 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0271 - val_mae: 0.1141 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0269 - val_mae: 0.1131 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0259 - val_mae: 0.1112 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0277 - val_mae: 0.1172 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0546 - val_loss: 0.0267 - val_mae: 0.1131 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0279 - val_mae: 0.1167 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0269 - val_mae: 0.1138 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0271 - val_mae: 0.1139 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0283 - val_mae: 0.1156 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0272 - val_mae: 0.1160 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0053 - mae: 0.0539 - val_loss: 0.0262 - val_mae: 0.1124 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0269 - val_mae: 0.1139 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0278 - val_mae: 0.1163 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0281 - val_mae: 0.1171 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0537 - val_loss: 0.0268 - val_mae: 0.1117 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0270 - val_mae: 0.1150 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0543 - val_loss: 0.0276 - val_mae: 0.1180 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0272 - val_mae: 0.1172 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0541 - val_loss: 0.0265 - val_mae: 0.1141 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0545 - val_loss: 0.0266 - val_mae: 0.1141 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0271 - val_mae: 0.1151 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0052 - mae: 0.0537 - val_loss: 0.0271 - val_mae: 0.1160 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0052 - mae: 0.0538 - val_loss: 0.0268 - val_mae: 0.1128 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0271 - val_mae: 0.1169 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0540 - val_loss: 0.0270 - val_mae: 0.1149 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0254 - val_mae: 0.1097 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0256 - val_mae: 0.1100 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0261 - val_mae: 0.1117 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0544 - val_loss: 0.0254 - val_mae: 0.1089 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0054 - mae: 0.0542 - val_loss: 0.0257 - val_mae: 0.1093 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0053 - mae: 0.0542 - val_loss: 0.0256 - val_mae: 0.1129 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0051 - mae: 0.0535 - val_loss: 0.0251 - val_mae: 0.1087 - lr: 1.0000e-05\n",
      "121/121 [==============================] - 0s 970us/step - loss: 0.0079 - mae: 0.0727\n",
      "121/121 [==============================] - 0s 893us/step\n",
      "Running model for doge...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 5, 256)            17152     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387073 (1.48 MB)\n",
      "Trainable params: 387073 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0351 - mae: 0.1068 - val_loss: 0.0091 - val_mae: 0.0781 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0180 - mae: 0.0843 - val_loss: 0.0037 - val_mae: 0.0465 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0150 - mae: 0.0778 - val_loss: 0.0048 - val_mae: 0.0485 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0150 - mae: 0.0784 - val_loss: 0.0022 - val_mae: 0.0351 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0131 - mae: 0.0737 - val_loss: 0.0028 - val_mae: 0.0432 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0134 - mae: 0.0747 - val_loss: 0.0028 - val_mae: 0.0404 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0129 - mae: 0.0723 - val_loss: 0.0073 - val_mae: 0.0651 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0126 - mae: 0.0720 - val_loss: 0.0032 - val_mae: 0.0448 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0115 - mae: 0.0692 - val_loss: 0.0029 - val_mae: 0.0438 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0623 - val_loss: 0.0023 - val_mae: 0.0392 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0089 - mae: 0.0612 - val_loss: 0.0032 - val_mae: 0.0413 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0619 - val_loss: 0.0020 - val_mae: 0.0349 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0090 - mae: 0.0611 - val_loss: 0.0020 - val_mae: 0.0371 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0093 - mae: 0.0613 - val_loss: 0.0037 - val_mae: 0.0518 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0087 - mae: 0.0603 - val_loss: 0.0024 - val_mae: 0.0397 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0080 - mae: 0.0587 - val_loss: 0.0028 - val_mae: 0.0414 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0086 - mae: 0.0596 - val_loss: 0.0024 - val_mae: 0.0393 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0071 - mae: 0.0553 - val_loss: 0.0020 - val_mae: 0.0359 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0077 - mae: 0.0559 - val_loss: 0.0021 - val_mae: 0.0363 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0555 - val_loss: 0.0018 - val_mae: 0.0346 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0550 - val_loss: 0.0018 - val_mae: 0.0359 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0552 - val_loss: 0.0015 - val_mae: 0.0309 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0071 - mae: 0.0549 - val_loss: 0.0021 - val_mae: 0.0358 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0554 - val_loss: 0.0020 - val_mae: 0.0364 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0075 - mae: 0.0558 - val_loss: 0.0020 - val_mae: 0.0352 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0068 - mae: 0.0547 - val_loss: 0.0019 - val_mae: 0.0354 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0550 - val_loss: 0.0017 - val_mae: 0.0332 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0534 - val_loss: 0.0019 - val_mae: 0.0356 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0536 - val_loss: 0.0017 - val_mae: 0.0331 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0532 - val_loss: 0.0019 - val_mae: 0.0348 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0532 - val_loss: 0.0016 - val_mae: 0.0316 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0534 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0518 - val_loss: 0.0018 - val_mae: 0.0340 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 0.0019 - val_mae: 0.0345 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0521 - val_loss: 0.0018 - val_mae: 0.0337 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0061 - mae: 0.0518 - val_loss: 0.0019 - val_mae: 0.0342 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0519 - val_loss: 0.0017 - val_mae: 0.0321 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 0.0018 - val_mae: 0.0337 - lr: 3.1250e-05\n",
      "Epoch 39/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0332 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0517 - val_loss: 0.0018 - val_mae: 0.0342 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0518 - val_loss: 0.0018 - val_mae: 0.0342 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 0.0018 - val_mae: 0.0332 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0334 - lr: 1.5625e-05\n",
      "Epoch 44/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0515 - val_loss: 0.0018 - val_mae: 0.0333 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 0.0018 - val_mae: 0.0330 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0515 - val_loss: 0.0018 - val_mae: 0.0337 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0516 - val_loss: 0.0018 - val_mae: 0.0335 - lr: 1.5625e-05\n",
      "Epoch 48/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0514 - val_loss: 0.0018 - val_mae: 0.0334 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 0.0018 - val_mae: 0.0334 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0512 - val_loss: 0.0017 - val_mae: 0.0331 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0504 - val_loss: 0.0018 - val_mae: 0.0335 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0333 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0331 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0516 - val_loss: 0.0018 - val_mae: 0.0338 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0514 - val_loss: 0.0018 - val_mae: 0.0334 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0018 - val_mae: 0.0335 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0511 - val_loss: 0.0017 - val_mae: 0.0329 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0332 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 0.0018 - val_mae: 0.0338 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0019 - val_mae: 0.0341 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0509 - val_loss: 0.0019 - val_mae: 0.0342 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0018 - val_mae: 0.0334 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0331 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0335 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0322 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0512 - val_loss: 0.0017 - val_mae: 0.0331 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0509 - val_loss: 0.0017 - val_mae: 0.0329 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0508 - val_loss: 0.0018 - val_mae: 0.0340 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0514 - val_loss: 0.0018 - val_mae: 0.0333 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0507 - val_loss: 0.0017 - val_mae: 0.0332 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0340 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0509 - val_loss: 0.0018 - val_mae: 0.0334 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 0.0017 - val_mae: 0.0327 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0510 - val_loss: 0.0019 - val_mae: 0.0341 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0511 - val_loss: 0.0018 - val_mae: 0.0337 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0514 - val_loss: 0.0018 - val_mae: 0.0340 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0509 - val_loss: 0.0018 - val_mae: 0.0337 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0508 - val_loss: 0.0018 - val_mae: 0.0338 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0509 - val_loss: 0.0018 - val_mae: 0.0340 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 0.0018 - val_mae: 0.0341 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0508 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0340 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0059 - mae: 0.0507 - val_loss: 0.0018 - val_mae: 0.0338 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0018 - val_mae: 0.0339 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0506 - val_loss: 0.0018 - val_mae: 0.0337 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0507 - val_loss: 0.0018 - val_mae: 0.0334 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0511 - val_loss: 0.0018 - val_mae: 0.0337 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 0.0018 - val_mae: 0.0338 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 0.0018 - val_mae: 0.0342 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0510 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 0.0017 - val_mae: 0.0330 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 0.0018 - val_mae: 0.0336 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0505 - val_loss: 0.0017 - val_mae: 0.0333 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0510 - val_loss: 0.0017 - val_mae: 0.0332 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0509 - val_loss: 0.0018 - val_mae: 0.0342 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0508 - val_loss: 0.0018 - val_mae: 0.0341 - lr: 1.0000e-05\n",
      "121/121 [==============================] - 0s 986us/step - loss: 0.0043 - mae: 0.0561\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for eth...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 5, 256)            17152     \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387073 (1.48 MB)\n",
      "Trainable params: 387073 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 5s 5ms/step - loss: 0.0267 - mae: 0.1043 - val_loss: 0.0024 - val_mae: 0.0381 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0130 - mae: 0.0828 - val_loss: 0.0059 - val_mae: 0.0643 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0114 - mae: 0.0774 - val_loss: 0.0096 - val_mae: 0.0758 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0103 - mae: 0.0743 - val_loss: 0.0044 - val_mae: 0.0547 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0105 - mae: 0.0741 - val_loss: 0.0108 - val_mae: 0.0811 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0095 - mae: 0.0716 - val_loss: 0.0025 - val_mae: 0.0385 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0083 - mae: 0.0664 - val_loss: 0.0065 - val_mae: 0.0679 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0077 - mae: 0.0642 - val_loss: 0.0038 - val_mae: 0.0442 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0079 - mae: 0.0649 - val_loss: 0.0038 - val_mae: 0.0522 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0078 - mae: 0.0645 - val_loss: 0.0069 - val_mae: 0.0683 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0637 - val_loss: 0.0024 - val_mae: 0.0397 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0070 - mae: 0.0612 - val_loss: 0.0049 - val_mae: 0.0599 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0072 - mae: 0.0613 - val_loss: 0.0044 - val_mae: 0.0549 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0607 - val_loss: 0.0048 - val_mae: 0.0589 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0069 - mae: 0.0608 - val_loss: 0.0047 - val_mae: 0.0621 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0599 - val_loss: 0.0044 - val_mae: 0.0575 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0587 - val_loss: 0.0024 - val_mae: 0.0410 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0066 - mae: 0.0591 - val_loss: 0.0026 - val_mae: 0.0450 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0580 - val_loss: 0.0021 - val_mae: 0.0390 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0063 - mae: 0.0580 - val_loss: 0.0039 - val_mae: 0.0538 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0064 - mae: 0.0581 - val_loss: 0.0040 - val_mae: 0.0566 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0579 - val_loss: 0.0027 - val_mae: 0.0456 - lr: 1.2500e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0062 - mae: 0.0576 - val_loss: 0.0037 - val_mae: 0.0535 - lr: 1.2500e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0063 - mae: 0.0578 - val_loss: 0.0026 - val_mae: 0.0428 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0568 - val_loss: 0.0035 - val_mae: 0.0533 - lr: 6.2500e-05\n",
      "Epoch 26/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0571 - val_loss: 0.0035 - val_mae: 0.0529 - lr: 6.2500e-05\n",
      "Epoch 27/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0564 - val_loss: 0.0031 - val_mae: 0.0503 - lr: 6.2500e-05\n",
      "Epoch 28/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0569 - val_loss: 0.0033 - val_mae: 0.0512 - lr: 6.2500e-05\n",
      "Epoch 29/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0563 - val_loss: 0.0030 - val_mae: 0.0480 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0567 - val_loss: 0.0031 - val_mae: 0.0492 - lr: 3.1250e-05\n",
      "Epoch 31/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0562 - val_loss: 0.0030 - val_mae: 0.0486 - lr: 3.1250e-05\n",
      "Epoch 32/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0563 - val_loss: 0.0028 - val_mae: 0.0468 - lr: 3.1250e-05\n",
      "Epoch 33/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0560 - val_loss: 0.0029 - val_mae: 0.0468 - lr: 3.1250e-05\n",
      "Epoch 34/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0558 - val_loss: 0.0036 - val_mae: 0.0545 - lr: 3.1250e-05\n",
      "Epoch 35/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0554 - val_loss: 0.0030 - val_mae: 0.0492 - lr: 1.5625e-05\n",
      "Epoch 36/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0059 - mae: 0.0558 - val_loss: 0.0029 - val_mae: 0.0479 - lr: 1.5625e-05\n",
      "Epoch 37/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0030 - val_mae: 0.0493 - lr: 1.5625e-05\n",
      "Epoch 38/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0059 - mae: 0.0561 - val_loss: 0.0030 - val_mae: 0.0493 - lr: 1.5625e-05\n",
      "Epoch 39/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0555 - val_loss: 0.0031 - val_mae: 0.0503 - lr: 1.5625e-05\n",
      "Epoch 40/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0030 - val_mae: 0.0495 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0553 - val_loss: 0.0030 - val_mae: 0.0494 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0027 - val_mae: 0.0465 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0560 - val_loss: 0.0029 - val_mae: 0.0483 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0561 - val_loss: 0.0030 - val_mae: 0.0490 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0551 - val_loss: 0.0030 - val_mae: 0.0488 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0556 - val_loss: 0.0032 - val_mae: 0.0509 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0552 - val_loss: 0.0030 - val_mae: 0.0491 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0559 - val_loss: 0.0030 - val_mae: 0.0494 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0552 - val_loss: 0.0031 - val_mae: 0.0504 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0554 - val_loss: 0.0030 - val_mae: 0.0491 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0031 - val_mae: 0.0500 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0554 - val_loss: 0.0030 - val_mae: 0.0487 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0056 - mae: 0.0547 - val_loss: 0.0032 - val_mae: 0.0507 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0554 - val_loss: 0.0029 - val_mae: 0.0483 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0028 - val_mae: 0.0473 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0555 - val_loss: 0.0028 - val_mae: 0.0471 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0554 - val_loss: 0.0027 - val_mae: 0.0464 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0557 - val_loss: 0.0031 - val_mae: 0.0500 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0027 - val_mae: 0.0461 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0552 - val_loss: 0.0028 - val_mae: 0.0470 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0028 - val_mae: 0.0473 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0557 - val_loss: 0.0029 - val_mae: 0.0483 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0553 - val_loss: 0.0028 - val_mae: 0.0474 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0553 - val_loss: 0.0026 - val_mae: 0.0456 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0555 - val_loss: 0.0027 - val_mae: 0.0466 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0057 - mae: 0.0554 - val_loss: 0.0026 - val_mae: 0.0457 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "846/846 [==============================] - 6s 7ms/step - loss: 0.0058 - mae: 0.0554 - val_loss: 0.0025 - val_mae: 0.0445 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0027 - val_mae: 0.0468 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0057 - mae: 0.0549 - val_loss: 0.0029 - val_mae: 0.0490 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0056 - mae: 0.0547 - val_loss: 0.0026 - val_mae: 0.0455 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0059 - mae: 0.0556 - val_loss: 0.0027 - val_mae: 0.0465 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0030 - val_mae: 0.0490 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0559 - val_loss: 0.0031 - val_mae: 0.0502 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0558 - val_loss: 0.0030 - val_mae: 0.0487 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0552 - val_loss: 0.0028 - val_mae: 0.0469 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0056 - mae: 0.0552 - val_loss: 0.0028 - val_mae: 0.0470 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0548 - val_loss: 0.0028 - val_mae: 0.0466 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0554 - val_loss: 0.0029 - val_mae: 0.0481 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0552 - val_loss: 0.0028 - val_mae: 0.0478 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0029 - val_mae: 0.0482 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0549 - val_loss: 0.0030 - val_mae: 0.0494 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0552 - val_loss: 0.0030 - val_mae: 0.0500 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0029 - val_mae: 0.0483 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0030 - val_mae: 0.0492 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0549 - val_loss: 0.0032 - val_mae: 0.0519 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0553 - val_loss: 0.0030 - val_mae: 0.0491 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0545 - val_loss: 0.0029 - val_mae: 0.0485 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0553 - val_loss: 0.0030 - val_mae: 0.0498 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0029 - val_mae: 0.0482 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0551 - val_loss: 0.0028 - val_mae: 0.0475 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0548 - val_loss: 0.0029 - val_mae: 0.0492 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0553 - val_loss: 0.0030 - val_mae: 0.0494 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0028 - val_mae: 0.0479 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0547 - val_loss: 0.0030 - val_mae: 0.0493 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0553 - val_loss: 0.0027 - val_mae: 0.0466 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0056 - mae: 0.0548 - val_loss: 0.0027 - val_mae: 0.0466 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0056 - mae: 0.0549 - val_loss: 0.0029 - val_mae: 0.0490 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0056 - mae: 0.0546 - val_loss: 0.0030 - val_mae: 0.0497 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0555 - val_loss: 0.0026 - val_mae: 0.0460 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0547 - val_loss: 0.0030 - val_mae: 0.0498 - lr: 1.0000e-05\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0054 - mae: 0.0664\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for xmr...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 5, 256)            17152     \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPoolin  (None, 1, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387073 (1.48 MB)\n",
      "Trainable params: 387073 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 5s 4ms/step - loss: 0.0321 - mae: 0.1130 - val_loss: 0.0032 - val_mae: 0.0473 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0162 - mae: 0.0896 - val_loss: 0.0070 - val_mae: 0.0729 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0152 - mae: 0.0860 - val_loss: 0.0105 - val_mae: 0.0912 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0137 - mae: 0.0823 - val_loss: 0.0057 - val_mae: 0.0632 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0128 - mae: 0.0797 - val_loss: 0.0027 - val_mae: 0.0439 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0119 - mae: 0.0773 - val_loss: 0.0065 - val_mae: 0.0691 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0118 - mae: 0.0770 - val_loss: 0.0077 - val_mae: 0.0766 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0112 - mae: 0.0750 - val_loss: 0.0024 - val_mae: 0.0362 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 21s 24ms/step - loss: 0.0108 - mae: 0.0735 - val_loss: 0.0024 - val_mae: 0.0391 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0106 - mae: 0.0721 - val_loss: 0.0052 - val_mae: 0.0610 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0100 - mae: 0.0707 - val_loss: 0.0072 - val_mae: 0.0605 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0098 - mae: 0.0704 - val_loss: 0.0013 - val_mae: 0.0271 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0096 - mae: 0.0689 - val_loss: 0.0019 - val_mae: 0.0334 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0096 - mae: 0.0690 - val_loss: 0.0017 - val_mae: 0.0304 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0094 - mae: 0.0689 - val_loss: 0.0031 - val_mae: 0.0478 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0092 - mae: 0.0676 - val_loss: 0.0027 - val_mae: 0.0372 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0089 - mae: 0.0670 - val_loss: 0.0028 - val_mae: 0.0396 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0079 - mae: 0.0623 - val_loss: 0.0027 - val_mae: 0.0449 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0076 - mae: 0.0614 - val_loss: 0.0033 - val_mae: 0.0504 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0292 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0617 - val_loss: 0.0012 - val_mae: 0.0251 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0616 - val_loss: 0.0032 - val_mae: 0.0385 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 193s 228ms/step - loss: 0.0077 - mae: 0.0620 - val_loss: 0.0016 - val_mae: 0.0302 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 4s 5ms/step - loss: 0.0074 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0276 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0075 - mae: 0.0610 - val_loss: 0.0032 - val_mae: 0.0466 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0073 - mae: 0.0602 - val_loss: 0.0023 - val_mae: 0.0382 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0068 - mae: 0.0585 - val_loss: 9.0622e-04 - val_mae: 0.0211 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0576 - val_loss: 0.0026 - val_mae: 0.0410 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0575 - val_loss: 0.0019 - val_mae: 0.0338 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0579 - val_loss: 0.0031 - val_mae: 0.0438 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0065 - mae: 0.0573 - val_loss: 0.0029 - val_mae: 0.0411 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0570 - val_loss: 0.0044 - val_mae: 0.0522 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0560 - val_loss: 0.0032 - val_mae: 0.0442 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0558 - val_loss: 0.0057 - val_mae: 0.0628 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0561 - val_loss: 0.0035 - val_mae: 0.0486 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0560 - val_loss: 0.0028 - val_mae: 0.0426 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0555 - val_loss: 0.0043 - val_mae: 0.0515 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0550 - val_loss: 0.0046 - val_mae: 0.0541 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0553 - val_loss: 0.0030 - val_mae: 0.0440 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0550 - val_loss: 0.0035 - val_mae: 0.0475 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0061 - mae: 0.0549 - val_loss: 0.0036 - val_mae: 0.0492 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0546 - val_loss: 0.0050 - val_mae: 0.0582 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0059 - mae: 0.0541 - val_loss: 0.0041 - val_mae: 0.0520 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0060 - mae: 0.0545 - val_loss: 0.0050 - val_mae: 0.0588 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0546 - val_loss: 0.0054 - val_mae: 0.0600 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0548 - val_loss: 0.0057 - val_mae: 0.0624 - lr: 3.1250e-05\n",
      "Epoch 47/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0545 - val_loss: 0.0045 - val_mae: 0.0548 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0543 - val_loss: 0.0051 - val_mae: 0.0582 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0538 - val_loss: 0.0056 - val_mae: 0.0610 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0539 - val_loss: 0.0055 - val_mae: 0.0601 - lr: 1.5625e-05\n",
      "Epoch 51/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0542 - val_loss: 0.0052 - val_mae: 0.0592 - lr: 1.5625e-05\n",
      "Epoch 52/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0540 - val_loss: 0.0055 - val_mae: 0.0604 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 0.0053 - val_mae: 0.0595 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0538 - val_loss: 0.0055 - val_mae: 0.0601 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0538 - val_loss: 0.0053 - val_mae: 0.0594 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0538 - val_loss: 0.0052 - val_mae: 0.0594 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0542 - val_loss: 0.0057 - val_mae: 0.0616 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0541 - val_loss: 0.0051 - val_mae: 0.0588 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0541 - val_loss: 0.0050 - val_mae: 0.0580 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 0.0055 - val_mae: 0.0612 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0540 - val_loss: 0.0057 - val_mae: 0.0624 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0537 - val_loss: 0.0053 - val_mae: 0.0600 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0544 - val_loss: 0.0049 - val_mae: 0.0581 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0538 - val_loss: 0.0054 - val_mae: 0.0609 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0538 - val_loss: 0.0052 - val_mae: 0.0597 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0543 - val_loss: 0.0054 - val_mae: 0.0605 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0534 - val_loss: 0.0054 - val_mae: 0.0604 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0541 - val_loss: 0.0054 - val_mae: 0.0606 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0058 - mae: 0.0538 - val_loss: 0.0056 - val_mae: 0.0623 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0538 - val_loss: 0.0053 - val_mae: 0.0599 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0539 - val_loss: 0.0056 - val_mae: 0.0617 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0540 - val_loss: 0.0056 - val_mae: 0.0622 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0542 - val_loss: 0.0056 - val_mae: 0.0620 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0538 - val_loss: 0.0051 - val_mae: 0.0589 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0536 - val_loss: 0.0053 - val_mae: 0.0607 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 0.0052 - val_mae: 0.0595 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0060 - mae: 0.0546 - val_loss: 0.0054 - val_mae: 0.0610 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0537 - val_loss: 0.0061 - val_mae: 0.0647 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0537 - val_loss: 0.0054 - val_mae: 0.0608 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0541 - val_loss: 0.0049 - val_mae: 0.0581 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0542 - val_loss: 0.0052 - val_mae: 0.0595 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0537 - val_loss: 0.0050 - val_mae: 0.0591 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0539 - val_loss: 0.0050 - val_mae: 0.0588 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0536 - val_loss: 0.0058 - val_mae: 0.0634 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0538 - val_loss: 0.0061 - val_mae: 0.0648 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0538 - val_loss: 0.0057 - val_mae: 0.0626 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0537 - val_loss: 0.0055 - val_mae: 0.0616 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0537 - val_loss: 0.0057 - val_mae: 0.0621 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0535 - val_loss: 0.0056 - val_mae: 0.0625 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 0.0053 - val_mae: 0.0609 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0539 - val_loss: 0.0056 - val_mae: 0.0620 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0057 - mae: 0.0535 - val_loss: 0.0056 - val_mae: 0.0622 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0057 - mae: 0.0533 - val_loss: 0.0052 - val_mae: 0.0595 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0535 - val_loss: 0.0063 - val_mae: 0.0656 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0541 - val_loss: 0.0058 - val_mae: 0.0631 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0544 - val_loss: 0.0059 - val_mae: 0.0634 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0539 - val_loss: 0.0062 - val_mae: 0.0652 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0537 - val_loss: 0.0060 - val_mae: 0.0641 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0537 - val_loss: 0.0056 - val_mae: 0.0623 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0059 - mae: 0.0538 - val_loss: 0.0058 - val_mae: 0.0634 - lr: 1.0000e-05\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0412 - mae: 0.1865\n",
      "121/121 [==============================] - 0s 1ms/step\n",
      "Running model for xrp...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 22)]           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 5, 256)            17152     \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPooli  (None, 2, 256)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 1, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387073 (1.48 MB)\n",
      "Trainable params: 387073 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0324 - mae: 0.1131 - val_loss: 0.0024 - val_mae: 0.0357 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0170 - mae: 0.0907 - val_loss: 0.0068 - val_mae: 0.0653 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0147 - mae: 0.0838 - val_loss: 0.0030 - val_mae: 0.0403 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0128 - mae: 0.0789 - val_loss: 0.0044 - val_mae: 0.0547 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0128 - mae: 0.0782 - val_loss: 0.0046 - val_mae: 0.0503 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0115 - mae: 0.0750 - val_loss: 0.0037 - val_mae: 0.0472 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0094 - mae: 0.0669 - val_loss: 0.0068 - val_mae: 0.0678 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0096 - mae: 0.0676 - val_loss: 0.0023 - val_mae: 0.0317 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0091 - mae: 0.0656 - val_loss: 0.0015 - val_mae: 0.0249 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0089 - mae: 0.0657 - val_loss: 0.0037 - val_mae: 0.0434 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0088 - mae: 0.0650 - val_loss: 0.0070 - val_mae: 0.0555 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0083 - mae: 0.0639 - val_loss: 0.0039 - val_mae: 0.0446 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0085 - mae: 0.0639 - val_loss: 0.0046 - val_mae: 0.0503 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0085 - mae: 0.0639 - val_loss: 0.0046 - val_mae: 0.0383 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0604 - val_loss: 0.0045 - val_mae: 0.0527 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0074 - mae: 0.0597 - val_loss: 0.0048 - val_mae: 0.0519 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0604 - val_loss: 0.0134 - val_mae: 0.0741 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0077 - mae: 0.0605 - val_loss: 0.0032 - val_mae: 0.0299 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0076 - mae: 0.0601 - val_loss: 0.0056 - val_mae: 0.0584 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0071 - mae: 0.0584 - val_loss: 0.0034 - val_mae: 0.0266 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0070 - mae: 0.0578 - val_loss: 0.0034 - val_mae: 0.0350 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0069 - mae: 0.0575 - val_loss: 0.0044 - val_mae: 0.0410 - lr: 1.2500e-04\n",
      "Epoch 23/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0070 - mae: 0.0575 - val_loss: 0.0041 - val_mae: 0.0311 - lr: 1.2500e-04\n",
      "Epoch 24/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0070 - mae: 0.0576 - val_loss: 0.0046 - val_mae: 0.0392 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0566 - val_loss: 0.0055 - val_mae: 0.0468 - lr: 6.2500e-05\n",
      "Epoch 26/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0565 - val_loss: 0.0039 - val_mae: 0.0360 - lr: 6.2500e-05\n",
      "Epoch 27/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0563 - val_loss: 0.0050 - val_mae: 0.0426 - lr: 6.2500e-05\n",
      "Epoch 28/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0065 - mae: 0.0558 - val_loss: 0.0038 - val_mae: 0.0322 - lr: 6.2500e-05\n",
      "Epoch 29/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0066 - mae: 0.0562 - val_loss: 0.0039 - val_mae: 0.0353 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0556 - val_loss: 0.0039 - val_mae: 0.0358 - lr: 3.1250e-05\n",
      "Epoch 31/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0557 - val_loss: 0.0044 - val_mae: 0.0422 - lr: 3.1250e-05\n",
      "Epoch 32/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0556 - val_loss: 0.0040 - val_mae: 0.0341 - lr: 3.1250e-05\n",
      "Epoch 33/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0560 - val_loss: 0.0046 - val_mae: 0.0401 - lr: 3.1250e-05\n",
      "Epoch 34/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0562 - val_loss: 0.0050 - val_mae: 0.0382 - lr: 3.1250e-05\n",
      "Epoch 35/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0065 - mae: 0.0560 - val_loss: 0.0049 - val_mae: 0.0363 - lr: 1.5625e-05\n",
      "Epoch 36/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0064 - mae: 0.0554 - val_loss: 0.0057 - val_mae: 0.0412 - lr: 1.5625e-05\n",
      "Epoch 37/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0065 - mae: 0.0557 - val_loss: 0.0052 - val_mae: 0.0386 - lr: 1.5625e-05\n",
      "Epoch 38/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0547 - val_loss: 0.0056 - val_mae: 0.0391 - lr: 1.5625e-05\n",
      "Epoch 39/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0548 - val_loss: 0.0057 - val_mae: 0.0393 - lr: 1.5625e-05\n",
      "Epoch 40/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0549 - val_loss: 0.0053 - val_mae: 0.0353 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0546 - val_loss: 0.0054 - val_mae: 0.0378 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0064 - mae: 0.0554 - val_loss: 0.0050 - val_mae: 0.0356 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0052 - val_mae: 0.0357 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0066 - mae: 0.0556 - val_loss: 0.0051 - val_mae: 0.0371 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0553 - val_loss: 0.0054 - val_mae: 0.0395 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0547 - val_loss: 0.0053 - val_mae: 0.0391 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0050 - val_mae: 0.0383 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0553 - val_loss: 0.0051 - val_mae: 0.0393 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0543 - val_loss: 0.0050 - val_mae: 0.0393 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0547 - val_loss: 0.0051 - val_mae: 0.0390 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0548 - val_loss: 0.0049 - val_mae: 0.0370 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0545 - val_loss: 0.0056 - val_mae: 0.0412 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0549 - val_loss: 0.0054 - val_mae: 0.0402 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0551 - val_loss: 0.0051 - val_mae: 0.0366 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0052 - val_mae: 0.0384 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0553 - val_loss: 0.0051 - val_mae: 0.0378 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0553 - val_loss: 0.0052 - val_mae: 0.0388 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0547 - val_loss: 0.0050 - val_mae: 0.0378 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0063 - mae: 0.0550 - val_loss: 0.0051 - val_mae: 0.0369 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0551 - val_loss: 0.0054 - val_mae: 0.0403 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0546 - val_loss: 0.0055 - val_mae: 0.0390 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0554 - val_loss: 0.0054 - val_mae: 0.0386 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0548 - val_loss: 0.0049 - val_mae: 0.0374 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0550 - val_loss: 0.0049 - val_mae: 0.0378 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0546 - val_loss: 0.0049 - val_mae: 0.0374 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0546 - val_loss: 0.0050 - val_mae: 0.0395 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0546 - val_loss: 0.0046 - val_mae: 0.0350 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0546 - val_loss: 0.0049 - val_mae: 0.0392 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0548 - val_loss: 0.0047 - val_mae: 0.0388 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0551 - val_loss: 0.0045 - val_mae: 0.0364 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0550 - val_loss: 0.0049 - val_mae: 0.0406 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0544 - val_loss: 0.0047 - val_mae: 0.0377 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0548 - val_loss: 0.0048 - val_mae: 0.0397 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0062 - mae: 0.0546 - val_loss: 0.0046 - val_mae: 0.0379 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0061 - mae: 0.0545 - val_loss: 0.0047 - val_mae: 0.0381 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "846/846 [==============================] - 4s 4ms/step - loss: 0.0062 - mae: 0.0545 - val_loss: 0.0047 - val_mae: 0.0364 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0542 - val_loss: 0.0046 - val_mae: 0.0363 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0546 - val_loss: 0.0048 - val_mae: 0.0385 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0445 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "846/846 [==============================] - 3s 3ms/step - loss: 0.0064 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0408 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0544 - val_loss: 0.0050 - val_mae: 0.0377 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0548 - val_loss: 0.0049 - val_mae: 0.0376 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0547 - val_loss: 0.0050 - val_mae: 0.0421 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0546 - val_loss: 0.0049 - val_mae: 0.0411 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0051 - val_mae: 0.0423 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0544 - val_loss: 0.0051 - val_mae: 0.0422 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0548 - val_loss: 0.0055 - val_mae: 0.0454 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0552 - val_loss: 0.0052 - val_mae: 0.0425 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0546 - val_loss: 0.0054 - val_mae: 0.0443 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0548 - val_loss: 0.0052 - val_mae: 0.0424 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0060 - mae: 0.0543 - val_loss: 0.0055 - val_mae: 0.0433 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0049 - val_mae: 0.0384 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0544 - val_loss: 0.0052 - val_mae: 0.0430 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0055 - val_mae: 0.0420 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0548 - val_loss: 0.0054 - val_mae: 0.0435 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0063 - mae: 0.0547 - val_loss: 0.0050 - val_mae: 0.0408 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0547 - val_loss: 0.0052 - val_mae: 0.0399 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0542 - val_loss: 0.0051 - val_mae: 0.0405 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0061 - mae: 0.0542 - val_loss: 0.0051 - val_mae: 0.0406 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "846/846 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0550 - val_loss: 0.0051 - val_mae: 0.0412 - lr: 1.0000e-05\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0129 - mae: 0.1025\n",
      "121/121 [==============================] - 0s 987us/step\n",
      "Running model for aave...\n",
      "Model: \"Improved_LSTM_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 5, 20)]           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 5, 256)            15616     \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 5, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 2, 256)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 2, 128)            98432     \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 2, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 1, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 385537 (1.47 MB)\n",
      "Trainable params: 385537 (1.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 46ms/step - loss: 0.7651 - mae: 0.7867 - val_loss: 0.3401 - val_mae: 0.5489 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1703 - mae: 0.3366 - val_loss: 0.6198 - val_mae: 0.7672 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1169 - mae: 0.2680 - val_loss: 0.3187 - val_mae: 0.5363 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1134 - mae: 0.2752 - val_loss: 0.4375 - val_mae: 0.6381 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0741 - mae: 0.2143 - val_loss: 0.2645 - val_mae: 0.4806 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0763 - mae: 0.2099 - val_loss: 0.2863 - val_mae: 0.5058 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0756 - mae: 0.2086 - val_loss: 0.1977 - val_mae: 0.4090 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0623 - mae: 0.1846 - val_loss: 0.2448 - val_mae: 0.4616 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0558 - mae: 0.1750 - val_loss: 0.1233 - val_mae: 0.3097 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0504 - mae: 0.1626 - val_loss: 0.1327 - val_mae: 0.3211 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0539 - mae: 0.1743 - val_loss: 0.0695 - val_mae: 0.2211 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0490 - mae: 0.1643 - val_loss: 0.0767 - val_mae: 0.2325 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0486 - mae: 0.1552 - val_loss: 0.1119 - val_mae: 0.2885 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0422 - mae: 0.1480 - val_loss: 0.1314 - val_mae: 0.3138 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0473 - mae: 0.1521 - val_loss: 0.1081 - val_mae: 0.2788 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0317 - mae: 0.1342 - val_loss: 0.0890 - val_mae: 0.2437 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0347 - mae: 0.1374 - val_loss: 0.0608 - val_mae: 0.1955 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0285 - mae: 0.1236 - val_loss: 0.1018 - val_mae: 0.2681 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0338 - mae: 0.1387 - val_loss: 0.0595 - val_mae: 0.1926 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0296 - mae: 0.1266 - val_loss: 0.0650 - val_mae: 0.1999 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0287 - mae: 0.1167 - val_loss: 0.0605 - val_mae: 0.1902 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0282 - mae: 0.1209 - val_loss: 0.0503 - val_mae: 0.1740 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0256 - mae: 0.1140 - val_loss: 0.0769 - val_mae: 0.2187 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0268 - mae: 0.1097 - val_loss: 0.0656 - val_mae: 0.1957 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0272 - mae: 0.1214 - val_loss: 0.1221 - val_mae: 0.2921 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0323 - mae: 0.1396 - val_loss: 0.0496 - val_mae: 0.1705 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0243 - mae: 0.1202 - val_loss: 0.1602 - val_mae: 0.3492 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0250 - mae: 0.1167 - val_loss: 0.0853 - val_mae: 0.2327 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0240 - mae: 0.1123 - val_loss: 0.1140 - val_mae: 0.2762 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0245 - mae: 0.1154 - val_loss: 0.0839 - val_mae: 0.2242 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0216 - mae: 0.1095 - val_loss: 0.1345 - val_mae: 0.3083 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0285 - mae: 0.1299 - val_loss: 0.0505 - val_mae: 0.1699 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0233 - mae: 0.1151 - val_loss: 0.0775 - val_mae: 0.2125 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0254 - mae: 0.1160 - val_loss: 0.0877 - val_mae: 0.2316 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0199 - mae: 0.1058 - val_loss: 0.0850 - val_mae: 0.2255 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0896 - val_loss: 0.0917 - val_mae: 0.2342 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.1002 - val_loss: 0.0835 - val_mae: 0.2207 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0981 - val_loss: 0.0818 - val_mae: 0.2190 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1023 - val_loss: 0.0943 - val_mae: 0.2415 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 0.1028 - val_loss: 0.0895 - val_mae: 0.2332 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0918 - val_loss: 0.0822 - val_mae: 0.2200 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0891 - val_loss: 0.0826 - val_mae: 0.2199 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1029 - val_loss: 0.0781 - val_mae: 0.2120 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.1008 - val_loss: 0.0791 - val_mae: 0.2135 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.0900 - val_loss: 0.0867 - val_mae: 0.2263 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 0.0989 - val_loss: 0.0878 - val_mae: 0.2289 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.0949 - val_loss: 0.0865 - val_mae: 0.2269 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0202 - mae: 0.1061 - val_loss: 0.0778 - val_mae: 0.2117 - lr: 3.1250e-05\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.1014 - val_loss: 0.0771 - val_mae: 0.2109 - lr: 3.1250e-05\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.1064 - val_loss: 0.0814 - val_mae: 0.2187 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 0.0944 - val_loss: 0.0870 - val_mae: 0.2283 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 0.1061 - val_loss: 0.0869 - val_mae: 0.2279 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0967 - val_loss: 0.0852 - val_mae: 0.2247 - lr: 1.5625e-05\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0897 - val_loss: 0.0830 - val_mae: 0.2209 - lr: 1.5625e-05\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0217 - mae: 0.1072 - val_loss: 0.0808 - val_mae: 0.2176 - lr: 1.5625e-05\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0965 - val_loss: 0.0801 - val_mae: 0.2165 - lr: 1.5625e-05\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0958 - val_loss: 0.0803 - val_mae: 0.2169 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.0989 - val_loss: 0.0810 - val_mae: 0.2179 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0928 - val_loss: 0.0817 - val_mae: 0.2190 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.0993 - val_loss: 0.0836 - val_mae: 0.2220 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0964 - val_loss: 0.0848 - val_mae: 0.2239 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0971 - val_loss: 0.0850 - val_mae: 0.2241 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0946 - val_loss: 0.0844 - val_mae: 0.2232 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0893 - val_loss: 0.0821 - val_mae: 0.2196 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0926 - val_loss: 0.0799 - val_mae: 0.2159 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 0.1020 - val_loss: 0.0791 - val_mae: 0.2146 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0933 - val_loss: 0.0779 - val_mae: 0.2125 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0932 - val_loss: 0.0785 - val_mae: 0.2135 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.1003 - val_loss: 0.0791 - val_mae: 0.2146 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0878 - val_loss: 0.0799 - val_mae: 0.2159 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0155 - mae: 0.0886 - val_loss: 0.0804 - val_mae: 0.2169 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0952 - val_loss: 0.0805 - val_mae: 0.2171 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0206 - mae: 0.1042 - val_loss: 0.0802 - val_mae: 0.2165 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0947 - val_loss: 0.0809 - val_mae: 0.2175 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0158 - mae: 0.0849 - val_loss: 0.0810 - val_mae: 0.2177 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0920 - val_loss: 0.0816 - val_mae: 0.2187 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0987 - val_loss: 0.0821 - val_mae: 0.2195 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0139 - mae: 0.0875 - val_loss: 0.0823 - val_mae: 0.2199 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.0986 - val_loss: 0.0822 - val_mae: 0.2196 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.0886 - val_loss: 0.0815 - val_mae: 0.2181 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0908 - val_loss: 0.0805 - val_mae: 0.2165 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0984 - val_loss: 0.0800 - val_mae: 0.2157 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0914 - val_loss: 0.0794 - val_mae: 0.2146 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0919 - val_loss: 0.0794 - val_mae: 0.2147 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0832 - val_loss: 0.0806 - val_mae: 0.2167 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0987 - val_loss: 0.0799 - val_mae: 0.2156 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0990 - val_loss: 0.0784 - val_mae: 0.2128 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0908 - val_loss: 0.0777 - val_mae: 0.2115 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0908 - val_loss: 0.0773 - val_mae: 0.2107 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.1010 - val_loss: 0.0778 - val_mae: 0.2118 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0956 - val_loss: 0.0780 - val_mae: 0.2121 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0859 - val_loss: 0.0788 - val_mae: 0.2136 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0989 - val_loss: 0.0804 - val_mae: 0.2165 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0948 - val_loss: 0.0826 - val_mae: 0.2204 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0976 - val_loss: 0.0828 - val_mae: 0.2209 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.1021 - val_loss: 0.0814 - val_mae: 0.2186 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0930 - val_loss: 0.0803 - val_mae: 0.2167 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0997 - val_loss: 0.0794 - val_mae: 0.2151 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0975 - val_loss: 0.0806 - val_mae: 0.2172 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 0.0988 - val_loss: 0.0818 - val_mae: 0.2192 - lr: 1.0000e-05\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0671 - mae: 0.2198\n",
      "1/1 [==============================] - 0s 216ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Data     Model       MSE       MAE      MAPE\n0   ada  LSTM-CNN  0.020265  0.121398  0.277190\n1   btc  LSTM-CNN  0.007930  0.072749  1.834286\n2  doge  LSTM-CNN  0.004268  0.056103  5.584329\n3   eth  LSTM-CNN  0.005444  0.066412  1.303854\n4   xmr  LSTM-CNN  0.041189  0.186515  7.039220\n5   xrp  LSTM-CNN  0.012900  0.102465  3.374718\n6  aave  LSTM-CNN  0.067126  0.219814  0.334660",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Model</th>\n      <th>MSE</th>\n      <th>MAE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ada</td>\n      <td>LSTM-CNN</td>\n      <td>0.020265</td>\n      <td>0.121398</td>\n      <td>0.277190</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>btc</td>\n      <td>LSTM-CNN</td>\n      <td>0.007930</td>\n      <td>0.072749</td>\n      <td>1.834286</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>doge</td>\n      <td>LSTM-CNN</td>\n      <td>0.004268</td>\n      <td>0.056103</td>\n      <td>5.584329</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eth</td>\n      <td>LSTM-CNN</td>\n      <td>0.005444</td>\n      <td>0.066412</td>\n      <td>1.303854</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xmr</td>\n      <td>LSTM-CNN</td>\n      <td>0.041189</td>\n      <td>0.186515</td>\n      <td>7.039220</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xrp</td>\n      <td>LSTM-CNN</td>\n      <td>0.012900</td>\n      <td>0.102465</td>\n      <td>3.374718</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aave</td>\n      <td>LSTM-CNN</td>\n      <td>0.067126</td>\n      <td>0.219814</td>\n      <td>0.334660</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.scripts.utils import split_data_frame, apply_functions\n",
    "\n",
    "def run_model_for_dataframe(df):\n",
    "    # Split the DataFrame into train, validation, and test sets\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "\n",
    "    # Apply any additional functions to preprocess the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    # Fit the model\n",
    "    model, history = fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Get the evaluation metrics for each set\n",
    "    mse, mae, mape = evaluate(model, X_test, y_test)\n",
    "\n",
    "    # Return the evaluation metrics along with the model and history\n",
    "    return model, history, (mse, mae, mape)\n",
    "\n",
    "# Assuming crypto_dfs is your dictionary of DataFrames for each crypto\n",
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_model_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    lstm_cnn = 'LSTM-CNN_sentiment'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': lstm_cnn,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "lstm_cnn_df = pd.DataFrame(summary_table)\n",
    "lstm_cnn_df.to_csv('../results/lstm_cnn_sentiment.csv')\n",
    "lstm_cnn_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:17:40.503807Z",
     "start_time": "2024-05-02T14:41:26.754292Z"
    }
   },
   "id": "454d8468ff65d12f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRANSFORMER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8361dbb4b70b0a7"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0, epsilon=1e-6, attention_axes=None, kernel_size=1):\n",
    "    \"\"\"\n",
    "    Creates a single transformer block.\n",
    "    \"\"\"\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout,\n",
    "        attention_axes=attention_axes\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=kernel_size, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=kernel_size)(x)\n",
    "    return x + res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T18:21:55.164959Z",
     "start_time": "2024-05-02T18:21:55.156646Z"
    }
   },
   "id": "f081ecca6372e338"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_transformer(n_timesteps, n_features, head_size, num_heads, ff_dim, num_trans_blocks, mlp_units, dropout=0, mlp_dropout=0, attention_axes=None, epsilon=1e-6, kernel_size=1):\n",
    "    \"\"\"\n",
    "    Creates a transformer model by building multiple transformer blocks.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = inputs\n",
    "    for _ in range(num_trans_blocks):\n",
    "        x = transformer_encoder(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout, attention_axes=attention_axes, kernel_size=kernel_size, epsilon=epsilon)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T18:21:55.422235Z",
     "start_time": "2024-05-02T18:21:55.415389Z"
    }
   },
   "id": "f1ee42a933468fd7"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fit_transformer(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Compiles and fits our transformer with the provided training and validation data.\n",
    "    \"\"\"\n",
    "    transformer = build_transformer(n_timesteps=X_train.shape[1], n_features=X_train.shape[2], head_size=128, num_heads=4, ff_dim=2, num_trans_blocks=4, mlp_units=[256], mlp_dropout=0.10, dropout=0.10, attention_axes=1)    \n",
    "    \n",
    "    transformer.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "        metrics=[\"mae\", \"mape\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = transformer.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=64,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    ).history\n",
    "\n",
    "    print(f\"Training completed in {time.time() - start:.2f} seconds\")\n",
    "    return transformer, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T18:21:55.897350Z",
     "start_time": "2024-05-02T18:21:55.890163Z"
    }
   },
   "id": "5120f9e78fe27e57"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\n",
    "    model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    return mse, mae, mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T18:21:56.370379Z",
     "start_time": "2024-05-02T18:21:56.364224Z"
    }
   },
   "id": "c92cf15c1428be72"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def run_transformer_for_dataframe(df):\n",
    "\n",
    "    # Preprocessing steps\n",
    "    train, val, test = split_data_frame(df, 0.7, 0.2)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = apply_functions(train, test, val)\n",
    "\n",
    "    transformer, history = fit_transformer(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse, mae, mape = evaluate(transformer, X_test, y_test)\n",
    "\n",
    "    # Return the model, history, and metrics\n",
    "    return transformer, history, (mse, mae, mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T18:32:46.201591Z",
     "start_time": "2024-05-02T18:32:46.191635Z"
    }
   },
   "id": "c89324655a1a0c68"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for ada...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 21ms/step - loss: 0.0245 - mae: 0.0861 - mape: 16.5231 - val_loss: 0.0071 - val_mae: 0.0776 - val_mape: 15.1800 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0045 - mae: 0.0484 - mape: 9.2058 - val_loss: 0.0032 - val_mae: 0.0515 - val_mape: 10.0207 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0032 - mae: 0.0410 - mape: 7.2988 - val_loss: 0.0017 - val_mae: 0.0373 - val_mape: 7.2027 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0026 - mae: 0.0367 - mape: 7.0521 - val_loss: 0.0023 - val_mae: 0.0446 - val_mape: 8.7783 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0024 - mae: 0.0344 - mape: 5.9234 - val_loss: 7.9760e-04 - val_mae: 0.0252 - val_mape: 5.0647 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0024 - mae: 0.0342 - mape: 5.6984 - val_loss: 8.6827e-04 - val_mae: 0.0229 - val_mape: 4.5199 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0022 - mae: 0.0329 - mape: 5.7950 - val_loss: 2.7731e-04 - val_mae: 0.0132 - val_mape: 2.5776 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0022 - mae: 0.0329 - mape: 6.2073 - val_loss: 4.4459e-04 - val_mae: 0.0179 - val_mape: 3.5168 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0023 - mae: 0.0336 - mape: 6.2995 - val_loss: 0.0012 - val_mae: 0.0321 - val_mape: 6.3576 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0022 - mae: 0.0325 - mape: 5.2940 - val_loss: 4.8878e-04 - val_mae: 0.0197 - val_mape: 3.9557 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0021 - mae: 0.0320 - mape: 4.9479 - val_loss: 2.5572e-04 - val_mae: 0.0129 - val_mape: 2.5473 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0021 - mae: 0.0319 - mape: 5.6230 - val_loss: 6.8227e-04 - val_mae: 0.0239 - val_mape: 4.7001 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0019 - mae: 0.0294 - mape: 4.9492 - val_loss: 3.8267e-04 - val_mae: 0.0182 - val_mape: 3.6566 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0018 - mae: 0.0293 - mape: 4.3553 - val_loss: 4.1710e-04 - val_mae: 0.0178 - val_mape: 3.5133 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0293 - mape: 4.5448 - val_loss: 7.0316e-04 - val_mae: 0.0252 - val_mape: 5.0339 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0292 - mape: 4.9881 - val_loss: 3.9826e-04 - val_mae: 0.0184 - val_mape: 3.6393 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0294 - mape: 4.8938 - val_loss: 3.2241e-04 - val_mae: 0.0157 - val_mape: 3.1226 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0279 - mape: 4.2180 - val_loss: 1.9216e-04 - val_mae: 0.0119 - val_mape: 2.3510 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0278 - mape: 4.6040 - val_loss: 8.9446e-05 - val_mae: 0.0071 - val_mape: 1.4154 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0017 - mae: 0.0281 - mape: 4.5672 - val_loss: 2.2202e-04 - val_mae: 0.0133 - val_mape: 2.6349 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0280 - mape: 4.5652 - val_loss: 1.8101e-04 - val_mae: 0.0120 - val_mape: 2.3522 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0017 - mae: 0.0281 - mape: 4.4914 - val_loss: 7.8803e-05 - val_mae: 0.0070 - val_mape: 1.3578 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0016 - mae: 0.0278 - mape: 4.8755 - val_loss: 5.0844e-05 - val_mae: 0.0054 - val_mape: 1.0798 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0017 - mae: 0.0280 - mape: 4.7961 - val_loss: 5.7235e-05 - val_mae: 0.0059 - val_mape: 1.1599 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0271 - mape: 4.2323 - val_loss: 8.3522e-05 - val_mae: 0.0077 - val_mape: 1.5477 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0269 - mape: 4.6453 - val_loss: 1.0811e-04 - val_mae: 0.0092 - val_mape: 1.8635 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0270 - mape: 4.5933 - val_loss: 1.5314e-04 - val_mae: 0.0109 - val_mape: 2.1646 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0016 - mae: 0.0269 - mape: 4.5972 - val_loss: 3.4388e-05 - val_mae: 0.0041 - val_mape: 0.8340 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0267 - mape: 4.2435 - val_loss: 1.6095e-04 - val_mae: 0.0111 - val_mape: 2.1954 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0264 - mape: 4.0848 - val_loss: 6.6364e-05 - val_mae: 0.0068 - val_mape: 1.3722 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0015 - mae: 0.0263 - mape: 4.3837 - val_loss: 4.4273e-05 - val_mae: 0.0051 - val_mape: 1.0396 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0262 - mape: 4.2166 - val_loss: 3.7988e-05 - val_mae: 0.0046 - val_mape: 0.9387 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0265 - mape: 4.2744 - val_loss: 4.0163e-05 - val_mae: 0.0047 - val_mape: 0.9481 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0262 - mape: 4.1785 - val_loss: 3.0110e-05 - val_mae: 0.0038 - val_mape: 0.7764 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0260 - mape: 4.2162 - val_loss: 3.6274e-05 - val_mae: 0.0045 - val_mape: 0.8965 - lr: 3.1250e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0259 - mape: 4.2966 - val_loss: 3.2448e-05 - val_mae: 0.0040 - val_mape: 0.8174 - lr: 3.1250e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0260 - mape: 4.2679 - val_loss: 4.0987e-05 - val_mae: 0.0047 - val_mape: 0.9556 - lr: 3.1250e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0015 - mae: 0.0259 - mape: 4.0622 - val_loss: 2.7670e-05 - val_mae: 0.0035 - val_mape: 0.7085 - lr: 3.1250e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0256 - mape: 4.0132 - val_loss: 4.5110e-05 - val_mae: 0.0052 - val_mape: 1.0711 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0257 - mape: 4.0734 - val_loss: 3.0559e-05 - val_mae: 0.0038 - val_mape: 0.7761 - lr: 1.5625e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0259 - mape: 4.0869 - val_loss: 3.0170e-05 - val_mae: 0.0038 - val_mape: 0.7670 - lr: 1.5625e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0255 - mape: 4.0251 - val_loss: 2.9002e-05 - val_mae: 0.0037 - val_mape: 0.7471 - lr: 1.5625e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0258 - mape: 4.0864 - val_loss: 3.1623e-05 - val_mae: 0.0039 - val_mape: 0.8015 - lr: 1.5625e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0256 - mape: 4.1958 - val_loss: 3.0875e-05 - val_mae: 0.0038 - val_mape: 0.7707 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0254 - mape: 4.0405 - val_loss: 2.9602e-05 - val_mae: 0.0037 - val_mape: 0.7719 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0254 - mape: 3.9869 - val_loss: 3.1809e-05 - val_mae: 0.0039 - val_mape: 0.8002 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0257 - mape: 4.2109 - val_loss: 3.0370e-05 - val_mae: 0.0038 - val_mape: 0.7738 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0256 - mape: 4.0916 - val_loss: 3.2241e-05 - val_mae: 0.0039 - val_mape: 0.8028 - lr: 1.0000e-05\n",
      "Training completed in 421.64 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 8.9610e-05 - mae: 0.0059 - mape: 2.8767\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for btc...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 21ms/step - loss: 0.0159 - mae: 0.0807 - mape: 20.7513 - val_loss: 0.0056 - val_mae: 0.0628 - val_mape: 148.9687 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0042 - mae: 0.0481 - mape: 16.3164 - val_loss: 0.0043 - val_mae: 0.0588 - val_mape: 189.6647 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0030 - mae: 0.0412 - mape: 8.2216 - val_loss: 0.0012 - val_mae: 0.0266 - val_mape: 106.5232 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0024 - mae: 0.0363 - mape: 10.7464 - val_loss: 0.0011 - val_mae: 0.0255 - val_mape: 83.3924 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0023 - mae: 0.0357 - mape: 10.8630 - val_loss: 0.0019 - val_mae: 0.0393 - val_mape: 120.0706 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0021 - mae: 0.0340 - mape: 9.1857 - val_loss: 4.1052e-04 - val_mae: 0.0152 - val_mape: 49.2205 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0021 - mae: 0.0337 - mape: 12.6166 - val_loss: 0.0020 - val_mae: 0.0410 - val_mape: 148.6901 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0020 - mae: 0.0328 - mape: 11.7447 - val_loss: 4.4518e-04 - val_mae: 0.0167 - val_mape: 43.6497 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0328 - mape: 10.1903 - val_loss: 7.0483e-04 - val_mae: 0.0204 - val_mape: 72.7742 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0325 - mape: 10.7871 - val_loss: 2.8633e-04 - val_mae: 0.0122 - val_mape: 39.8322 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0324 - mape: 12.0570 - val_loss: 2.9069e-04 - val_mae: 0.0132 - val_mape: 48.7458 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0325 - mape: 9.0772 - val_loss: 2.3791e-04 - val_mae: 0.0116 - val_mape: 39.0486 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0320 - mape: 9.1951 - val_loss: 2.0697e-04 - val_mae: 0.0111 - val_mape: 28.8658 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0322 - mape: 7.5968 - val_loss: 3.3334e-04 - val_mae: 0.0146 - val_mape: 50.8165 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0320 - mape: 11.3500 - val_loss: 2.2110e-04 - val_mae: 0.0114 - val_mape: 32.9261 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0295 - mape: 9.7585 - val_loss: 1.2746e-04 - val_mae: 0.0078 - val_mape: 27.1633 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0291 - mape: 9.6465 - val_loss: 2.9065e-04 - val_mae: 0.0135 - val_mape: 43.9369 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0295 - mape: 9.8520 - val_loss: 2.0168e-04 - val_mae: 0.0110 - val_mape: 21.6424 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0293 - mape: 9.3122 - val_loss: 1.1858e-04 - val_mae: 0.0075 - val_mape: 23.2475 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0294 - mape: 10.5518 - val_loss: 1.7523e-04 - val_mae: 0.0094 - val_mape: 36.4167 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0016 - mae: 0.0293 - mape: 10.1436 - val_loss: 1.2129e-04 - val_mae: 0.0080 - val_mape: 23.6273 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0284 - mape: 8.0304 - val_loss: 1.6144e-04 - val_mae: 0.0099 - val_mape: 36.2403 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0283 - mape: 9.3078 - val_loss: 1.8993e-04 - val_mae: 0.0111 - val_mape: 38.0817 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0283 - mape: 8.7525 - val_loss: 1.7706e-04 - val_mae: 0.0104 - val_mape: 35.7242 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0281 - mape: 8.0949 - val_loss: 1.1305e-04 - val_mae: 0.0078 - val_mape: 28.5438 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0280 - mape: 8.8857 - val_loss: 1.7283e-04 - val_mae: 0.0103 - val_mape: 33.5063 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0276 - mape: 9.5180 - val_loss: 1.2370e-04 - val_mae: 0.0083 - val_mape: 20.9710 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0275 - mape: 9.2541 - val_loss: 1.1169e-04 - val_mae: 0.0077 - val_mape: 21.7699 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0271 - mape: 8.0108 - val_loss: 1.2591e-04 - val_mae: 0.0085 - val_mape: 24.4058 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0274 - mape: 8.0732 - val_loss: 1.2456e-04 - val_mae: 0.0083 - val_mape: 26.3514 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0273 - mape: 8.6947 - val_loss: 9.0301e-05 - val_mae: 0.0066 - val_mape: 21.2313 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0269 - mape: 8.6697 - val_loss: 1.4097e-04 - val_mae: 0.0090 - val_mape: 23.6006 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0268 - mape: 8.8464 - val_loss: 9.4814e-05 - val_mae: 0.0070 - val_mape: 21.4880 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0268 - mape: 8.1139 - val_loss: 1.0375e-04 - val_mae: 0.0073 - val_mape: 20.6077 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0269 - mape: 9.0483 - val_loss: 7.4761e-05 - val_mae: 0.0055 - val_mape: 17.9962 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0267 - mape: 9.2195 - val_loss: 1.0989e-04 - val_mae: 0.0076 - val_mape: 22.1427 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0265 - mape: 8.6377 - val_loss: 1.1531e-04 - val_mae: 0.0082 - val_mape: 24.3183 - lr: 3.1250e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0268 - mape: 8.8155 - val_loss: 1.1408e-04 - val_mae: 0.0081 - val_mape: 25.5916 - lr: 3.1250e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0013 - mae: 0.0266 - mape: 8.1524 - val_loss: 1.0070e-04 - val_mae: 0.0073 - val_mape: 22.7900 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0268 - mape: 8.2206 - val_loss: 1.0615e-04 - val_mae: 0.0078 - val_mape: 22.1996 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0265 - mape: 9.1722 - val_loss: 8.6222e-05 - val_mae: 0.0065 - val_mape: 19.1068 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0263 - mape: 7.6042 - val_loss: 1.2680e-04 - val_mae: 0.0088 - val_mape: 25.6113 - lr: 1.5625e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0264 - mape: 9.1524 - val_loss: 7.8635e-05 - val_mae: 0.0059 - val_mape: 17.7060 - lr: 1.5625e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0261 - mape: 8.3670 - val_loss: 8.9268e-05 - val_mae: 0.0068 - val_mape: 19.1296 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0013 - mae: 0.0264 - mape: 9.4316 - val_loss: 1.1695e-04 - val_mae: 0.0084 - val_mape: 25.3728 - lr: 1.5625e-05\n",
      "Training completed in 362.96 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0136 - mape: 15.4099\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for doge...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 8s 17ms/step - loss: 0.0269 - mae: 0.0904 - mape: 22.9632 - val_loss: 0.0048 - val_mae: 0.0618 - val_mape: 170.3615 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0067 - mae: 0.0543 - mape: 12.0404 - val_loss: 0.0012 - val_mae: 0.0259 - val_mape: 50.5527 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0051 - mae: 0.0469 - mape: 10.7910 - val_loss: 4.2924e-04 - val_mae: 0.0161 - val_mape: 37.0099 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0041 - mae: 0.0412 - mape: 9.5226 - val_loss: 3.8673e-04 - val_mae: 0.0148 - val_mape: 35.3273 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0040 - mae: 0.0405 - mape: 8.3602 - val_loss: 3.8732e-04 - val_mae: 0.0145 - val_mape: 43.7203 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0037 - mae: 0.0376 - mape: 7.8647 - val_loss: 8.8917e-04 - val_mae: 0.0245 - val_mape: 85.5779 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0034 - mae: 0.0367 - mape: 7.8337 - val_loss: 8.5847e-04 - val_mae: 0.0222 - val_mape: 58.0931 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0033 - mae: 0.0360 - mape: 8.6808 - val_loss: 5.4741e-04 - val_mae: 0.0201 - val_mape: 51.4940 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0027 - mae: 0.0318 - mape: 5.7478 - val_loss: 3.6511e-04 - val_mae: 0.0148 - val_mape: 45.4705 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0027 - mae: 0.0312 - mape: 7.0100 - val_loss: 2.2417e-04 - val_mae: 0.0105 - val_mape: 39.7492 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0027 - mae: 0.0316 - mape: 6.0870 - val_loss: 1.8713e-04 - val_mae: 0.0093 - val_mape: 26.6950 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0026 - mae: 0.0309 - mape: 6.4936 - val_loss: 3.4501e-04 - val_mae: 0.0139 - val_mape: 38.6839 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0026 - mae: 0.0313 - mape: 6.8580 - val_loss: 2.9043e-04 - val_mae: 0.0114 - val_mape: 32.6883 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 7s 18ms/step - loss: 0.0027 - mae: 0.0315 - mape: 5.4848 - val_loss: 3.2837e-04 - val_mae: 0.0137 - val_mape: 47.8852 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0026 - mae: 0.0311 - mape: 6.9872 - val_loss: 2.2046e-04 - val_mae: 0.0104 - val_mape: 35.2902 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0023 - mae: 0.0285 - mape: 6.7086 - val_loss: 1.8568e-04 - val_mae: 0.0094 - val_mape: 29.9002 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0022 - mae: 0.0284 - mape: 7.0580 - val_loss: 3.9708e-04 - val_mae: 0.0162 - val_mape: 49.5296 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0023 - mae: 0.0287 - mape: 6.3067 - val_loss: 1.8809e-04 - val_mae: 0.0093 - val_mape: 29.7820 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0022 - mae: 0.0285 - mape: 6.4873 - val_loss: 3.6804e-04 - val_mae: 0.0158 - val_mape: 37.0367 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0022 - mae: 0.0286 - mape: 6.0144 - val_loss: 7.3414e-04 - val_mae: 0.0236 - val_mape: 55.7513 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0275 - mape: 6.1457 - val_loss: 2.7743e-04 - val_mae: 0.0130 - val_mape: 33.3109 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0021 - mae: 0.0275 - mape: 5.5441 - val_loss: 1.7804e-04 - val_mae: 0.0098 - val_mape: 25.6447 - lr: 1.2500e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0271 - mape: 4.8493 - val_loss: 1.6919e-04 - val_mae: 0.0085 - val_mape: 24.2963 - lr: 1.2500e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0269 - mape: 6.0906 - val_loss: 2.2606e-04 - val_mae: 0.0108 - val_mape: 31.6869 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0270 - mape: 5.5869 - val_loss: 2.3647e-04 - val_mae: 0.0117 - val_mape: 29.5840 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0266 - mape: 6.1411 - val_loss: 2.2507e-04 - val_mae: 0.0118 - val_mape: 31.2130 - lr: 6.2500e-05\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0266 - mape: 5.9459 - val_loss: 1.3317e-04 - val_mae: 0.0072 - val_mape: 23.1605 - lr: 6.2500e-05\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0266 - mape: 5.8230 - val_loss: 2.1949e-04 - val_mae: 0.0115 - val_mape: 29.3599 - lr: 6.2500e-05\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0020 - mae: 0.0266 - mape: 5.9253 - val_loss: 1.4685e-04 - val_mae: 0.0082 - val_mape: 24.2067 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0265 - mape: 5.9688 - val_loss: 1.3832e-04 - val_mae: 0.0076 - val_mape: 22.5923 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0262 - mape: 5.6671 - val_loss: 1.2491e-04 - val_mae: 0.0069 - val_mape: 21.2182 - lr: 3.1250e-05\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0262 - mape: 5.9437 - val_loss: 1.2669e-04 - val_mae: 0.0073 - val_mape: 21.3962 - lr: 3.1250e-05\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0260 - mape: 5.5486 - val_loss: 1.6061e-04 - val_mae: 0.0091 - val_mape: 25.4623 - lr: 3.1250e-05\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0262 - mape: 5.7051 - val_loss: 1.7196e-04 - val_mae: 0.0095 - val_mape: 26.7861 - lr: 3.1250e-05\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 7s 18ms/step - loss: 0.0018 - mae: 0.0260 - mape: 5.7317 - val_loss: 1.2788e-04 - val_mae: 0.0071 - val_mape: 21.3237 - lr: 3.1250e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 7s 18ms/step - loss: 0.0018 - mae: 0.0260 - mape: 6.0176 - val_loss: 1.2156e-04 - val_mae: 0.0065 - val_mape: 21.1636 - lr: 1.5625e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0019 - mae: 0.0261 - mape: 5.8548 - val_loss: 1.2946e-04 - val_mae: 0.0073 - val_mape: 21.2990 - lr: 1.5625e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0259 - mape: 5.7902 - val_loss: 1.2626e-04 - val_mae: 0.0069 - val_mape: 21.8819 - lr: 1.5625e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0258 - mape: 5.8864 - val_loss: 1.6232e-04 - val_mae: 0.0092 - val_mape: 25.2015 - lr: 1.5625e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0261 - mape: 5.2933 - val_loss: 1.2239e-04 - val_mae: 0.0068 - val_mape: 22.0615 - lr: 1.5625e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0261 - mape: 5.4870 - val_loss: 1.3492e-04 - val_mae: 0.0075 - val_mape: 22.2451 - lr: 1.5625e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0261 - mape: 6.2293 - val_loss: 1.2726e-04 - val_mae: 0.0071 - val_mape: 21.5301 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0258 - mape: 5.3384 - val_loss: 1.4275e-04 - val_mae: 0.0081 - val_mape: 22.6566 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0258 - mape: 5.8905 - val_loss: 1.3722e-04 - val_mae: 0.0078 - val_mape: 22.6055 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0257 - mape: 6.2074 - val_loss: 1.4417e-04 - val_mae: 0.0081 - val_mape: 23.0011 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0018 - mae: 0.0258 - mape: 5.6081 - val_loss: 1.3608e-04 - val_mae: 0.0077 - val_mape: 22.0739 - lr: 1.0000e-05\n",
      "Training completed in 350.22 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 7.1294e-05 - mae: 0.0058 - mape: 37.8267\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for eth...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 9s 18ms/step - loss: 0.0157 - mae: 0.0792 - mape: 58.8019 - val_loss: 0.0126 - val_mae: 0.0971 - val_mape: 466.4494 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0044 - mae: 0.0490 - mape: 25.2321 - val_loss: 0.0063 - val_mae: 0.0712 - val_mape: 317.5815 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0031 - mae: 0.0416 - mape: 21.6416 - val_loss: 0.0057 - val_mae: 0.0676 - val_mape: 279.3976 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0028 - mae: 0.0391 - mape: 22.7569 - val_loss: 0.0039 - val_mae: 0.0541 - val_mape: 239.6249 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0025 - mae: 0.0366 - mape: 16.4012 - val_loss: 0.0026 - val_mae: 0.0441 - val_mape: 216.4621 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0357 - mape: 18.4304 - val_loss: 9.8987e-04 - val_mae: 0.0252 - val_mape: 110.8013 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0023 - mae: 0.0349 - mape: 19.4277 - val_loss: 4.3876e-04 - val_mae: 0.0159 - val_mape: 58.1201 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0022 - mae: 0.0342 - mape: 16.8283 - val_loss: 0.0023 - val_mae: 0.0432 - val_mape: 235.7709 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0340 - mape: 17.8249 - val_loss: 0.0012 - val_mae: 0.0312 - val_mape: 128.2549 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0022 - mae: 0.0338 - mape: 17.9649 - val_loss: 8.1157e-04 - val_mae: 0.0238 - val_mape: 160.8932 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0020 - mae: 0.0327 - mape: 18.8755 - val_loss: 6.8995e-04 - val_mae: 0.0217 - val_mape: 123.3516 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0020 - mae: 0.0328 - mape: 16.2228 - val_loss: 6.5630e-04 - val_mae: 0.0214 - val_mape: 138.6432 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0018 - mae: 0.0307 - mape: 15.0616 - val_loss: 3.6629e-04 - val_mae: 0.0152 - val_mape: 100.3522 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0302 - mape: 13.2896 - val_loss: 2.6440e-04 - val_mae: 0.0127 - val_mape: 56.4938 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0018 - mae: 0.0304 - mape: 14.6629 - val_loss: 4.3513e-04 - val_mae: 0.0166 - val_mape: 90.5165 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0304 - mape: 12.5607 - val_loss: 2.3964e-04 - val_mae: 0.0119 - val_mape: 69.6023 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0018 - mae: 0.0309 - mape: 13.6634 - val_loss: 7.3731e-04 - val_mae: 0.0229 - val_mape: 116.0943 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0018 - mae: 0.0305 - mape: 13.9940 - val_loss: 5.0898e-04 - val_mae: 0.0187 - val_mape: 61.6937 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0301 - mape: 13.4664 - val_loss: 8.1252e-04 - val_mae: 0.0251 - val_mape: 146.3763 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0288 - mape: 13.1739 - val_loss: 3.1064e-04 - val_mae: 0.0137 - val_mape: 88.5570 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0016 - mae: 0.0291 - mape: 13.0008 - val_loss: 3.2508e-04 - val_mae: 0.0143 - val_mape: 90.5348 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0292 - mape: 12.7729 - val_loss: 1.8967e-04 - val_mae: 0.0095 - val_mape: 54.3930 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0292 - mape: 12.5134 - val_loss: 1.7506e-04 - val_mae: 0.0086 - val_mape: 36.7403 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0288 - mape: 12.9866 - val_loss: 1.5060e-04 - val_mae: 0.0085 - val_mape: 40.2352 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0016 - mae: 0.0289 - mape: 12.2062 - val_loss: 1.7257e-04 - val_mae: 0.0090 - val_mape: 48.2439 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0017 - mae: 0.0293 - mape: 12.3055 - val_loss: 1.9212e-04 - val_mae: 0.0092 - val_mape: 37.3219 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0016 - mae: 0.0288 - mape: 12.2388 - val_loss: 1.4131e-04 - val_mae: 0.0076 - val_mape: 39.5408 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0288 - mape: 12.0196 - val_loss: 3.9976e-04 - val_mae: 0.0173 - val_mape: 66.0344 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0288 - mape: 12.9764 - val_loss: 1.8726e-04 - val_mae: 0.0096 - val_mape: 50.5502 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0282 - mape: 11.9775 - val_loss: 1.2257e-04 - val_mae: 0.0071 - val_mape: 29.5100 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0280 - mape: 11.5062 - val_loss: 1.6261e-04 - val_mae: 0.0092 - val_mape: 71.6449 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0279 - mape: 11.4813 - val_loss: 1.4645e-04 - val_mae: 0.0083 - val_mape: 59.3007 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0280 - mape: 11.3170 - val_loss: 1.8297e-04 - val_mae: 0.0102 - val_mape: 25.9228 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0015 - mae: 0.0279 - mape: 11.9293 - val_loss: 1.6646e-04 - val_mae: 0.0096 - val_mape: 48.7003 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0275 - mape: 12.0134 - val_loss: 1.3565e-04 - val_mae: 0.0080 - val_mape: 36.5751 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0277 - mape: 11.1359 - val_loss: 1.2565e-04 - val_mae: 0.0073 - val_mape: 41.4904 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0276 - mape: 12.6563 - val_loss: 1.1388e-04 - val_mae: 0.0067 - val_mape: 22.2734 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0276 - mape: 11.2706 - val_loss: 1.2490e-04 - val_mae: 0.0074 - val_mape: 53.0277 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0274 - mape: 11.6355 - val_loss: 1.1885e-04 - val_mae: 0.0069 - val_mape: 23.8766 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0272 - mape: 11.3912 - val_loss: 1.1774e-04 - val_mae: 0.0070 - val_mape: 37.4434 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0273 - mape: 11.5041 - val_loss: 1.2099e-04 - val_mae: 0.0069 - val_mape: 47.2469 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0015 - mae: 0.0273 - mape: 11.4364 - val_loss: 1.3453e-04 - val_mae: 0.0081 - val_mape: 32.9923 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0270 - mape: 11.4998 - val_loss: 1.2357e-04 - val_mae: 0.0073 - val_mape: 38.8230 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0270 - mape: 11.4289 - val_loss: 1.1588e-04 - val_mae: 0.0069 - val_mape: 38.1121 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0271 - mape: 11.3357 - val_loss: 1.1728e-04 - val_mae: 0.0069 - val_mape: 32.9471 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0270 - mape: 12.0061 - val_loss: 1.3284e-04 - val_mae: 0.0080 - val_mape: 27.0200 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0014 - mae: 0.0271 - mape: 11.4626 - val_loss: 1.0698e-04 - val_mae: 0.0065 - val_mape: 41.1231 - lr: 1.5625e-05\n",
      "Epoch 48/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0268 - mape: 10.9715 - val_loss: 1.1262e-04 - val_mae: 0.0066 - val_mape: 37.2515 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0267 - mape: 11.7254 - val_loss: 1.1369e-04 - val_mae: 0.0068 - val_mape: 34.6833 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0269 - mape: 10.6851 - val_loss: 1.1787e-04 - val_mae: 0.0071 - val_mape: 35.6348 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0268 - mape: 10.7599 - val_loss: 1.1327e-04 - val_mae: 0.0068 - val_mape: 42.4122 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0266 - mape: 11.0548 - val_loss: 1.0830e-04 - val_mae: 0.0065 - val_mape: 38.5783 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0267 - mape: 10.4506 - val_loss: 1.2212e-04 - val_mae: 0.0071 - val_mape: 53.0106 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0271 - mape: 10.4189 - val_loss: 1.0984e-04 - val_mae: 0.0064 - val_mape: 42.5599 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0269 - mape: 10.3294 - val_loss: 1.1700e-04 - val_mae: 0.0069 - val_mape: 42.9867 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0014 - mae: 0.0268 - mape: 11.3872 - val_loss: 1.2172e-04 - val_mae: 0.0073 - val_mape: 41.0142 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0014 - mae: 0.0271 - mape: 11.0399 - val_loss: 1.1398e-04 - val_mae: 0.0068 - val_mape: 36.6990 - lr: 1.0000e-05\n",
      "Training completed in 485.59 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 1.5452e-04 - mae: 0.0084 - mape: 32.7412\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for xmr...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 21ms/step - loss: 0.0245 - mae: 0.0916 - mape: 86.7910 - val_loss: 0.0047 - val_mae: 0.0569 - val_mape: 1580.9437 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0057 - mae: 0.0546 - mape: 39.0763 - val_loss: 0.0027 - val_mae: 0.0410 - val_mape: 1754.9313 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0043 - mae: 0.0472 - mape: 41.9721 - val_loss: 0.0011 - val_mae: 0.0234 - val_mape: 725.5500 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0037 - mae: 0.0434 - mape: 31.9272 - val_loss: 0.0091 - val_mae: 0.0908 - val_mape: 3605.9050 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0034 - mae: 0.0416 - mape: 31.5485 - val_loss: 0.0016 - val_mae: 0.0330 - val_mape: 1443.2227 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0031 - mae: 0.0394 - mape: 40.7349 - val_loss: 7.8938e-04 - val_mae: 0.0201 - val_mape: 372.0756 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0030 - mae: 0.0389 - mape: 32.1604 - val_loss: 5.4201e-04 - val_mae: 0.0154 - val_mape: 312.4232 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0029 - mae: 0.0379 - mape: 27.5024 - val_loss: 5.0019e-04 - val_mae: 0.0142 - val_mape: 584.6420 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0027 - mae: 0.0370 - mape: 30.7790 - val_loss: 4.0206e-04 - val_mae: 0.0129 - val_mape: 368.2796 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0026 - mae: 0.0365 - mape: 30.4053 - val_loss: 3.2685e-04 - val_mae: 0.0112 - val_mape: 337.3863 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0026 - mae: 0.0360 - mape: 30.4755 - val_loss: 5.1035e-04 - val_mae: 0.0153 - val_mape: 460.3041 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 11s 25ms/step - loss: 0.0026 - mae: 0.0364 - mape: 39.6743 - val_loss: 8.0791e-04 - val_mae: 0.0233 - val_mape: 1100.6559 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0024 - mae: 0.0353 - mape: 29.4075 - val_loss: 6.8550e-04 - val_mae: 0.0209 - val_mape: 368.0275 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 11s 26ms/step - loss: 0.0024 - mae: 0.0350 - mape: 25.0948 - val_loss: 3.8450e-04 - val_mae: 0.0128 - val_mape: 183.9896 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 10s 24ms/step - loss: 0.0020 - mae: 0.0313 - mape: 20.9815 - val_loss: 3.7098e-04 - val_mae: 0.0121 - val_mape: 515.4985 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 10s 23ms/step - loss: 0.0019 - mae: 0.0309 - mape: 26.9403 - val_loss: 3.0187e-04 - val_mae: 0.0110 - val_mape: 561.2825 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0019 - mae: 0.0311 - mape: 25.3991 - val_loss: 3.5393e-04 - val_mae: 0.0124 - val_mape: 132.4616 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0019 - mae: 0.0306 - mape: 26.4581 - val_loss: 2.7809e-04 - val_mae: 0.0107 - val_mape: 186.1468 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0019 - mae: 0.0310 - mape: 23.7882 - val_loss: 4.2665e-04 - val_mae: 0.0149 - val_mape: 755.3987 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0019 - mae: 0.0308 - mape: 21.6763 - val_loss: 5.9459e-04 - val_mae: 0.0190 - val_mape: 343.6878 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0019 - mae: 0.0309 - mape: 24.8258 - val_loss: 2.6637e-04 - val_mae: 0.0109 - val_mape: 294.0454 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0016 - mae: 0.0283 - mape: 24.4514 - val_loss: 2.6779e-04 - val_mae: 0.0080 - val_mape: 417.7607 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 9s 21ms/step - loss: 0.0017 - mae: 0.0287 - mape: 22.1671 - val_loss: 2.3983e-04 - val_mae: 0.0081 - val_mape: 301.8020 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 0.0016 - mae: 0.0284 - mape: 21.3871 - val_loss: 2.5041e-04 - val_mae: 0.0084 - val_mape: 467.2129 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0017 - mae: 0.0286 - mape: 22.3334 - val_loss: 2.5387e-04 - val_mae: 0.0091 - val_mape: 533.4241 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0016 - mae: 0.0281 - mape: 23.6953 - val_loss: 3.5215e-04 - val_mae: 0.0131 - val_mape: 122.3960 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0274 - mape: 25.1562 - val_loss: 2.2166e-04 - val_mae: 0.0079 - val_mape: 302.2199 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0273 - mape: 18.1422 - val_loss: 2.1154e-04 - val_mae: 0.0076 - val_mape: 394.3941 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0273 - mape: 26.6389 - val_loss: 2.2399e-04 - val_mae: 0.0077 - val_mape: 359.0139 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0272 - mape: 18.5667 - val_loss: 1.9095e-04 - val_mae: 0.0075 - val_mape: 389.2264 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0272 - mape: 20.4651 - val_loss: 2.1629e-04 - val_mae: 0.0078 - val_mape: 300.3926 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0272 - mape: 19.5510 - val_loss: 1.8648e-04 - val_mae: 0.0069 - val_mape: 265.2901 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0270 - mape: 16.1162 - val_loss: 2.1374e-04 - val_mae: 0.0081 - val_mape: 439.7312 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0015 - mae: 0.0270 - mape: 17.7273 - val_loss: 1.7149e-04 - val_mae: 0.0066 - val_mape: 229.6436 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0015 - mae: 0.0269 - mape: 24.1885 - val_loss: 2.1121e-04 - val_mae: 0.0084 - val_mape: 507.8665 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0264 - mape: 20.8644 - val_loss: 1.9555e-04 - val_mae: 0.0070 - val_mape: 357.8056 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0262 - mape: 16.4005 - val_loss: 2.3388e-04 - val_mae: 0.0089 - val_mape: 515.8674 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0264 - mape: 21.4803 - val_loss: 1.9745e-04 - val_mae: 0.0069 - val_mape: 427.5192 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0262 - mape: 17.2922 - val_loss: 1.9319e-04 - val_mae: 0.0068 - val_mape: 400.1369 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0014 - mae: 0.0261 - mape: 16.0752 - val_loss: 1.8662e-04 - val_mae: 0.0068 - val_mape: 323.7796 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0257 - mape: 17.5593 - val_loss: 1.8916e-04 - val_mae: 0.0066 - val_mape: 341.2969 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0257 - mape: 13.1332 - val_loss: 1.9098e-04 - val_mae: 0.0068 - val_mape: 368.3301 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0260 - mape: 15.5519 - val_loss: 1.8120e-04 - val_mae: 0.0064 - val_mape: 198.5656 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 0.0014 - mae: 0.0260 - mape: 15.4078 - val_loss: 1.7505e-04 - val_mae: 0.0064 - val_mape: 232.3469 - lr: 3.1250e-05\n",
      "Training completed in 376.60 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 1.6586e-04 - mae: 0.0093 - mape: 37.0243\n",
      "121/121 [==============================] - 1s 3ms/step\n",
      "Running model for xrp...\n",
      "Epoch 1/100\n",
      "423/423 [==============================] - 10s 20ms/step - loss: 0.0222 - mae: 0.0868 - mape: 24.5825 - val_loss: 0.0106 - val_mae: 0.0685 - val_mape: 249.9789 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "423/423 [==============================] - 9s 22ms/step - loss: 0.0056 - mae: 0.0528 - mape: 15.7304 - val_loss: 0.0057 - val_mae: 0.0337 - val_mape: 130.3506 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "423/423 [==============================] - 9s 20ms/step - loss: 0.0043 - mae: 0.0459 - mape: 13.6554 - val_loss: 0.0027 - val_mae: 0.0302 - val_mape: 57.6564 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0036 - mae: 0.0414 - mape: 13.0543 - val_loss: 0.0039 - val_mae: 0.0348 - val_mape: 114.3453 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0034 - mae: 0.0396 - mape: 11.8694 - val_loss: 0.0032 - val_mae: 0.0285 - val_mape: 78.4798 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0032 - mae: 0.0384 - mape: 13.2243 - val_loss: 0.0026 - val_mae: 0.0307 - val_mape: 72.8203 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0030 - mae: 0.0372 - mape: 11.8551 - val_loss: 0.0022 - val_mae: 0.0219 - val_mape: 68.5447 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0030 - mae: 0.0364 - mape: 11.2456 - val_loss: 0.0019 - val_mae: 0.0219 - val_mape: 50.1823 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0031 - mae: 0.0372 - mape: 10.9121 - val_loss: 0.0015 - val_mae: 0.0237 - val_mape: 41.5189 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0029 - mae: 0.0358 - mape: 12.1794 - val_loss: 0.0028 - val_mae: 0.0263 - val_mape: 100.2610 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0028 - mae: 0.0350 - mape: 10.2737 - val_loss: 0.0013 - val_mae: 0.0205 - val_mape: 38.5379 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0029 - mae: 0.0361 - mape: 11.2665 - val_loss: 0.0013 - val_mae: 0.0210 - val_mape: 56.2794 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0026 - mae: 0.0347 - mape: 11.2006 - val_loss: 0.0018 - val_mae: 0.0295 - val_mape: 77.7730 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0028 - mae: 0.0353 - mape: 10.5498 - val_loss: 0.0013 - val_mae: 0.0149 - val_mape: 43.7478 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0027 - mae: 0.0351 - mape: 10.9564 - val_loss: 0.0011 - val_mae: 0.0147 - val_mape: 37.9851 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0334 - mape: 10.1108 - val_loss: 0.0019 - val_mae: 0.0230 - val_mape: 68.1174 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0026 - mae: 0.0345 - mape: 11.7253 - val_loss: 0.0011 - val_mae: 0.0164 - val_mape: 34.1525 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0025 - mae: 0.0335 - mape: 10.8011 - val_loss: 0.0019 - val_mae: 0.0215 - val_mape: 81.8460 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0329 - mape: 9.9966 - val_loss: 0.0011 - val_mae: 0.0201 - val_mape: 46.7931 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0024 - mae: 0.0327 - mape: 9.4440 - val_loss: 0.0011 - val_mae: 0.0161 - val_mape: 40.9570 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0302 - mape: 8.1183 - val_loss: 0.0011 - val_mae: 0.0120 - val_mape: 36.7033 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0302 - mape: 8.4615 - val_loss: 9.7598e-04 - val_mae: 0.0114 - val_mape: 35.6774 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0300 - mape: 7.6033 - val_loss: 9.3839e-04 - val_mae: 0.0152 - val_mape: 31.2612 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0295 - mape: 8.7641 - val_loss: 9.1733e-04 - val_mae: 0.0117 - val_mape: 36.8974 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0295 - mape: 8.5143 - val_loss: 9.5562e-04 - val_mae: 0.0169 - val_mape: 48.2604 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0021 - mae: 0.0305 - mape: 8.4399 - val_loss: 8.7284e-04 - val_mae: 0.0121 - val_mape: 31.0041 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0296 - mape: 7.6648 - val_loss: 0.0011 - val_mae: 0.0124 - val_mape: 37.7758 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0297 - mape: 8.3576 - val_loss: 9.9336e-04 - val_mae: 0.0125 - val_mape: 31.7493 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0300 - mape: 9.0722 - val_loss: 0.0010 - val_mae: 0.0118 - val_mape: 35.0727 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0019 - mae: 0.0292 - mape: 7.5525 - val_loss: 9.9793e-04 - val_mae: 0.0122 - val_mape: 44.6987 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0020 - mae: 0.0295 - mape: 7.8101 - val_loss: 0.0011 - val_mae: 0.0133 - val_mape: 33.5495 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0283 - mape: 8.0713 - val_loss: 0.0010 - val_mae: 0.0137 - val_mape: 47.0380 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0018 - mae: 0.0278 - mape: 6.8415 - val_loss: 0.0013 - val_mae: 0.0168 - val_mape: 35.4239 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0278 - mape: 6.9977 - val_loss: 0.0010 - val_mae: 0.0105 - val_mape: 36.9932 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0280 - mape: 7.7685 - val_loss: 0.0011 - val_mae: 0.0121 - val_mape: 38.1222 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 0.0017 - mae: 0.0275 - mape: 9.0767 - val_loss: 0.0012 - val_mae: 0.0131 - val_mape: 36.9842 - lr: 2.5000e-04\n",
      "Training completed in 293.04 seconds\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 3.4231e-04 - mae: 0.0136 - mape: 51.0229\n",
      "121/121 [==============================] - 0s 3ms/step\n",
      "Running model for aave...\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 67ms/step - loss: 0.9970 - mae: 0.9125 - mape: 100.2051 - val_loss: 0.0787 - val_mae: 0.2155 - val_mape: 184.1853 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7987 - mae: 0.7860 - mape: 87.4943 - val_loss: 0.2038 - val_mae: 0.4027 - val_mape: 563.5056 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3835 - mae: 0.5197 - mape: 64.9367 - val_loss: 0.4685 - val_mae: 0.6655 - val_mape: 966.5985 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1302 - mae: 0.2796 - mape: 51.2464 - val_loss: 0.1911 - val_mae: 0.3979 - val_mape: 585.0206 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1692 - mae: 0.3269 - mape: 67.2635 - val_loss: 0.1444 - val_mae: 0.3416 - val_mape: 482.2106 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0868 - mae: 0.2148 - mape: 44.0034 - val_loss: 0.1677 - val_mae: 0.3572 - val_mape: 500.5602 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1045 - mae: 0.2701 - mape: 49.8609 - val_loss: 0.1679 - val_mae: 0.3511 - val_mape: 474.1977 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0888 - mae: 0.2361 - mape: 41.7209 - val_loss: 0.1254 - val_mae: 0.3011 - val_mape: 400.5686 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0655 - mae: 0.1882 - mape: 40.0919 - val_loss: 0.0945 - val_mae: 0.2615 - val_mape: 350.3127 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0635 - mae: 0.1888 - mape: 41.8618 - val_loss: 0.0849 - val_mae: 0.2482 - val_mape: 337.0656 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0584 - mae: 0.1840 - mape: 40.5481 - val_loss: 0.0899 - val_mae: 0.2572 - val_mape: 341.6247 - lr: 5.0000e-04\n",
      "Training completed in 1.85 seconds\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2489 - mae: 0.4831 - mape: 69.3312\n",
      "1/1 [==============================] - 0s 124ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Data                  Model       MSE       MAE      MAPE\n0   ada  Transformer_sentiment  0.000090  0.005927  0.028767\n1   btc  Transformer_sentiment  0.001656  0.013554  0.154099\n2  doge  Transformer_sentiment  0.000071  0.005782  0.378267\n3   eth  Transformer_sentiment  0.000155  0.008440  0.327412\n4   xmr  Transformer_sentiment  0.000166  0.009335  0.370243\n5   xrp  Transformer_sentiment  0.000342  0.013617  0.510229\n6  aave  Transformer_sentiment  0.248934  0.483078  0.693312",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Model</th>\n      <th>MSE</th>\n      <th>MAE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ada</td>\n      <td>Transformer_sentiment</td>\n      <td>0.000090</td>\n      <td>0.005927</td>\n      <td>0.028767</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>btc</td>\n      <td>Transformer_sentiment</td>\n      <td>0.001656</td>\n      <td>0.013554</td>\n      <td>0.154099</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>doge</td>\n      <td>Transformer_sentiment</td>\n      <td>0.000071</td>\n      <td>0.005782</td>\n      <td>0.378267</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eth</td>\n      <td>Transformer_sentiment</td>\n      <td>0.000155</td>\n      <td>0.008440</td>\n      <td>0.327412</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>xmr</td>\n      <td>Transformer_sentiment</td>\n      <td>0.000166</td>\n      <td>0.009335</td>\n      <td>0.370243</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xrp</td>\n      <td>Transformer_sentiment</td>\n      <td>0.000342</td>\n      <td>0.013617</td>\n      <td>0.510229</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aave</td>\n      <td>Transformer_sentiment</td>\n      <td>0.248934</td>\n      <td>0.483078</td>\n      <td>0.693312</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = []\n",
    "\n",
    "for crypto, df in crypto_dfs.items():\n",
    "\n",
    "    print(f\"Running model for {crypto}...\")\n",
    "    model, history, metrics = run_transformer_for_dataframe(df)\n",
    "\n",
    "    # Unpack the metrics\n",
    "    transformer_sent = 'Transformer_sentiment'\n",
    "    mse, mae, mape = metrics\n",
    "\n",
    "    # Append the metrics to the summary table\n",
    "    summary_table.append({\n",
    "        'Data': crypto,\n",
    "        'Model': transformer_sent,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "# Convert the summary table to a DataFrame\n",
    "transformer_sent_df = pd.DataFrame(summary_table)\n",
    "transformer_sent_df.to_csv('../results/transformer_sentiment.csv')\n",
    "transformer_sent_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T19:11:28.642566Z",
     "start_time": "2024-05-02T18:32:47.827089Z"
    }
   },
   "id": "f8a3d73d589f19c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8d461914cba7065"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                            ada       btc      doge       eth       xmr  \\\nLSTM                   0.039191  0.036518   0.04523  0.058626  0.034918   \nLSTM-CNN               0.081877  0.042862  0.050316  0.039123  0.046871   \nTransformer            0.581803    0.0107  0.026137  0.608224  0.012544   \nLSTM_sentiment         0.050398  0.015871  0.013051  0.034302  0.012693   \nLSTM-CNN_sentiment     0.121398  0.072749  0.056103  0.066412  0.186515   \nTransformer_sentiment  0.005927  0.013554  0.005782   0.00844  0.009335   \n\n                            xrp      aave  \nLSTM                     0.0142  0.402494  \nLSTM-CNN               0.026126   0.44255  \nTransformer            0.173767  0.093047  \nLSTM_sentiment         0.022688  0.470003  \nLSTM-CNN_sentiment     0.102465  0.219814  \nTransformer_sentiment  0.013617  0.483078  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ada</th>\n      <th>btc</th>\n      <th>doge</th>\n      <th>eth</th>\n      <th>xmr</th>\n      <th>xrp</th>\n      <th>aave</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LSTM</th>\n      <td>0.039191</td>\n      <td>0.036518</td>\n      <td>0.04523</td>\n      <td>0.058626</td>\n      <td>0.034918</td>\n      <td>0.0142</td>\n      <td>0.402494</td>\n    </tr>\n    <tr>\n      <th>LSTM-CNN</th>\n      <td>0.081877</td>\n      <td>0.042862</td>\n      <td>0.050316</td>\n      <td>0.039123</td>\n      <td>0.046871</td>\n      <td>0.026126</td>\n      <td>0.44255</td>\n    </tr>\n    <tr>\n      <th>Transformer</th>\n      <td>0.581803</td>\n      <td>0.0107</td>\n      <td>0.026137</td>\n      <td>0.608224</td>\n      <td>0.012544</td>\n      <td>0.173767</td>\n      <td>0.093047</td>\n    </tr>\n    <tr>\n      <th>LSTM_sentiment</th>\n      <td>0.050398</td>\n      <td>0.015871</td>\n      <td>0.013051</td>\n      <td>0.034302</td>\n      <td>0.012693</td>\n      <td>0.022688</td>\n      <td>0.470003</td>\n    </tr>\n    <tr>\n      <th>LSTM-CNN_sentiment</th>\n      <td>0.121398</td>\n      <td>0.072749</td>\n      <td>0.056103</td>\n      <td>0.066412</td>\n      <td>0.186515</td>\n      <td>0.102465</td>\n      <td>0.219814</td>\n    </tr>\n    <tr>\n      <th>Transformer_sentiment</th>\n      <td>0.005927</td>\n      <td>0.013554</td>\n      <td>0.005782</td>\n      <td>0.00844</td>\n      <td>0.009335</td>\n      <td>0.013617</td>\n      <td>0.483078</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['LSTM', 'LSTM-CNN', 'Transformer', 'LSTM_sentiment', 'LSTM-CNN_sentiment', 'Transformer_sentiment']\n",
    "cryptos = ['ada', 'btc', 'doge', 'eth', 'xmr', 'xrp', 'aave']\n",
    "file_paths = ['../results/lstm.csv', '../results/lstm_cnn.csv', '../results/transformer.csv', '../results/lstm_sentiment.csv', '../results/lstm_cnn_sentiment.csv', '../results/transformer_sentiment.csv']\n",
    "\n",
    "results = pd.DataFrame(index=models, columns=cryptos)\n",
    "\n",
    "# Loop through each file and each crypto to fill the DataFrame\n",
    "for model, file_path in zip(models, file_paths):\n",
    "    df = pd.read_csv(file_path)\n",
    "    for crypto in cryptos:\n",
    "        # Assuming the MAE column in each file is named 'test_mae'\n",
    "        results.at[model, crypto] = df.loc[df['Data'] == crypto, 'MAE'].values[0]\n",
    "\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T19:22:57.271812Z",
     "start_time": "2024-05-02T19:22:57.251669Z"
    }
   },
   "id": "880f3e064afc9f91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
